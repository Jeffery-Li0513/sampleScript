{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试不同模型\n",
    "\n",
    "1.\tmultiple linear regression (MLR)\n",
    "2.\tbackpropagation artificial neural network (BPNN)\n",
    "3.\tgradient boosting regression (GBR)\n",
    "4.\textreme gradient boosting(XGBoost)\n",
    "5.\tRF\n",
    "6.\tsupport vector regression with radial basis kernel function (SVR-rbf)\n",
    "7.\tsupport vector regression with linear kernel function (SVR-lin)\n",
    "8.\tsupport vector regression with polynomial kernel function (SVR-poly)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.featurizers.composition import alloy\n",
    "from matminer.featurizers.conversions import StrToComposition\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5755032f5264b59a75421d99de3815b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StrToComposition:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b8ff2825fc475bbd1059d2ece8410d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WenAlloys:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('data-全组分-500.csv')\n",
    "\n",
    "# Convert formula to composition\n",
    "data = StrToComposition().featurize_dataframe(data, 'formula')\n",
    "# 然后基于composition计算特征\n",
    "data = alloy.WenAlloys().featurize_dataframe(data, 'composition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择前400条数据作为训练集和验证集；后500条数据作为验证集。\n",
    "data_fit = data.iloc[:400]\n",
    "data_test = data.iloc[400:]\n",
    "\n",
    "data_fit_X = data_fit[['Nb', 'APE mean', 'Radii gamma', 'Electronegativity local mismatch', 'VEC mean', 'Shear modulus strength model']]\n",
    "data_fit_y = data_fit['Pugh']\n",
    "data_test_X = data_test[['Nb', 'APE mean', 'Radii gamma', 'Electronegativity local mismatch', 'VEC mean', 'Shear modulus strength model']]\n",
    "data_test_y = data_test['Pugh']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. multiple linear regression (MLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网格搜索-度量记录： {'mean_fit_time': array([0.00740666, 0.00220208, 0.00200133, 0.00180178]), 'std_fit_time': array([9.31667206e-03, 4.00400176e-04, 4.62310777e-07, 7.49105703e-04]), 'mean_score_time': array([0.00120111, 0.00100126, 0.00100112, 0.00100074]), 'std_score_time': array([4.00329016e-04, 3.56832255e-07, 3.37174788e-07, 5.95569420e-07]), 'param_fit_intercept': masked_array(data=[True, True, False, False],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_normalize': masked_array(data=[True, False, True, False],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'fit_intercept': True, 'normalize': True}, {'fit_intercept': True, 'normalize': False}, {'fit_intercept': False, 'normalize': True}, {'fit_intercept': False, 'normalize': False}], 'split0_test_score': array([-0.04157347, -0.04157347, -0.03562766, -0.03562766]), 'split1_test_score': array([-0.04843757, -0.04843757, -0.04407534, -0.04407534]), 'split2_test_score': array([-0.42496873, -0.42496873, -0.46498721, -0.46498721]), 'split3_test_score': array([-0.0425519 , -0.0425519 , -0.05107279, -0.05107279]), 'split4_test_score': array([-0.03562827, -0.03562827, -0.03449856, -0.03449856]), 'mean_test_score': array([-0.11863199, -0.11863199, -0.12605231, -0.12605231]), 'std_test_score': array([0.15322224, 0.15322224, 0.1695746 , 0.1695746 ]), 'rank_test_score': array([1, 2, 3, 3])}\n",
      "网格搜索-最佳度量值: -0.1186319881370681\n",
      "网格搜索-最佳参数： {'fit_intercept': True, 'normalize': True}\n",
      "网格搜索-最佳模型： LinearRegression(normalize=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\zefengli\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "param_grid_simple = {'fit_intercept': [True, False], 'normalize': [True, False]}\n",
    "search_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid_simple, cv=5, scoring='neg_mean_squared_error')\n",
    "search_lr.fit(data_fit_X, data_fit_y)\n",
    "\n",
    "print('网格搜索-度量记录：',search_lr.cv_results_)  # 包含每次训练的相关信息\n",
    "print('网格搜索-最佳度量值:',search_lr.best_score_)  # 获取最佳度量值\n",
    "print('网格搜索-最佳参数：',search_lr.best_params_)  # 获取最佳度量值时的代定参数的值。是一个字典\n",
    "print('网格搜索-最佳模型：',search_lr.best_estimator_)  # 获取最佳度量时的分类器模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. gradient boosting regression (GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网格搜索-度量记录： {'mean_fit_time': array([2.41284847e-02, 4.59720135e-02, 6.93703651e-02, 9.53991413e-02,\n",
      "       1.13102865e-01, 1.35229397e-01, 1.63977003e-01, 1.81273413e-01,\n",
      "       2.03399754e-01, 3.36304665e-02, 7.04638958e-02, 9.84012604e-02,\n",
      "       1.28624392e-01, 1.65863228e-01, 1.92193794e-01, 2.26713800e-01,\n",
      "       2.54752731e-01, 2.84764814e-01, 4.33478832e-02, 8.51866245e-02,\n",
      "       1.28516817e-01, 1.68073797e-01, 2.11103153e-01, 2.51426506e-01,\n",
      "       2.87422514e-01, 3.30140400e-01, 3.68555641e-01, 5.11530876e-02,\n",
      "       1.01201868e-01, 1.51645947e-01, 2.00292587e-01, 2.50849056e-01,\n",
      "       3.00533390e-01, 3.62558937e-01, 4.05148315e-01, 4.45736456e-01,\n",
      "       5.90534210e-02, 1.15414238e-01, 1.74379826e-01, 2.30768251e-01,\n",
      "       2.94684410e-01, 3.55054808e-01, 4.14303207e-01, 4.72268057e-01,\n",
      "       5.31521225e-01, 6.73712254e-02, 1.33721542e-01, 2.01204491e-01,\n",
      "       2.70060110e-01, 3.36521673e-01, 4.02100229e-01, 4.74467421e-01,\n",
      "       5.41643429e-01, 6.04342699e-01, 7.52680302e-02, 1.51354694e-01,\n",
      "       2.27317333e-01, 3.03892803e-01, 3.75468874e-01, 4.46835756e-01,\n",
      "       5.15193224e-01, 5.32857370e-01, 5.42851305e-01, 8.44767094e-02,\n",
      "       1.65589666e-01, 2.52337122e-01, 3.31622887e-01, 3.99774218e-01,\n",
      "       4.20805502e-01, 4.29729891e-01, 4.42922401e-01, 4.55158758e-01,\n",
      "       8.86805534e-02, 1.80471754e-01, 2.54045630e-01, 2.84384727e-01,\n",
      "       2.91773605e-01, 3.08014536e-01, 3.14501047e-01, 3.31227589e-01,\n",
      "       3.35836220e-01, 5.92542171e-02, 1.15416574e-01, 1.69153547e-01,\n",
      "       2.27546597e-01, 2.89878798e-01, 3.44236040e-01, 4.02276373e-01,\n",
      "       4.56214762e-01, 5.15268326e-01, 9.28843975e-02, 1.79786348e-01,\n",
      "       2.66842413e-01, 3.52520990e-01, 4.34827709e-01, 5.16669703e-01,\n",
      "       6.07375145e-01, 6.86164188e-01, 7.59422112e-01, 1.32227516e-01,\n",
      "       2.57877874e-01, 3.70861626e-01, 4.93930626e-01, 6.17204809e-01,\n",
      "       7.30121565e-01, 8.30812311e-01, 9.41931248e-01, 1.04932551e+00,\n",
      "       1.87784100e-01, 3.58353233e-01, 5.03495884e-01, 6.69640350e-01,\n",
      "       8.23801613e-01, 9.96277571e-01, 1.16164942e+00, 1.30528526e+00,\n",
      "       1.48636179e+00, 2.38134623e-01, 4.79180813e-01, 7.10486984e-01,\n",
      "       8.73484516e-01, 1.07234874e+00, 1.26432414e+00, 1.48565412e+00,\n",
      "       1.75579433e+00, 1.90014672e+00, 3.00199032e-01, 6.16002893e-01,\n",
      "       9.41613913e-01, 1.18346820e+00, 1.51723819e+00, 1.66851649e+00,\n",
      "       1.92921219e+00, 2.28190994e+00, 2.53578644e+00, 4.14017391e-01,\n",
      "       8.08002234e-01, 1.18400731e+00, 1.60706077e+00, 1.93015466e+00,\n",
      "       2.24023571e+00, 2.56289043e+00, 2.87302079e+00, 3.21132889e+00,\n",
      "       5.13598633e-01, 1.03652692e+00, 1.40089369e+00, 1.91181822e+00,\n",
      "       2.35594168e+00, 2.79615402e+00, 3.33025861e+00, 3.73644762e+00,\n",
      "       4.08486924e+00, 5.86366463e-01, 1.17234688e+00, 1.81697941e+00,\n",
      "       2.39013767e+00, 3.04868689e+00, 3.58730149e+00, 4.12241597e+00,\n",
      "       4.45120864e+00, 5.06761713e+00, 8.04732323e-02, 1.57767487e-01,\n",
      "       2.35213757e-01, 3.13011122e-01, 3.91884422e-01, 4.69551134e-01,\n",
      "       5.47646713e-01, 6.23400545e-01, 6.97979403e-01, 1.16213179e-01,\n",
      "       2.28221798e-01, 3.47845221e-01, 4.67758417e-01, 5.79965687e-01,\n",
      "       6.94798803e-01, 8.08297968e-01, 9.45513773e-01, 1.14814630e+00,\n",
      "       1.80829906e-01, 3.58369160e-01, 5.28805733e-01, 7.13506508e-01,\n",
      "       8.79322338e-01, 1.06737061e+00, 1.25193801e+00, 1.42669706e+00,\n",
      "       1.63248405e+00, 2.60261393e-01, 5.15399265e-01, 8.10021257e-01,\n",
      "       1.08923092e+00, 1.33961382e+00, 1.66737804e+00, 1.91676946e+00,\n",
      "       2.26835303e+00, 2.52533717e+00, 4.25586843e-01, 7.72902250e-01,\n",
      "       1.18848467e+00, 1.56562324e+00, 1.96357937e+00, 2.41057549e+00,\n",
      "       2.82085872e+00, 3.22399197e+00, 3.59748411e+00, 7.05511856e-01,\n",
      "       1.13810158e+00, 1.70156660e+00, 2.25781684e+00, 2.86422796e+00,\n",
      "       3.34017024e+00, 3.92899303e+00, 4.42991438e+00, 4.81231647e+00,\n",
      "       1.21447606e+00, 1.77922125e+00, 2.47150669e+00, 3.19966145e+00,\n",
      "       3.90034566e+00, 4.49348474e+00, 4.68777194e+00, 4.77260370e+00,\n",
      "       4.82833114e+00, 2.04084640e+00, 2.68773861e+00, 3.50081549e+00,\n",
      "       4.36042652e+00, 4.74856000e+00, 4.72702336e+00, 4.89591389e+00,\n",
      "       4.90061808e+00, 5.00598440e+00, 2.92866211e+00, 4.06527662e+00,\n",
      "       4.77748599e+00, 4.99562736e+00, 5.03212152e+00, 5.18215528e+00,\n",
      "       5.22153888e+00, 5.30602369e+00, 5.41805277e+00, 5.86532593e-02,\n",
      "       1.18908262e-01, 1.78562021e-01, 2.31010246e-01, 2.89863491e-01,\n",
      "       3.45113230e-01, 3.98762703e-01, 4.55414057e-01, 5.13667059e-01,\n",
      "       8.92810345e-02, 1.72156525e-01, 2.50827742e-01, 3.36905909e-01,\n",
      "       4.16779041e-01, 4.94849205e-01, 5.82729721e-01, 6.57598114e-01,\n",
      "       7.56688166e-01, 1.20308781e-01, 2.34413147e-01, 3.45313549e-01,\n",
      "       4.44604063e-01, 5.63512325e-01, 6.88625860e-01, 8.04330921e-01,\n",
      "       8.75343704e-01, 9.79246855e-01, 1.60761881e-01, 3.06987476e-01,\n",
      "       4.43935919e-01, 5.87879372e-01, 6.97886515e-01, 8.56234837e-01,\n",
      "       9.87258053e-01, 1.13830061e+00, 1.27113576e+00, 1.94203997e-01,\n",
      "       3.86079168e-01, 5.65150404e-01, 7.57940388e-01, 9.07677746e-01,\n",
      "       1.03481326e+00, 1.26103063e+00, 1.43873920e+00, 1.60174756e+00,\n",
      "       2.27113867e-01, 4.77557278e-01, 7.21707916e-01, 9.18590641e-01,\n",
      "       1.19726987e+00, 1.33930831e+00, 1.55002203e+00, 1.72578316e+00,\n",
      "       1.95902181e+00, 2.69155979e-01, 5.83072615e-01, 8.48839521e-01,\n",
      "       1.06223984e+00, 1.28605223e+00, 1.54770789e+00, 1.81095414e+00,\n",
      "       2.18604259e+00, 2.50072145e+00, 3.10008478e-01, 6.71441650e-01,\n",
      "       1.06724381e+00, 1.35711403e+00, 1.59615993e+00, 1.98920817e+00,\n",
      "       2.31810737e+00, 2.81896229e+00, 3.05924363e+00, 3.44513321e-01,\n",
      "       7.80309486e-01, 1.24553213e+00, 1.68152828e+00, 2.05486808e+00,\n",
      "       2.45302992e+00, 2.87341213e+00, 3.18029089e+00, 3.50483961e+00,\n",
      "       2.30207443e-02, 4.46407318e-02, 6.61716461e-02, 8.58778954e-02,\n",
      "       1.08117247e-01, 1.28716850e-01, 1.51244974e-01, 1.76775265e-01,\n",
      "       1.98487949e-01, 3.28296661e-02, 6.48592949e-02, 9.75013733e-02,\n",
      "       1.28425455e-01, 1.60546017e-01, 1.88187933e-01, 2.34431505e-01,\n",
      "       2.55453777e-01, 2.84274006e-01, 4.16377068e-02, 8.23852062e-02,\n",
      "       1.22911644e-01, 1.63560581e-01, 2.04293728e-01, 2.44544601e-01,\n",
      "       2.86071682e-01, 3.26709986e-01, 3.65853167e-01, 5.07510662e-02,\n",
      "       9.96911526e-02, 1.48442268e-01, 1.97489929e-01, 2.47825193e-01,\n",
      "       2.94267368e-01, 3.46514893e-01, 3.97561407e-01, 4.46205711e-01,\n",
      "       5.93132973e-02, 1.16906309e-01, 1.73558044e-01, 2.30810213e-01,\n",
      "       2.87861109e-01, 3.46915388e-01, 4.01970673e-01, 4.60418749e-01,\n",
      "       5.20673227e-01, 6.68607712e-02, 1.32119989e-01, 1.97379446e-01,\n",
      "       2.62237978e-01, 3.27898073e-01, 3.91556120e-01, 4.57015276e-01,\n",
      "       5.20273066e-01, 5.79326487e-01, 7.42674828e-02, 1.47734213e-01,\n",
      "       2.21601343e-01, 2.95068169e-01, 3.67133522e-01, 4.38798666e-01,\n",
      "       5.14267492e-01, 5.87734270e-01, 6.65004730e-01, 8.14741611e-02,\n",
      "       1.62147284e-01, 2.44221783e-01, 3.24488831e-01, 4.02766275e-01,\n",
      "       4.80236530e-01, 5.64313078e-01, 6.44786119e-01, 7.23457527e-01,\n",
      "       8.76789570e-02, 1.75159454e-01, 2.63639545e-01, 3.51118755e-01,\n",
      "       4.43803263e-01, 5.25477743e-01, 6.15359211e-01, 6.94431305e-01,\n",
      "       7.86314821e-01, 5.78524590e-02, 1.14704275e-01, 1.71556234e-01,\n",
      "       2.27014875e-01, 2.83457708e-01, 3.39909124e-01, 3.96360254e-01,\n",
      "       4.53137922e-01, 5.09493399e-01, 9.53928947e-02, 1.86477280e-01,\n",
      "       2.76664877e-01, 3.68464184e-01, 4.56740427e-01, 5.42521524e-01,\n",
      "       6.30112743e-01, 7.10100079e-01, 7.97058535e-01, 1.47042322e-01,\n",
      "       3.19599771e-01, 4.42133951e-01, 5.71949577e-01, 7.05288601e-01,\n",
      "       8.24899864e-01, 9.44523954e-01, 1.08153868e+00, 1.19165592e+00,\n",
      "       2.05802250e-01, 4.09089136e-01, 6.06781578e-01, 8.20601511e-01,\n",
      "       9.82359743e-01, 1.14438829e+00, 1.31739788e+00, 1.48835297e+00,\n",
      "       1.69113741e+00, 2.71847296e-01, 5.34085417e-01, 7.84913540e-01,\n",
      "       1.05696092e+00, 1.30698814e+00, 1.51657901e+00, 1.72379165e+00,\n",
      "       1.92196379e+00, 2.19766908e+00, 3.37037945e-01, 6.65642071e-01,\n",
      "       9.74163294e-01, 1.28184562e+00, 1.61966281e+00, 1.90252657e+00,\n",
      "       2.29024048e+00, 2.72254400e+00, 3.05849848e+00, 3.78959608e-01,\n",
      "       7.61551523e-01, 1.13519936e+00, 1.53698201e+00, 2.04456186e+00,\n",
      "       2.50868030e+00, 3.05577807e+00, 3.54882588e+00, 3.83896146e+00,\n",
      "       4.17304087e-01, 8.47014093e-01, 1.30266933e+00, 1.77040191e+00,\n",
      "       2.39262624e+00, 3.09521360e+00, 3.66052761e+00, 4.47887158e+00,\n",
      "       4.93844900e+00, 4.33830595e-01, 9.42312574e-01, 1.50447803e+00,\n",
      "       2.09533114e+00, 2.92274456e+00, 3.62061181e+00, 4.45976343e+00,\n",
      "       5.25978594e+00, 6.06831627e+00, 8.00728798e-02, 1.58944607e-01,\n",
      "       2.37615490e-01, 3.17088175e-01, 3.96960735e-01, 4.76633453e-01,\n",
      "       5.56505871e-01, 6.33375931e-01, 7.12247515e-01, 1.20910120e-01,\n",
      "       2.41419172e-01, 3.59927034e-01, 4.81637669e-01, 5.98544168e-01,\n",
      "       7.16651201e-01, 8.36552286e-01, 9.49463129e-01, 1.05996351e+00,\n",
      "       1.90172672e-01, 3.77743435e-01, 5.67915821e-01, 7.52684259e-01,\n",
      "       9.24039841e-01, 1.09279323e+00, 1.25914431e+00, 1.40948138e+00,\n",
      "       1.53919907e+00, 3.16086864e-01, 6.30172920e-01, 9.49462986e-01,\n",
      "       1.25393963e+00, 1.54096060e+00, 1.77412663e+00, 2.00984244e+00,\n",
      "       2.22607312e+00, 2.42380323e+00, 5.59908724e-01, 1.11281161e+00,\n",
      "       1.66746349e+00, 2.19494791e+00, 2.68592157e+00, 3.14787521e+00,\n",
      "       3.46870232e+00, 3.74641919e+00, 4.04477086e+00, 9.78537750e-01,\n",
      "       1.98160100e+00, 2.96930771e+00, 3.93392200e+00, 4.87123880e+00,\n",
      "       5.66246243e+00, 6.20485759e+00, 6.78484602e+00, 7.11510415e+00,\n",
      "       1.57074156e+00, 3.19560165e+00, 4.84754043e+00, 6.48833866e+00,\n",
      "       8.02822719e+00, 9.63208137e+00, 1.09304599e+01, 1.23790151e+01,\n",
      "       1.32302280e+01, 2.35850606e+00, 4.66703315e+00, 7.12582273e+00,\n",
      "       9.52141023e+00, 1.20736861e+01, 1.44887754e+01, 1.67665600e+01,\n",
      "       1.89452817e+01, 2.11172717e+01, 3.09773893e+00, 6.31322355e+00,\n",
      "       9.48888893e+00, 1.27342865e+01, 1.59220837e+01, 1.92200714e+01,\n",
      "       2.22588356e+01, 2.54100841e+01, 2.81143561e+01, 5.80528259e-02,\n",
      "       1.15104914e-01, 1.71955967e-01, 2.29208469e-01, 2.86460543e-01,\n",
      "       3.42515993e-01, 3.99162769e-01, 4.55013418e-01, 5.15268421e-01,\n",
      "       9.44858074e-02, 1.82365656e-01, 2.66041708e-01, 3.51919651e-01,\n",
      "       4.45804977e-01, 5.32283592e-01, 6.15759611e-01, 7.09244919e-01,\n",
      "       7.95522928e-01, 1.31919956e-01, 2.48025751e-01, 3.57725191e-01,\n",
      "       4.82638931e-01, 6.01494408e-01, 7.35899639e-01, 8.43734789e-01,\n",
      "       9.72842360e-01, 1.07864795e+00, 1.66657686e-01, 3.15565968e-01,\n",
      "       4.72429371e-01, 6.08552837e-01, 7.54285431e-01, 9.32647991e-01,\n",
      "       1.07477698e+00, 1.21990900e+00, 1.34185429e+00, 1.89885283e-01,\n",
      "       3.85677814e-01, 5.57638979e-01, 7.74156189e-01, 9.78036404e-01,\n",
      "       1.13128567e+00, 1.30978031e+00, 1.55450735e+00, 1.67260962e+00,\n",
      "       2.09808493e-01, 4.36720467e-01, 6.55736923e-01, 8.76656008e-01,\n",
      "       1.13310466e+00, 1.35142703e+00, 1.59815378e+00, 1.80845509e+00,\n",
      "       1.98852916e+00, 2.23619986e-01, 4.57344961e-01, 7.51327848e-01,\n",
      "       1.02829661e+00, 1.26132412e+00, 1.55211439e+00, 1.78063192e+00,\n",
      "       1.93066921e+00, 2.34586716e+00, 2.32030964e-01, 5.05494881e-01,\n",
      "       7.98363590e-01, 1.08838921e+00, 1.38886261e+00, 1.68973570e+00,\n",
      "       2.07860174e+00, 2.46588769e+00, 2.64466448e+00, 2.33032417e-01,\n",
      "       5.12304068e-01, 8.52417421e-01, 1.18465157e+00, 1.51716604e+00,\n",
      "       1.84931316e+00, 2.28981509e+00, 2.67369647e+00, 3.09601150e+00,\n",
      "       2.26205349e-02, 4.50407028e-02, 6.69701099e-02, 8.88801098e-02,\n",
      "       1.10521269e-01, 1.33120823e-01, 1.55046606e-01, 1.75971794e-01,\n",
      "       1.98289633e-01, 3.28296661e-02, 6.45667553e-02, 9.67938423e-02,\n",
      "       1.28425264e-01, 1.60054493e-01, 1.92281771e-01, 2.23016357e-01,\n",
      "       2.55442572e-01, 2.87672472e-01, 4.21496391e-02, 8.30756187e-02,\n",
      "       1.24021149e-01, 1.63854122e-01, 2.05493975e-01, 2.45547199e-01,\n",
      "       2.86074257e-01, 3.39042616e-01, 3.82681513e-01, 5.20471096e-02,\n",
      "       1.03200865e-01, 1.53139400e-01, 1.99599075e-01, 2.47647619e-01,\n",
      "       2.96283722e-01, 3.46438265e-01, 3.96482372e-01, 4.44523525e-01,\n",
      "       5.82525253e-02, 1.15130424e-01, 1.75067186e-01, 2.31224775e-01,\n",
      "       2.87767649e-01, 3.44421196e-01, 4.02165985e-01, 4.59543085e-01,\n",
      "       5.17501593e-01, 6.62601948e-02, 1.31629086e-01, 1.98197269e-01,\n",
      "       2.62746811e-01, 3.28623819e-01, 3.91880369e-01, 4.55331993e-01,\n",
      "       5.22222042e-01, 5.88169432e-01, 7.44673729e-02, 1.46949720e-01,\n",
      "       2.17507267e-01, 2.92296982e-01, 3.69552755e-01, 4.40522337e-01,\n",
      "       5.12389183e-01, 5.95882559e-01, 6.60339403e-01, 8.10733318e-02,\n",
      "       1.61146450e-01, 2.41619635e-01, 3.21892738e-01, 4.04167604e-01,\n",
      "       4.84352446e-01, 5.64953327e-01, 6.43723249e-01, 7.25196552e-01,\n",
      "       8.71929646e-02, 1.73369026e-01, 2.60561848e-01, 3.48536921e-01,\n",
      "       4.37834263e-01, 5.21194887e-01, 6.07987070e-01, 6.84688807e-01,\n",
      "       7.82766390e-01, 5.74523926e-02, 1.13922119e-01, 1.69754457e-01,\n",
      "       2.25729942e-01, 2.82766724e-01, 3.41031027e-01, 3.96078253e-01,\n",
      "       4.54535103e-01, 5.10492611e-01, 9.39976215e-02, 1.87478209e-01,\n",
      "       2.80070591e-01, 3.71066999e-01, 4.64462328e-01, 5.59643793e-01,\n",
      "       6.49735117e-01, 7.36605215e-01, 8.37010765e-01, 1.45045090e-01,\n",
      "       2.88587618e-01, 4.34010410e-01, 5.79126501e-01, 7.20655107e-01,\n",
      "       8.69190073e-01, 1.01792536e+00, 1.15985456e+00, 1.30284414e+00,\n",
      "       1.98598337e-01, 4.05684996e-01, 6.06182098e-01, 8.17391634e-01,\n",
      "       1.02679815e+00, 1.23761368e+00, 1.46312766e+00, 1.68294725e+00,\n",
      "       1.88211083e+00, 2.40443087e-01, 4.91076708e-01, 7.47423315e-01,\n",
      "       1.00459189e+00, 1.28566127e+00, 1.58695951e+00, 1.91375155e+00,\n",
      "       2.18544245e+00, 2.46690774e+00, 2.68861771e-01, 5.53338051e-01,\n",
      "       8.64526176e-01, 1.18524532e+00, 1.52450581e+00, 1.87984648e+00,\n",
      "       2.26080346e+00, 2.62029648e+00, 2.98451276e+00, 2.79053879e-01,\n",
      "       5.77248287e-01, 9.16094494e-01, 1.27463880e+00, 1.66041355e+00,\n",
      "       2.05829759e+00, 2.49011073e+00, 2.95346518e+00, 3.36596422e+00,\n",
      "       2.82181883e-01, 5.86970139e-01, 9.33494043e-01, 1.29885392e+00,\n",
      "       1.73289876e+00, 2.17839375e+00, 2.70931449e+00, 3.17943716e+00,\n",
      "       3.68588657e+00, 2.82784414e-01, 5.84564400e-01, 9.41618967e-01,\n",
      "       1.33590660e+00, 1.76921229e+00, 2.21746893e+00, 2.74296303e+00,\n",
      "       3.30251794e+00, 3.90427961e+00, 7.94718742e-02, 1.59051657e-01,\n",
      "       2.37631989e-01, 3.14813042e-01, 3.92695522e-01, 4.67348146e-01,\n",
      "       5.50745010e-01, 6.79962301e-01, 7.04055500e-01, 1.20509481e-01,\n",
      "       2.55832672e-01, 3.64531088e-01, 4.79035521e-01, 5.88334990e-01,\n",
      "       7.10846043e-01, 8.26752186e-01, 9.42055988e-01, 1.06316638e+00,\n",
      "       1.88170862e-01, 3.74941206e-01, 5.61510515e-01, 7.47879553e-01,\n",
      "       9.41255760e-01, 1.12782526e+00, 1.31699677e+00, 1.49615550e+00,\n",
      "       1.68883848e+00, 3.20626163e-01, 6.40211010e-01, 9.45235348e-01,\n",
      "       1.25472383e+00, 1.56934252e+00, 1.87632494e+00, 2.19310646e+00,\n",
      "       2.50713539e+00, 2.80230775e+00, 5.48234844e-01, 1.08776970e+00,\n",
      "       1.64117999e+00, 2.19250078e+00, 2.75150113e+00, 3.30331311e+00,\n",
      "       3.85642023e+00, 4.42190514e+00, 4.96704946e+00, 9.61328506e-01,\n",
      "       1.90955725e+00, 2.87377810e+00, 3.89086690e+00, 4.80056386e+00,\n",
      "       5.77024541e+00, 6.76534982e+00, 7.72667341e+00, 8.67333231e+00,\n",
      "       1.53199277e+00, 3.08100047e+00, 4.61238461e+00, 6.19142790e+00,\n",
      "       7.69605141e+00, 9.24194937e+00, 1.08819996e+01, 1.24008864e+01,\n",
      "       1.40255979e+01, 2.27818170e+00, 4.60878963e+00, 6.89446707e+00,\n",
      "       9.15191970e+00, 1.15252767e+01, 1.38963687e+01, 1.61912956e+01,\n",
      "       1.85724845e+01, 2.08937272e+01, 3.00709977e+00, 6.01777844e+00,\n",
      "       9.10530286e+00, 1.22671828e+01, 1.54924062e+01, 1.83911689e+01,\n",
      "       2.14735837e+01, 2.46551339e+01, 2.77095606e+01, 5.86537361e-02,\n",
      "       1.15718746e-01, 1.71266603e-01, 2.28719425e-01, 2.87370157e-01,\n",
      "       3.46433449e-01, 4.00488997e-01, 4.62200594e-01, 5.14302063e-01,\n",
      "       9.47926998e-02, 1.88280058e-01, 2.82472610e-01, 3.75663900e-01,\n",
      "       4.68348789e-01, 5.62645292e-01, 6.59832573e-01, 7.50730848e-01,\n",
      "       8.44407701e-01, 1.34735155e-01, 2.69755793e-01, 4.05091524e-01,\n",
      "       5.38635349e-01, 6.73238707e-01, 7.99342918e-01, 9.36651468e-01,\n",
      "       1.06797094e+00, 1.19569254e+00, 1.63348866e-01, 3.29298925e-01,\n",
      "       4.96251488e-01, 6.60800600e-01, 8.22948074e-01, 9.81692410e-01,\n",
      "       1.16465869e+00, 1.34562345e+00, 1.45410962e+00, 1.75665283e-01,\n",
      "       3.60142231e-01, 5.52534103e-01, 7.35119963e-01, 9.38713789e-01,\n",
      "       1.11758127e+00, 1.30939746e+00, 1.52467108e+00, 1.73229804e+00,\n",
      "       1.82476139e-01, 3.69669199e-01, 5.73268604e-01, 7.95580864e-01,\n",
      "       1.01857510e+00, 1.20315170e+00, 1.45971179e+00, 1.70564599e+00,\n",
      "       1.92434902e+00, 1.83967161e-01, 3.72338247e-01, 5.88935614e-01,\n",
      "       8.31755829e-01, 1.06039734e+00, 1.24921293e+00, 1.52978692e+00,\n",
      "       1.80696192e+00, 2.03013377e+00, 1.88171148e-01, 3.83348036e-01,\n",
      "       5.81928444e-01, 8.27296638e-01, 1.05032258e+00, 1.33991036e+00,\n",
      "       1.55032406e+00, 1.87342410e+00, 2.11635513e+00, 1.82580423e-01,\n",
      "       3.79865122e-01, 5.89570093e-01, 8.16992855e-01, 1.06583166e+00,\n",
      "       1.29425344e+00, 1.61285524e+00, 1.89996777e+00, 2.11564317e+00]), 'std_fit_time': array([7.95669940e-04, 5.28861371e-04, 1.88552870e-03, 1.13853845e-02,\n",
      "       2.83102068e-03, 2.05257744e-03, 4.72990732e-03, 2.05016751e-03,\n",
      "       3.71330454e-03, 4.90154472e-04, 7.81995340e-03, 2.35603549e-03,\n",
      "       1.94293370e-03, 7.28021889e-03, 1.80733141e-03, 2.00577286e-03,\n",
      "       1.04127312e-03, 1.26143322e-03, 7.51306666e-04, 1.10159737e-03,\n",
      "       3.55872186e-03, 1.34653964e-03, 4.27121388e-03, 6.19345504e-03,\n",
      "       2.51260566e-03, 1.77693805e-03, 2.09730512e-03, 6.68397625e-04,\n",
      "       6.70157341e-04, 1.42086536e-03, 6.70597408e-04, 1.15922819e-03,\n",
      "       8.53939969e-04, 2.11840360e-02, 5.43365637e-03, 2.70168637e-03,\n",
      "       6.03156597e-07, 4.05466067e-04, 2.01876000e-03, 1.04765105e-03,\n",
      "       3.27957992e-03, 9.44853201e-04, 1.31615333e-03, 1.35718969e-03,\n",
      "       1.97330023e-03, 4.05693564e-04, 4.90329737e-04, 1.88998016e-03,\n",
      "       1.27475929e-03, 1.81880691e-03, 2.05860324e-03, 2.05542279e-03,\n",
      "       2.29762106e-03, 4.06290676e-03, 1.16711992e-03, 9.15745342e-04,\n",
      "       6.70580556e-04, 9.88080052e-04, 2.20860448e-03, 2.39778008e-03,\n",
      "       1.12192227e-02, 1.32525438e-02, 1.61537431e-02, 3.93267408e-03,\n",
      "       2.06381353e-03, 4.28687173e-03, 2.00738717e-03, 1.74752695e-02,\n",
      "       2.88707620e-02, 3.15773360e-02, 3.16479389e-02, 3.23190078e-02,\n",
      "       8.00693115e-04, 6.65860438e-03, 1.62902869e-02, 4.62874682e-02,\n",
      "       3.78181085e-02, 4.45384416e-02, 3.71753792e-02, 3.91439169e-02,\n",
      "       3.76208224e-02, 7.48443145e-04, 1.31246010e-03, 1.79045747e-03,\n",
      "       4.18035779e-03, 2.86514380e-03, 1.74191149e-03, 3.12743715e-03,\n",
      "       2.31650722e-03, 9.80640246e-04, 4.00352563e-04, 3.03536937e-03,\n",
      "       3.72358046e-03, 5.84887107e-03, 3.39423392e-03, 1.47140424e-03,\n",
      "       9.24832632e-03, 1.51528987e-02, 1.94616793e-02, 3.02257763e-03,\n",
      "       6.44546601e-03, 9.73751960e-03, 8.81152703e-03, 1.96508212e-02,\n",
      "       1.66899482e-02, 1.68869987e-02, 1.97638040e-02, 3.36191911e-02,\n",
      "       3.86513118e-03, 1.07463455e-02, 2.73526107e-02, 5.53208402e-03,\n",
      "       1.54963289e-02, 3.70808860e-02, 2.49231626e-02, 4.75834726e-02,\n",
      "       2.06814913e-02, 1.89363079e-02, 1.15970956e-02, 1.92048660e-02,\n",
      "       3.01561389e-02, 3.78372269e-02, 2.87144076e-02, 4.61386525e-02,\n",
      "       4.74334745e-02, 8.67321741e-02, 9.79218073e-03, 1.96525595e-02,\n",
      "       5.31811489e-02, 6.37788618e-02, 6.22444924e-02, 5.50011553e-02,\n",
      "       4.88314879e-02, 1.06912206e-01, 9.17124663e-02, 1.87147696e-02,\n",
      "       3.35602581e-02, 4.60466859e-02, 8.54069105e-02, 4.93463985e-02,\n",
      "       1.25582239e-01, 9.11671966e-02, 1.15916939e-01, 1.05170923e-01,\n",
      "       2.49773053e-02, 5.03515406e-02, 2.93974320e-02, 5.24567178e-02,\n",
      "       5.25736757e-02, 1.65024899e-01, 1.06004398e-01, 5.37789424e-02,\n",
      "       1.13107083e-01, 3.04152298e-02, 3.28126177e-02, 9.81235717e-02,\n",
      "       5.55234587e-02, 1.70766532e-01, 1.57149579e-01, 9.20201689e-02,\n",
      "       2.34232601e-01, 1.36281469e-01, 1.49766323e-03, 2.63911930e-03,\n",
      "       8.95162055e-04, 1.19587523e-03, 1.77694397e-03, 6.00636725e-04,\n",
      "       1.56508202e-03, 1.31421173e-03, 2.28526857e-03, 1.03110384e-03,\n",
      "       2.89059300e-03, 3.35049003e-03, 4.94648726e-03, 2.96089625e-03,\n",
      "       4.32353396e-03, 4.15732715e-03, 1.13577443e-02, 9.21966524e-02,\n",
      "       8.84186799e-03, 1.81486750e-02, 1.07977034e-02, 2.16556893e-02,\n",
      "       1.45784487e-02, 1.44715426e-02, 1.51713606e-02, 1.94250636e-02,\n",
      "       2.16438522e-02, 1.07080984e-02, 2.84497079e-02, 3.42632580e-02,\n",
      "       2.96133206e-02, 2.74636220e-02, 3.58799892e-02, 2.97695538e-02,\n",
      "       1.42646681e-01, 5.62627024e-02, 1.22321715e-02, 3.40683634e-02,\n",
      "       2.83403836e-02, 4.86172741e-02, 6.07230261e-02, 3.18011100e-02,\n",
      "       6.94020419e-02, 4.98146233e-02, 6.46809276e-02, 3.00084884e-02,\n",
      "       3.66013842e-02, 4.88599151e-02, 5.82434287e-02, 7.63987008e-02,\n",
      "       8.05452257e-02, 8.38254158e-02, 5.68856631e-02, 4.27001937e-02,\n",
      "       3.43601583e-02, 5.31505650e-02, 4.87799418e-02, 7.10593100e-02,\n",
      "       7.47448828e-02, 6.68514856e-02, 1.22132579e-01, 1.00871179e-01,\n",
      "       1.10796928e-01, 8.18670003e-02, 1.20255696e-01, 8.01778196e-02,\n",
      "       7.01313320e-02, 9.59177891e-02, 9.59576164e-02, 5.30572097e-02,\n",
      "       5.62225270e-02, 6.00406243e-02, 1.56699094e-01, 9.60136749e-02,\n",
      "       6.81044357e-02, 6.91337156e-02, 5.30684154e-02, 5.81587452e-02,\n",
      "       1.42408875e-02, 5.44275530e-02, 1.18120318e-01, 1.02054366e-03,\n",
      "       1.72234150e-03, 5.43058906e-03, 6.74100170e-03, 6.18931147e-03,\n",
      "       2.99617710e-03, 2.87314262e-03, 1.79096387e-03, 1.72233598e-03,\n",
      "       1.16692364e-03, 2.45164825e-03, 2.72983018e-03, 1.24464718e-02,\n",
      "       3.77684698e-03, 3.00926751e-03, 2.77263020e-02, 3.63685447e-03,\n",
      "       3.85892221e-02, 2.22889702e-03, 7.20125656e-03, 1.35771580e-02,\n",
      "       6.62141031e-03, 9.57909811e-03, 3.61380624e-02, 3.90617031e-02,\n",
      "       4.20561909e-02, 3.74659502e-02, 5.79954131e-03, 9.87055803e-03,\n",
      "       2.00274883e-02, 3.95907252e-02, 2.69341597e-02, 3.16639529e-02,\n",
      "       2.08552755e-02, 4.20351660e-02, 8.71352227e-02, 1.12284848e-02,\n",
      "       1.40307396e-02, 4.80581032e-02, 6.95332923e-02, 3.03949560e-02,\n",
      "       5.40013701e-02, 1.25363459e-01, 9.29148477e-02, 6.45183613e-02,\n",
      "       1.08370928e-02, 2.00835736e-02, 2.83910061e-02, 5.47415142e-02,\n",
      "       7.21520557e-02, 1.14261012e-01, 6.84878989e-02, 4.51155458e-02,\n",
      "       1.55397368e-01, 9.57201062e-03, 3.74265318e-02, 2.93707235e-02,\n",
      "       3.79779691e-02, 3.03535987e-02, 5.39727693e-02, 9.26060559e-02,\n",
      "       1.55754069e-01, 2.01542786e-01, 1.15925533e-02, 2.79843461e-02,\n",
      "       5.11652650e-02, 7.84849699e-02, 1.23891718e-01, 1.53183924e-01,\n",
      "       1.93621894e-01, 2.20861272e-01, 2.70894875e-01, 2.36466485e-02,\n",
      "       2.73784982e-02, 9.44186940e-02, 6.55302353e-02, 2.12185064e-01,\n",
      "       1.50441176e-01, 1.43397132e-01, 1.12063439e-01, 2.00268559e-01,\n",
      "       1.41559466e-03, 8.00883849e-04, 1.36990349e-03, 1.47074887e-03,\n",
      "       1.67944995e-03, 1.85614217e-03, 2.00592115e-03, 1.16009760e-03,\n",
      "       9.66510156e-04, 7.49067385e-04, 7.49003669e-04, 1.82311119e-03,\n",
      "       9.82391870e-04, 8.00931601e-04, 2.93047206e-03, 2.10918161e-02,\n",
      "       1.67085252e-03, 1.41613200e-03, 8.00633464e-04, 8.87591744e-04,\n",
      "       4.00280992e-04, 5.76407621e-04, 7.94968675e-04, 2.11929137e-03,\n",
      "       1.61750385e-03, 1.88106652e-03, 2.92012234e-03, 3.97755213e-04,\n",
      "       4.90173964e-04, 9.82573349e-04, 5.86391266e-04, 8.00216398e-04,\n",
      "       3.16512459e-03, 1.72208646e-03, 2.31749999e-03, 3.76648362e-03,\n",
      "       3.88110532e-04, 9.80620417e-04, 1.20117673e-03, 1.20128800e-03,\n",
      "       1.20115285e-03, 1.49765053e-03, 1.48833233e-03, 1.41576329e-03,\n",
      "       4.00805569e-04, 7.48927226e-04, 1.89921447e-03, 9.80766366e-04,\n",
      "       2.60999714e-03, 2.65559838e-03, 1.94122821e-03, 2.41894400e-03,\n",
      "       4.53836184e-03, 1.47111874e-03, 9.79939163e-04, 1.20124820e-03,\n",
      "       2.06083866e-03, 3.25271663e-03, 3.43253283e-03, 3.26479614e-03,\n",
      "       2.40197186e-03, 3.54739304e-03, 9.42345371e-03, 1.02049682e-03,\n",
      "       1.09641044e-03, 1.89923963e-03, 1.71932494e-03, 4.22745310e-03,\n",
      "       3.97333207e-03, 5.31168197e-03, 4.58274978e-03, 8.01711407e-03,\n",
      "       1.74492647e-03, 1.67533602e-03, 3.26491602e-03, 4.12211726e-03,\n",
      "       9.48687861e-03, 6.07164596e-03, 7.68524076e-03, 1.07502309e-02,\n",
      "       9.88005310e-03, 7.49143931e-04, 1.02101150e-03, 1.35785115e-03,\n",
      "       9.82764583e-04, 1.94124298e-03, 1.74503583e-03, 4.33986047e-03,\n",
      "       5.90345420e-04, 2.97889764e-03, 9.81861683e-04, 1.78461918e-03,\n",
      "       1.54517323e-03, 2.28502691e-03, 2.69020590e-03, 7.74667533e-03,\n",
      "       1.11408195e-02, 8.74355588e-03, 1.16195480e-02, 1.69524840e-03,\n",
      "       2.45323418e-02, 2.05443683e-02, 7.97981448e-03, 1.05339798e-02,\n",
      "       6.57901930e-03, 1.36743136e-02, 1.80991748e-02, 2.89887640e-02,\n",
      "       4.55337265e-03, 1.01782763e-02, 1.15604641e-02, 1.37668074e-02,\n",
      "       3.13643830e-02, 1.69745879e-02, 3.97717982e-02, 1.88962381e-02,\n",
      "       3.72175265e-02, 7.74293418e-03, 1.23822072e-02, 1.36711259e-02,\n",
      "       2.24080315e-02, 2.91014852e-02, 5.31876477e-02, 1.71934096e-02,\n",
      "       5.15932120e-02, 1.02214424e-01, 8.83905548e-03, 1.44025605e-02,\n",
      "       1.78620078e-02, 2.33907816e-02, 4.16674450e-02, 7.89829833e-02,\n",
      "       1.07831671e-01, 1.84991825e-01, 2.50259657e-01, 1.05462237e-02,\n",
      "       2.55971243e-02, 2.73576822e-02, 3.51463036e-02, 1.10413603e-01,\n",
      "       5.52064213e-02, 8.12972737e-02, 1.11703842e-01, 3.09304444e-01,\n",
      "       5.98586165e-03, 7.57073660e-03, 1.91036060e-02, 3.85321615e-02,\n",
      "       1.39833072e-01, 1.54288987e-01, 1.25678049e-01, 1.75685163e-01,\n",
      "       2.14300581e-01, 1.19445367e-02, 2.71017104e-02, 3.70544611e-02,\n",
      "       1.42269118e-01, 1.95370591e-01, 1.46362090e-01, 1.76689925e-01,\n",
      "       1.85102469e-01, 1.25869087e-01, 1.09658459e-03, 1.16752890e-03,\n",
      "       1.74507417e-03, 9.80600891e-04, 2.41878608e-03, 1.72211981e-03,\n",
      "       2.36875911e-03, 2.99611975e-03, 1.85668212e-03, 7.49207985e-04,\n",
      "       1.94068732e-03, 1.20098602e-03, 1.16712808e-03, 3.10116317e-03,\n",
      "       5.06422532e-03, 5.63043789e-03, 4.32146957e-03, 9.01897073e-03,\n",
      "       6.32937486e-04, 1.62643903e-03, 2.15614560e-03, 1.89911403e-03,\n",
      "       3.31371668e-03, 1.13310885e-02, 1.29420262e-02, 1.09903487e-02,\n",
      "       3.40393090e-02, 2.13769931e-03, 3.44421171e-03, 3.66964486e-03,\n",
      "       4.71185855e-03, 9.47925437e-03, 1.52913400e-02, 2.64756657e-02,\n",
      "       3.25831687e-02, 4.99996125e-02, 2.24696422e-03, 1.15068670e-02,\n",
      "       6.20477127e-03, 1.14038971e-02, 2.60692192e-02, 3.21406621e-02,\n",
      "       4.95355936e-02, 4.33233705e-02, 6.07392462e-02, 1.66860961e-02,\n",
      "       3.02160662e-02, 2.81240510e-02, 4.00865297e-02, 4.68663363e-02,\n",
      "       6.83979831e-02, 6.53847265e-02, 1.01396109e-01, 2.11670552e-01,\n",
      "       2.74125981e-02, 4.83710664e-02, 7.03126114e-02, 9.80016097e-02,\n",
      "       1.06574305e-01, 1.28473007e-01, 1.59030887e-01, 3.49894323e-01,\n",
      "       2.61094914e-01, 6.03881760e-02, 7.76534481e-02, 8.32936071e-02,\n",
      "       1.29383328e-01, 1.34761286e-01, 1.97035031e-01, 1.45167417e-01,\n",
      "       3.30835639e-01, 3.47697950e-01, 5.93285386e-02, 8.89730360e-02,\n",
      "       7.53090144e-02, 9.07889825e-02, 1.23574361e-01, 8.52659661e-02,\n",
      "       2.96147682e-01, 2.10513560e-01, 5.95071535e-01, 6.32485143e-04,\n",
      "       1.26591261e-03, 1.94063809e-03, 1.26613883e-03, 1.32771120e-03,\n",
      "       1.94800535e-03, 2.48396044e-03, 3.38532405e-03, 1.94033803e-03,\n",
      "       1.35766133e-03, 4.35800945e-03, 2.92843023e-03, 3.61416254e-03,\n",
      "       2.16403525e-02, 4.26489479e-03, 1.16278662e-02, 9.73703370e-03,\n",
      "       1.06756996e-02, 2.56359979e-03, 5.23536092e-03, 5.54017565e-03,\n",
      "       5.19680580e-03, 2.10938578e-02, 1.51804036e-02, 1.45378993e-02,\n",
      "       1.56399662e-02, 1.42587159e-02, 4.85022964e-03, 7.92569523e-03,\n",
      "       1.90649676e-02, 1.29577814e-02, 3.25358365e-02, 2.70902858e-02,\n",
      "       2.50380107e-02, 2.70906769e-02, 2.61184630e-02, 1.10647276e-02,\n",
      "       1.56909594e-02, 2.52349968e-02, 2.85238509e-02, 4.92422829e-02,\n",
      "       6.21931754e-02, 1.54674147e-02, 5.47427101e-02, 4.73350409e-02,\n",
      "       1.28457643e-02, 1.25235209e-02, 2.33271639e-02, 3.20063540e-02,\n",
      "       9.34837235e-02, 5.07722218e-02, 1.08929260e-01, 9.53995199e-02,\n",
      "       1.23453751e-01, 9.45601450e-03, 2.11624801e-02, 1.69973779e-02,\n",
      "       2.76721348e-02, 7.01367423e-02, 9.02218388e-02, 6.82876716e-02,\n",
      "       2.48372454e-02, 8.08130972e-02, 7.66415311e-03, 1.90388227e-02,\n",
      "       5.19794295e-02, 5.18993277e-02, 8.19247212e-02, 1.18413403e-01,\n",
      "       3.65586792e-02, 1.64102770e-01, 1.41418492e-01, 1.33874150e-02,\n",
      "       1.36913560e-02, 1.61761969e-02, 3.49037979e-02, 5.67663732e-02,\n",
      "       9.68076243e-02, 9.16113979e-02, 1.66729241e-01, 1.31272596e-01,\n",
      "       4.90349403e-04, 8.95215465e-04, 1.11121596e-03, 7.49041929e-04,\n",
      "       1.46495719e-03, 1.41556095e-03, 9.14366448e-04, 6.90987413e-04,\n",
      "       1.03373562e-03, 4.00257167e-04, 9.04484823e-04, 1.08287323e-03,\n",
      "       7.51076327e-04, 8.07701574e-04, 1.11734016e-03, 1.51744553e-03,\n",
      "       1.68127686e-03, 1.61007275e-03, 2.22636724e-04, 6.33088375e-04,\n",
      "       1.02600222e-03, 7.47504490e-04, 7.50879220e-04, 1.18199774e-03,\n",
      "       1.74504792e-03, 2.08785180e-02, 5.85138962e-03, 1.09614933e-03,\n",
      "       1.68038028e-03, 1.09654106e-03, 5.10895057e-03, 1.13730229e-03,\n",
      "       1.51058728e-03, 2.40338155e-03, 1.17164528e-03, 1.99179607e-03,\n",
      "       4.00209498e-04, 1.59621565e-03, 3.87449777e-03, 4.94266361e-03,\n",
      "       3.23666190e-03, 2.87165510e-03, 4.21862007e-03, 3.90645970e-03,\n",
      "       4.54385282e-03, 9.81009749e-04, 1.47121546e-03, 4.14063342e-03,\n",
      "       2.58364336e-03, 3.90341893e-03, 3.87109603e-03, 4.91661613e-03,\n",
      "       4.14420858e-03, 6.14257898e-03, 1.49826223e-03, 1.22628358e-03,\n",
      "       1.79662546e-03, 3.04667512e-03, 5.16528399e-03, 3.21269614e-03,\n",
      "       5.52104650e-03, 1.96977112e-02, 6.68179892e-03, 1.09649766e-03,\n",
      "       1.67488010e-03, 2.41923202e-03, 3.26508853e-03, 3.71274703e-03,\n",
      "       4.84215714e-03, 5.29918819e-03, 5.35011865e-03, 6.22889200e-03,\n",
      "       1.19411220e-03, 2.55339270e-03, 3.90615501e-03, 5.76594467e-03,\n",
      "       5.98914704e-03, 8.66934677e-03, 8.12592002e-03, 9.66655175e-03,\n",
      "       8.37625764e-03, 4.90212913e-04, 1.01634353e-03, 1.02088963e-03,\n",
      "       1.76315992e-03, 1.00080128e-03, 2.13007985e-03, 1.10893976e-03,\n",
      "       8.10363119e-04, 2.94372336e-03, 1.76025301e-04, 5.89974713e-04,\n",
      "       7.98032614e-04, 1.94182759e-03, 1.28529475e-03, 1.77655112e-03,\n",
      "       1.40217696e-02, 7.46212810e-03, 3.98352416e-03, 3.89923767e-03,\n",
      "       9.59923929e-03, 8.89420806e-03, 7.87124145e-03, 1.44907282e-02,\n",
      "       2.28909476e-02, 2.51306484e-02, 2.01918563e-02, 1.76192052e-02,\n",
      "       8.36388341e-03, 1.42397868e-02, 1.62015809e-02, 1.27103739e-02,\n",
      "       1.72883407e-02, 2.65341861e-02, 3.16981048e-02, 2.45604466e-02,\n",
      "       2.67940668e-02, 1.09821155e-02, 2.18559465e-02, 1.95900121e-02,\n",
      "       2.04724923e-02, 1.59858985e-02, 2.92489599e-02, 3.50856944e-02,\n",
      "       5.97349343e-02, 3.05666370e-02, 9.18938809e-03, 1.84190171e-02,\n",
      "       2.38497558e-02, 2.98127659e-02, 3.28366567e-02, 5.14740840e-02,\n",
      "       4.05124283e-02, 5.99849780e-02, 6.81160546e-02, 7.08895951e-03,\n",
      "       1.25912041e-02, 1.95503666e-02, 1.71836958e-02, 3.65236602e-02,\n",
      "       2.04937894e-02, 2.39100562e-02, 3.10429289e-02, 4.07506932e-02,\n",
      "       6.70125438e-03, 1.57451736e-02, 2.02954879e-02, 2.80757250e-02,\n",
      "       4.15510933e-02, 3.57809717e-02, 6.26445007e-02, 3.34989613e-02,\n",
      "       4.30131377e-02, 9.55986755e-03, 1.38698387e-02, 2.05415005e-02,\n",
      "       2.54857255e-02, 5.46496497e-02, 5.54021618e-02, 8.00091877e-02,\n",
      "       8.36460111e-02, 6.99522763e-02, 1.02037558e-03, 1.01093258e-03,\n",
      "       8.12818603e-04, 9.70355317e-04, 1.70711931e-03, 4.32468682e-03,\n",
      "       2.20322327e-03, 8.12684297e-02, 3.13838622e-03, 1.35764735e-03,\n",
      "       1.83208797e-02, 7.89156485e-03, 1.07914774e-02, 1.32776150e-03,\n",
      "       2.92806843e-03, 1.41515642e-03, 7.48697849e-04, 1.60139805e-03,\n",
      "       8.95748589e-04, 4.90154518e-04, 1.67411067e-03, 4.66940772e-03,\n",
      "       9.01024895e-03, 3.71292953e-03, 4.17067877e-03, 7.94508615e-03,\n",
      "       3.55725873e-03, 8.13957563e-03, 1.44686304e-02, 2.22358067e-03,\n",
      "       1.20263036e-02, 3.64216189e-03, 4.94769600e-03, 3.06466874e-03,\n",
      "       4.44948821e-03, 1.20226433e-02, 6.09922259e-03, 1.11542092e-02,\n",
      "       1.49308080e-02, 2.52151307e-02, 2.08898558e-02, 1.31546691e-02,\n",
      "       1.14382835e-02, 2.56918630e-02, 2.03345707e-02, 5.58825143e-02,\n",
      "       5.44041041e-02, 6.72826784e-02, 8.95363941e-02, 8.46902013e-02,\n",
      "       8.21055049e-02, 9.19044501e-02, 1.02807808e-01, 1.28705879e-01,\n",
      "       4.66585385e-02, 6.22769574e-02, 9.62095523e-02, 7.48136112e-02,\n",
      "       9.66937308e-02, 1.48432659e-01, 1.49241690e-01, 1.66239484e-01,\n",
      "       1.74605142e-01, 7.09005015e-02, 1.27948179e-01, 1.34461586e-01,\n",
      "       1.50778271e-01, 1.75694938e-01, 1.27723977e-01, 1.73238172e-01,\n",
      "       1.50853887e-01, 2.50787306e-01, 5.39525473e-02, 1.06561396e-01,\n",
      "       1.73204957e-01, 3.06738330e-01, 3.40302997e-01, 2.80889887e-01,\n",
      "       4.67310902e-01, 4.53626213e-01, 4.98363342e-01, 8.00979238e-04,\n",
      "       1.34228104e-03, 1.36946195e-03, 1.20389260e-03, 1.34076236e-03,\n",
      "       1.09465301e-03, 4.09334985e-03, 5.75029218e-03, 5.26134726e-04,\n",
      "       9.79285251e-04, 1.28499842e-03, 1.12788994e-03, 1.27634859e-03,\n",
      "       1.00656490e-03, 1.69842756e-03, 2.56271728e-03, 2.60666816e-03,\n",
      "       3.04651060e-03, 6.24060466e-03, 9.10111903e-03, 9.37061664e-03,\n",
      "       8.72294731e-03, 1.72691489e-02, 1.99520950e-02, 3.39093565e-02,\n",
      "       2.08702467e-02, 1.78154917e-02, 5.84967381e-03, 1.68438071e-02,\n",
      "       2.31501675e-02, 3.54126683e-02, 4.97900672e-02, 6.45175445e-02,\n",
      "       7.73686326e-02, 7.81392706e-02, 5.57905354e-02, 8.56831736e-03,\n",
      "       1.49403756e-02, 2.71390681e-02, 3.78266565e-02, 5.03858546e-02,\n",
      "       7.61274410e-02, 8.44532903e-02, 7.74236651e-02, 7.80910730e-02,\n",
      "       1.71582533e-02, 2.52635255e-02, 2.99408832e-02, 3.40169590e-02,\n",
      "       5.57339728e-02, 9.71670000e-02, 9.75826687e-02, 1.43346208e-01,\n",
      "       8.01670332e-02, 1.79539624e-02, 3.03455923e-02, 2.96686492e-02,\n",
      "       3.94057119e-02, 4.60639013e-02, 3.24855408e-02, 8.94574136e-02,\n",
      "       8.11014840e-02, 1.04770991e-01, 1.81164240e-02, 3.01673064e-02,\n",
      "       3.08798432e-02, 4.27235390e-02, 4.72229296e-02, 5.73177130e-02,\n",
      "       7.07154391e-02, 5.91633290e-02, 8.39329065e-02, 1.61131080e-02,\n",
      "       2.81124144e-02, 2.96445597e-02, 2.53686830e-02, 3.96646988e-02,\n",
      "       5.44007795e-02, 6.62295724e-02, 8.22630044e-02, 6.34647168e-02]), 'mean_score_time': array([0.00160184, 0.00087099, 0.00140104, 0.00140119, 0.00120106,\n",
      "       0.00160151, 0.0010006 , 0.00100088, 0.00120101, 0.00100117,\n",
      "       0.00140104, 0.00140114, 0.0014019 , 0.00140142, 0.00180154,\n",
      "       0.00180135, 0.00100112, 0.00160165, 0.00100102, 0.00100112,\n",
      "       0.00140119, 0.00140123, 0.00180168, 0.00140142, 0.0018012 ,\n",
      "       0.00180187, 0.00200191, 0.00100126, 0.00140133, 0.00160131,\n",
      "       0.00180187, 0.00200171, 0.00211401, 0.00200205, 0.00200176,\n",
      "       0.00240197, 0.00140157, 0.00160103, 0.00180178, 0.00200195,\n",
      "       0.00220218, 0.00200143, 0.00220189, 0.00300217, 0.0026022 ,\n",
      "       0.00120111, 0.00180202, 0.00180182, 0.00200171, 0.00240221,\n",
      "       0.00240211, 0.00260248, 0.00300264, 0.00288076, 0.00180206,\n",
      "       0.00180154, 0.00220222, 0.00240231, 0.00300298, 0.00280261,\n",
      "       0.00300245, 0.00300298, 0.00300255, 0.00180202, 0.002002  ,\n",
      "       0.00200181, 0.00300264, 0.00272088, 0.00240169, 0.00260191,\n",
      "       0.00280256, 0.00300269, 0.00160146, 0.00200181, 0.00260224,\n",
      "       0.00260215, 0.00260201, 0.00280232, 0.00260239, 0.00280271,\n",
      "       0.00280218, 0.00100055, 0.00100121, 0.00120106, 0.00100102,\n",
      "       0.00120077, 0.00120115, 0.00120106, 0.00120115, 0.00120134,\n",
      "       0.00120106, 0.00140142, 0.00140114, 0.00120111, 0.00160108,\n",
      "       0.00140119, 0.0018013 , 0.00180163, 0.00140133, 0.00140109,\n",
      "       0.00140152, 0.00180154, 0.00160103, 0.00180182, 0.00140128,\n",
      "       0.00160165, 0.00160136, 0.0016016 , 0.00120115, 0.00140123,\n",
      "       0.0012012 , 0.00120134, 0.00160146, 0.00160184, 0.00200143,\n",
      "       0.00180192, 0.00200152, 0.00140133, 0.00160136, 0.00120153,\n",
      "       0.00140128, 0.00200191, 0.00160122, 0.00200176, 0.00240216,\n",
      "       0.00200181, 0.00140166, 0.00120115, 0.00180173, 0.0016016 ,\n",
      "       0.00200148, 0.00220218, 0.00280218, 0.00220213, 0.00240202,\n",
      "       0.00120087, 0.00160165, 0.00200129, 0.00220194, 0.00220213,\n",
      "       0.0024024 , 0.00280237, 0.00300231, 0.00320282, 0.00140157,\n",
      "       0.0018013 , 0.00200191, 0.00240211, 0.00260234, 0.0026022 ,\n",
      "       0.00320287, 0.00380344, 0.00380354, 0.00140104, 0.00180182,\n",
      "       0.00220237, 0.00280228, 0.0028019 , 0.00320287, 0.00320306,\n",
      "       0.00340304, 0.00460396, 0.00120091, 0.00100079, 0.00111408,\n",
      "       0.00140152, 0.00120077, 0.0012013 , 0.00120125, 0.00120101,\n",
      "       0.00140152, 0.00100107, 0.00140109, 0.00140157, 0.00120111,\n",
      "       0.00120144, 0.00160155, 0.00160174, 0.002002  , 0.00140142,\n",
      "       0.00100093, 0.0010006 , 0.00120106, 0.00140109, 0.0012012 ,\n",
      "       0.00160103, 0.00160179, 0.00200195, 0.00200152, 0.00100107,\n",
      "       0.00120139, 0.00160198, 0.00160141, 0.00200181, 0.00200171,\n",
      "       0.00200171, 0.0024024 , 0.00200143, 0.00100098, 0.00180187,\n",
      "       0.00160165, 0.00140138, 0.00200186, 0.00240197, 0.0024024 ,\n",
      "       0.00240178, 0.00280223, 0.00100098, 0.00180187, 0.00200205,\n",
      "       0.00200176, 0.00240221, 0.00220199, 0.00240164, 0.00260229,\n",
      "       0.00320296, 0.00140119, 0.00140119, 0.00180216, 0.00200214,\n",
      "       0.00280228, 0.00280242, 0.00280223, 0.00300255, 0.00320263,\n",
      "       0.00160131, 0.00180168, 0.00200171, 0.00240207, 0.00260234,\n",
      "       0.0030025 , 0.00280228, 0.00260196, 0.00280237, 0.00160155,\n",
      "       0.00220165, 0.00240231, 0.00260215, 0.00240207, 0.00220203,\n",
      "       0.00280237, 0.0026021 , 0.00280237, 0.00120082, 0.00140142,\n",
      "       0.00120111, 0.00120077, 0.00160155, 0.00100131, 0.00120087,\n",
      "       0.00100083, 0.00140119, 0.00100107, 0.00120091, 0.0012013 ,\n",
      "       0.00140142, 0.00140162, 0.00160193, 0.00140128, 0.00160131,\n",
      "       0.00140119, 0.0014019 , 0.00120091, 0.00120139, 0.00160151,\n",
      "       0.00120101, 0.00120134, 0.00160146, 0.00140133, 0.00180173,\n",
      "       0.00100117, 0.00140195, 0.00120096, 0.00140109, 0.00180154,\n",
      "       0.00160151, 0.00180144, 0.00180116, 0.00160189, 0.0012013 ,\n",
      "       0.00120096, 0.00120106, 0.00140095, 0.00200152, 0.00160151,\n",
      "       0.00200157, 0.00200195, 0.00200143, 0.0012012 , 0.00100131,\n",
      "       0.00160122, 0.00180149, 0.002002  , 0.00200176, 0.00220137,\n",
      "       0.00220194, 0.00280271, 0.00120111, 0.00120115, 0.00180149,\n",
      "       0.00160136, 0.00200176, 0.00200224, 0.00220203, 0.00240235,\n",
      "       0.00300317, 0.00120115, 0.00140114, 0.00160127, 0.00180154,\n",
      "       0.00200152, 0.00280266, 0.00280242, 0.00320315, 0.00340281,\n",
      "       0.00120082, 0.00160151, 0.002002  , 0.0022018 , 0.00240202,\n",
      "       0.0028028 , 0.00300288, 0.00300274, 0.00340314, 0.00120087,\n",
      "       0.00120101, 0.00120101, 0.00100112, 0.00120115, 0.00100107,\n",
      "       0.00120177, 0.00160131, 0.00120101, 0.00100098, 0.00120087,\n",
      "       0.0012012 , 0.00120125, 0.00120139, 0.00160136, 0.0012012 ,\n",
      "       0.00120139, 0.00180187, 0.00100102, 0.00120101, 0.0016016 ,\n",
      "       0.00120087, 0.00100074, 0.00200176, 0.00120101, 0.00200162,\n",
      "       0.00160122, 0.00100098, 0.0010005 , 0.0020021 , 0.00160174,\n",
      "       0.00160155, 0.00140133, 0.00200214, 0.00220227, 0.00220156,\n",
      "       0.00094156, 0.00140128, 0.0014009 , 0.00140095, 0.00200248,\n",
      "       0.00200186, 0.00259714, 0.00280252, 0.00300293, 0.00100088,\n",
      "       0.00180173, 0.00160117, 0.00200195, 0.00240226, 0.00280256,\n",
      "       0.00240216, 0.00340328, 0.00320272, 0.0012013 , 0.00140114,\n",
      "       0.00220208, 0.00240173, 0.00280256, 0.00300288, 0.00300293,\n",
      "       0.00400386, 0.00360322, 0.00100079, 0.00180221, 0.00240245,\n",
      "       0.00280852, 0.00340257, 0.00400352, 0.00400376, 0.00400372,\n",
      "       0.00480437, 0.00160203, 0.00200171, 0.00260201, 0.00320306,\n",
      "       0.00400414, 0.00400348, 0.00460463, 0.00520468, 0.00560508,\n",
      "       0.00100102, 0.00100117, 0.00120106, 0.00119214, 0.00120106,\n",
      "       0.00120087, 0.00120125, 0.00100088, 0.00120077, 0.00100121,\n",
      "       0.00140147, 0.00160127, 0.00100121, 0.00140133, 0.00160127,\n",
      "       0.00120096, 0.00160165, 0.0018127 , 0.00100083, 0.00120115,\n",
      "       0.00120044, 0.00120091, 0.00180182, 0.00190973, 0.00180206,\n",
      "       0.00200181, 0.00160151, 0.00100069, 0.00160117, 0.00140119,\n",
      "       0.00160141, 0.00120111, 0.00200195, 0.00200152, 0.00200195,\n",
      "       0.00200171, 0.00100045, 0.00120106, 0.00160174, 0.00120106,\n",
      "       0.00140123, 0.00200148, 0.0022017 , 0.00220199, 0.00220184,\n",
      "       0.00140123, 0.00120106, 0.00160112, 0.0016017 , 0.00200157,\n",
      "       0.00220194, 0.0024024 , 0.00260215, 0.00300274, 0.0012013 ,\n",
      "       0.00140133, 0.00140157, 0.00200186, 0.00200181, 0.00260234,\n",
      "       0.0030026 , 0.00320287, 0.00340328, 0.00120087, 0.00160127,\n",
      "       0.00180178, 0.00220184, 0.00260234, 0.00300264, 0.00320282,\n",
      "       0.00400343, 0.00400362, 0.00140109, 0.00160131, 0.00200171,\n",
      "       0.00240216, 0.00300283, 0.00300264, 0.00360312, 0.00400381,\n",
      "       0.00480423, 0.00100102, 0.0010006 , 0.00120153, 0.00120101,\n",
      "       0.00120096, 0.00120068, 0.00120115, 0.00140119, 0.00140114,\n",
      "       0.00100074, 0.00120149, 0.0012013 , 0.00120111, 0.00140142,\n",
      "       0.00140147, 0.00140095, 0.00160174, 0.00140157, 0.00120125,\n",
      "       0.00140753, 0.00140166, 0.00160131, 0.00120101, 0.0016017 ,\n",
      "       0.0016016 , 0.00140095, 0.00200186, 0.00160193, 0.00140123,\n",
      "       0.00140157, 0.00140147, 0.0016016 , 0.00180173, 0.00200205,\n",
      "       0.00201263, 0.00240226, 0.00180163, 0.00120111, 0.00180159,\n",
      "       0.00160136, 0.00211105, 0.00260248, 0.00200191, 0.00260224,\n",
      "       0.00280261, 0.00120091, 0.00140142, 0.00180206, 0.00240211,\n",
      "       0.00260186, 0.00220218, 0.0030026 , 0.00311117, 0.00340333,\n",
      "       0.0012013 , 0.00180197, 0.00220218, 0.00251203, 0.0030026 ,\n",
      "       0.00320311, 0.00360322, 0.00400324, 0.00431089, 0.00160136,\n",
      "       0.00200191, 0.00260258, 0.00300269, 0.00340314, 0.00440383,\n",
      "       0.0044035 , 0.00500417, 0.00540514, 0.00150857, 0.00280242,\n",
      "       0.00280252, 0.00320311, 0.00400348, 0.00480437, 0.00540466,\n",
      "       0.00600591, 0.00600572, 0.00100093, 0.00100045, 0.00100121,\n",
      "       0.00100088, 0.00120111, 0.00119672, 0.00120139, 0.0012013 ,\n",
      "       0.00180154, 0.00100102, 0.00100117, 0.00100136, 0.00140157,\n",
      "       0.00120134, 0.00120106, 0.00140157, 0.00160141, 0.00160165,\n",
      "       0.00140119, 0.00140123, 0.00120125, 0.00100088, 0.00140119,\n",
      "       0.00120101, 0.00160151, 0.00180202, 0.00190768, 0.00100164,\n",
      "       0.00100107, 0.00180178, 0.00140166, 0.00140133, 0.00160122,\n",
      "       0.00140147, 0.00180154, 0.00180168, 0.00100098, 0.00100141,\n",
      "       0.00100079, 0.00120091, 0.00160127, 0.00120101, 0.00180187,\n",
      "       0.002002  , 0.00200181, 0.00100117, 0.00140138, 0.00140119,\n",
      "       0.00160155, 0.00160151, 0.00160165, 0.00180182, 0.00180144,\n",
      "       0.00201297, 0.00100074, 0.00100121, 0.00160127, 0.00140152,\n",
      "       0.00180187, 0.00200171, 0.00200195, 0.00200167, 0.00220213,\n",
      "       0.00100079, 0.00100083, 0.00140128, 0.00160146, 0.00160131,\n",
      "       0.00200214, 0.00200157, 0.00200219, 0.00200176, 0.00120125,\n",
      "       0.00100117, 0.00120101, 0.00140142, 0.00180173, 0.0018013 ,\n",
      "       0.00220208, 0.00210953, 0.00260205, 0.00100112, 0.0012012 ,\n",
      "       0.00140157, 0.00140181, 0.00100064, 0.00120139, 0.00140157,\n",
      "       0.00120087, 0.00160127, 0.00120149, 0.00100098, 0.0012013 ,\n",
      "       0.00140176, 0.00120134, 0.00120139, 0.00120144, 0.00180221,\n",
      "       0.00160136, 0.00100064, 0.00100074, 0.00140157, 0.00120101,\n",
      "       0.00120153, 0.00140109, 0.00140133, 0.00180163, 0.00180244,\n",
      "       0.00100121, 0.00120115, 0.00120091, 0.0012012 , 0.00140166,\n",
      "       0.00140123, 0.00160155, 0.00140157, 0.0018014 , 0.00120158,\n",
      "       0.00140157, 0.00140138, 0.00120144, 0.00120096, 0.0020021 ,\n",
      "       0.0016016 , 0.00220222, 0.00220199, 0.00100083, 0.00180211,\n",
      "       0.00140152, 0.00160122, 0.00200162, 0.00200181, 0.00200162,\n",
      "       0.0024024 , 0.00260272, 0.00140119, 0.00140133, 0.00180197,\n",
      "       0.00200171, 0.00241203, 0.00220184, 0.00280261, 0.00300288,\n",
      "       0.00320334, 0.00160165, 0.00180187, 0.00200195, 0.00240221,\n",
      "       0.00260229, 0.0036036 , 0.00300331, 0.00340333, 0.00420408,\n",
      "       0.00180197, 0.00200224, 0.00260243, 0.00280266, 0.00360346,\n",
      "       0.00380354, 0.0042038 , 0.00460372, 0.00540495, 0.00100069,\n",
      "       0.00140085, 0.00160131, 0.00100112, 0.00100107, 0.00140109,\n",
      "       0.00100069, 0.00120096, 0.00120077, 0.00100112, 0.00100107,\n",
      "       0.00100102, 0.00120101, 0.00160184, 0.00140138, 0.00140142,\n",
      "       0.0014009 , 0.00180178, 0.00100093, 0.00120101, 0.00120115,\n",
      "       0.00140123, 0.00140147, 0.00180149, 0.00160155, 0.00180159,\n",
      "       0.00120144, 0.00120125, 0.00140114, 0.0016017 , 0.00100098,\n",
      "       0.00140138, 0.00140142, 0.00140138, 0.00200162, 0.00200181,\n",
      "       0.00120153, 0.00120091, 0.00180168, 0.0016016 , 0.00200181,\n",
      "       0.00160155, 0.00200176, 0.00200205, 0.00200181, 0.00100107,\n",
      "       0.00120091, 0.00120139, 0.00160141, 0.00140128, 0.00180144,\n",
      "       0.00200157, 0.00220242, 0.00220208, 0.00120096, 0.00100121,\n",
      "       0.00120106, 0.00140114, 0.00160117, 0.00200162, 0.00200181,\n",
      "       0.00240235, 0.00200124, 0.00120153, 0.0012012 , 0.00160155,\n",
      "       0.0016017 , 0.00180187, 0.00200171, 0.00200181, 0.00220156,\n",
      "       0.00280271, 0.00100074, 0.00140123, 0.00140171, 0.00140157,\n",
      "       0.00200195, 0.00220203, 0.00240231, 0.0022018 , 0.00260215,\n",
      "       0.00100141, 0.00100102, 0.00100107, 0.00100088, 0.00140133,\n",
      "       0.00100079, 0.00160217, 0.00120125, 0.00120111, 0.00100102,\n",
      "       0.00100074, 0.00140142, 0.00100088, 0.00120096, 0.00140142,\n",
      "       0.00140123, 0.00120101, 0.00160136, 0.00100088, 0.00140109,\n",
      "       0.00100088, 0.00140157, 0.00100045, 0.0012013 , 0.00140138,\n",
      "       0.00160127, 0.0018014 , 0.00100074, 0.00100079, 0.00120115,\n",
      "       0.00140166, 0.00140152, 0.00100093, 0.00180149, 0.00200195,\n",
      "       0.00180149, 0.00100088, 0.00160136, 0.00140162, 0.001401  ,\n",
      "       0.001401  , 0.00200129, 0.00200152, 0.0022018 , 0.00220232,\n",
      "       0.00140147, 0.001401  , 0.00140138, 0.00200219, 0.00200152,\n",
      "       0.00260229, 0.00240192, 0.00260234, 0.00220151, 0.00120134,\n",
      "       0.0012013 , 0.00200205, 0.00220203, 0.00220208, 0.0026022 ,\n",
      "       0.0030025 , 0.00340319, 0.00380325, 0.00140104, 0.00200138,\n",
      "       0.00220213, 0.00280252, 0.00300269, 0.00360398, 0.00380406,\n",
      "       0.00400352, 0.00480418, 0.00180173, 0.00200191, 0.00280247,\n",
      "       0.0030026 , 0.00380344, 0.00420356, 0.00460429, 0.00540118,\n",
      "       0.00600519, 0.0010006 , 0.00100121, 0.0012012 , 0.00100102,\n",
      "       0.00140123, 0.00120096, 0.00100112, 0.00140138, 0.0012012 ,\n",
      "       0.00100045, 0.00120106, 0.00140133, 0.00120082, 0.00140123,\n",
      "       0.00140157, 0.00140142, 0.00140138, 0.00160146, 0.00120111,\n",
      "       0.0014009 , 0.00140147, 0.00160141, 0.00120101, 0.00100126,\n",
      "       0.00160155, 0.0014008 , 0.00159597, 0.00120077, 0.00100112,\n",
      "       0.00100069, 0.00120111, 0.00100098, 0.0012012 , 0.00140128,\n",
      "       0.00140109, 0.00140104, 0.00100107, 0.00100064, 0.00160098,\n",
      "       0.00140123, 0.00160151, 0.00100055, 0.00140166, 0.00120139,\n",
      "       0.00140152, 0.00100093, 0.00100117, 0.00140152, 0.00120115,\n",
      "       0.00120096, 0.00100079, 0.00120101, 0.00160136, 0.00180168,\n",
      "       0.00100112, 0.0012013 , 0.00120091, 0.00120139, 0.00140042,\n",
      "       0.00200214, 0.00180197, 0.00180159, 0.00180116, 0.00100079,\n",
      "       0.00140157, 0.00160189, 0.00140152, 0.00140133, 0.00160222,\n",
      "       0.001401  , 0.0018014 , 0.00200181, 0.0012013 , 0.00100088,\n",
      "       0.00140119, 0.00120087, 0.00160141, 0.00200143, 0.00160155,\n",
      "       0.00200176, 0.00160136]), 'std_score_time': array([4.90193437e-04, 2.59661910e-04, 4.89706993e-04, 4.90465925e-04,\n",
      "       4.00233279e-04, 4.90602187e-04, 5.51978917e-07, 2.13248060e-07,\n",
      "       4.00257309e-04, 5.09122765e-07, 4.90388213e-04, 4.90407820e-04,\n",
      "       4.90466064e-04, 4.90174126e-04, 4.00328846e-04, 4.00114244e-04,\n",
      "       2.61174468e-07, 4.90329714e-04, 3.23406696e-07, 3.37174788e-07,\n",
      "       4.90466018e-04, 4.90427108e-04, 4.00161942e-04, 4.90174010e-04,\n",
      "       4.00638637e-04, 4.00257281e-04, 1.90734863e-07, 3.23406696e-07,\n",
      "       4.90251785e-04, 4.90251831e-04, 4.00495657e-04, 5.09122765e-07,\n",
      "       2.23541412e-04, 3.50402318e-07, 8.12024420e-07, 4.90057163e-04,\n",
      "       4.90641538e-04, 4.90407565e-04, 4.00567917e-04, 3.16297988e-07,\n",
      "       3.99875897e-04, 3.23406696e-07, 4.00376643e-04, 6.74349576e-07,\n",
      "       4.90349449e-04, 4.00328675e-04, 4.00567179e-04, 4.00471840e-04,\n",
      "       5.91739352e-07, 4.90252109e-04, 4.90427038e-04, 4.90096135e-04,\n",
      "       2.61174468e-07, 2.43998016e-04, 4.00471726e-04, 3.99732661e-04,\n",
      "       4.00567349e-04, 4.90758037e-04, 4.42200589e-07, 4.00066631e-04,\n",
      "       5.30983387e-07, 3.23406696e-07, 3.23406696e-07, 4.00209810e-04,\n",
      "       1.50789149e-07, 3.16297988e-07, 6.57274664e-07, 3.92523776e-04,\n",
      "       4.90485525e-04, 4.90115569e-04, 4.00281730e-04, 1.78416128e-07,\n",
      "       4.90271296e-04, 3.16297988e-07, 4.89901661e-04, 4.90602674e-04,\n",
      "       4.90485502e-04, 4.00638694e-04, 4.90407936e-04, 4.00233450e-04,\n",
      "       4.00805569e-04, 2.43140197e-07, 6.32595976e-07, 3.99994975e-04,\n",
      "       6.32595976e-07, 4.00376614e-04, 4.00424099e-04, 4.00352478e-04,\n",
      "       4.00424043e-04, 4.00567832e-04, 4.00233365e-04, 4.90466180e-04,\n",
      "       4.90407635e-04, 4.00567264e-04, 4.90446538e-04, 4.90563408e-04,\n",
      "       4.00328931e-04, 4.00257480e-04, 4.90446538e-04, 4.90349380e-04,\n",
      "       4.90290765e-04, 4.00090342e-04, 4.90504921e-04, 4.00233365e-04,\n",
      "       4.90096066e-04, 4.90427108e-04, 4.90388305e-04, 4.90582726e-04,\n",
      "       4.00304837e-04, 4.90427038e-04, 4.00281332e-04, 4.00328647e-04,\n",
      "       4.90271528e-04, 4.90485641e-04, 5.35248383e-07, 4.00161942e-04,\n",
      "       6.57274664e-07, 4.90251808e-04, 4.90096228e-04, 4.00471726e-04,\n",
      "       4.90485479e-04, 3.23406696e-07, 4.90271273e-04, 3.37174788e-07,\n",
      "       4.90290788e-04, 2.33601546e-07, 4.90174173e-04, 4.00185596e-04,\n",
      "       4.00424043e-04, 4.90290765e-04, 7.89305942e-07, 4.00471755e-04,\n",
      "       4.00328959e-04, 4.00019161e-04, 4.90115709e-04, 4.00209555e-04,\n",
      "       4.90135030e-04, 4.26496120e-07, 3.99995117e-04, 4.00614806e-04,\n",
      "       4.90290857e-04, 7.48965485e-04, 4.42200589e-07, 7.49246256e-04,\n",
      "       4.90349125e-04, 4.00447874e-04, 7.16843432e-07, 4.90524366e-04,\n",
      "       4.90271389e-04, 4.90641306e-04, 4.00090569e-04, 3.99565878e-04,\n",
      "       4.00567094e-04, 4.90290927e-04, 3.99995117e-04, 4.00257281e-04,\n",
      "       4.00614777e-04, 4.00424383e-04, 4.00448044e-04, 4.00829514e-04,\n",
      "       4.90582819e-04, 8.01134244e-04, 4.00304809e-04, 3.87384339e-07,\n",
      "       2.26521561e-04, 4.90096692e-04, 4.00257196e-04, 4.00472039e-04,\n",
      "       3.99780586e-04, 4.00376473e-04, 4.89998815e-04, 2.78041453e-07,\n",
      "       4.90349449e-04, 4.90349171e-04, 4.00328789e-04, 4.00758056e-04,\n",
      "       4.90446677e-04, 4.90115848e-04, 3.98950589e-07, 4.90368586e-04,\n",
      "       3.50402318e-07, 3.81469727e-07, 4.00471783e-04, 4.90349148e-04,\n",
      "       4.00161800e-04, 4.89920871e-04, 4.90251878e-04, 1.78416128e-07,\n",
      "       2.13248060e-07, 4.62310777e-07, 4.00066688e-04, 4.90310284e-04,\n",
      "       4.90232695e-04, 5.51978917e-07, 4.62310777e-07, 2.78041453e-07,\n",
      "       4.90583305e-04, 1.90734863e-07, 3.23406696e-07, 4.00376586e-04,\n",
      "       4.90329691e-04, 4.90504921e-04, 6.14361702e-07, 4.90154449e-04,\n",
      "       4.90582726e-04, 4.90602998e-04, 4.00471953e-04, 4.15696997e-07,\n",
      "       4.00495941e-04, 9.53674316e-08, 3.01578299e-07, 4.89862720e-04,\n",
      "       4.00209555e-04, 4.90037857e-04, 4.90427061e-04, 4.00757970e-04,\n",
      "       4.90466064e-04, 4.90076682e-04, 4.00757829e-04, 6.50319180e-07,\n",
      "       4.00257338e-04, 4.00686448e-04, 4.00352847e-04, 4.42200589e-07,\n",
      "       4.00209896e-04, 4.90349310e-04, 4.00281162e-04, 3.81469727e-07,\n",
      "       4.89979404e-04, 4.89784907e-04, 3.23406696e-07, 4.00138253e-04,\n",
      "       4.90738661e-04, 4.00662603e-04, 4.90349194e-04, 3.99780643e-04,\n",
      "       4.89881945e-04, 4.90407658e-04, 4.90757968e-04, 4.00185795e-04,\n",
      "       4.00066518e-04, 4.90563292e-04, 7.49411620e-04, 4.00114102e-04,\n",
      "       4.90368956e-04, 4.00209725e-04, 4.00495657e-04, 4.90543862e-04,\n",
      "       2.33601546e-07, 4.00209612e-04, 6.28991411e-07, 4.90174034e-04,\n",
      "       4.10190833e-07, 4.00305178e-04, 4.00353018e-04, 4.90660964e-04,\n",
      "       4.90212867e-04, 4.90368725e-04, 4.90193413e-04, 4.90154611e-04,\n",
      "       4.90076984e-04, 4.90466203e-04, 4.00066489e-04, 4.00185624e-04,\n",
      "       4.90310237e-04, 4.00376473e-04, 4.00328675e-04, 4.90368655e-04,\n",
      "       4.90349171e-04, 4.00662631e-04, 1.78416128e-07, 4.90622509e-04,\n",
      "       4.00519382e-04, 4.90641422e-04, 4.00686505e-04, 4.90212959e-04,\n",
      "       4.00400573e-04, 4.00257593e-04, 4.90329691e-04, 4.00472181e-04,\n",
      "       4.00519552e-04, 4.00114130e-04, 4.90466111e-04, 3.98950589e-07,\n",
      "       4.90018322e-04, 1.78416128e-07, 3.50402318e-07, 3.56832255e-07,\n",
      "       4.00281134e-04, 7.59953377e-07, 4.90466273e-04, 4.00424298e-04,\n",
      "       5.00111031e-07, 5.43678010e-07, 3.99208211e-04, 4.00710400e-04,\n",
      "       4.00471755e-04, 4.00447874e-04, 4.00424043e-04, 4.01020135e-04,\n",
      "       4.89901498e-04, 5.43678010e-07, 1.10806942e-06, 4.00185681e-04,\n",
      "       4.90427177e-04, 4.86280395e-07, 4.00424128e-04, 4.90407612e-04,\n",
      "       4.90115755e-04, 4.00567406e-04, 5.22348936e-07, 4.00090342e-04,\n",
      "       7.48850727e-04, 4.00066489e-04, 4.90388166e-04, 4.00114130e-04,\n",
      "       4.90115593e-04, 4.26496120e-07, 4.00424270e-04, 4.90115662e-04,\n",
      "       4.00161885e-04, 4.26496120e-07, 6.50319180e-07, 4.90310237e-04,\n",
      "       4.00447931e-04, 4.00972749e-04, 4.00614834e-04, 5.00111031e-07,\n",
      "       4.00185624e-04, 5.09122765e-07, 4.00233507e-04, 4.90349125e-04,\n",
      "       4.00853423e-04, 1.16800773e-07, 4.00567094e-04, 4.00281418e-04,\n",
      "       4.00018820e-04, 4.00185681e-04, 4.90388050e-04, 4.00161914e-04,\n",
      "       4.00781674e-04, 4.00495657e-04, 3.23406696e-07, 4.00734317e-04,\n",
      "       4.90388189e-04, 4.00328817e-04, 5.35248383e-07, 5.00111031e-07,\n",
      "       4.00495998e-04, 4.42200589e-07, 4.90465925e-04, 5.35248383e-07,\n",
      "       3.87384339e-07, 3.23406696e-07, 4.90310237e-04, 4.90252202e-04,\n",
      "       4.90544349e-04, 4.15696997e-07, 3.99947376e-04, 4.00424043e-04,\n",
      "       1.18637756e-04, 4.89998954e-04, 4.90310933e-04, 4.90660686e-04,\n",
      "       1.50789149e-07, 3.23406696e-07, 4.85945270e-04, 4.00257537e-04,\n",
      "       2.33601546e-07, 2.61174468e-07, 4.00543667e-04, 4.90427084e-04,\n",
      "       1.78416128e-07, 4.90310191e-04, 4.00161800e-04, 4.90193437e-04,\n",
      "       8.00323501e-04, 4.00400290e-04, 4.00352677e-04, 4.90310284e-04,\n",
      "       4.00638921e-04, 4.90446630e-04, 4.00757970e-04, 3.01578299e-07,\n",
      "       2.78041453e-07, 4.42200589e-07, 4.90271342e-04, 2.43140197e-07,\n",
      "       4.00185709e-04, 4.90446607e-04, 4.03540371e-04, 4.90680278e-04,\n",
      "       4.76837158e-07, 2.13248060e-07, 1.78416128e-07, 4.00662546e-04,\n",
      "       4.90543839e-04, 2.78041453e-07, 4.90290742e-04, 4.00233279e-04,\n",
      "       3.23406696e-07, 6.33163681e-04, 4.90505500e-04, 7.49284089e-04,\n",
      "       4.90057302e-04, 7.16843432e-07, 3.50402318e-07, 4.00471982e-04,\n",
      "       4.05532479e-04, 4.00352563e-04, 4.00090342e-04, 4.00018763e-04,\n",
      "       2.61174468e-07, 4.00495657e-04, 4.90933902e-07, 4.90329760e-04,\n",
      "       4.90699527e-04, 4.90933902e-07, 4.90349125e-04, 4.90505060e-04,\n",
      "       4.00161885e-04, 4.90135100e-04, 4.05839044e-04, 6.97552626e-07,\n",
      "       4.00424355e-04, 4.00543639e-04, 4.00424128e-04, 4.00352648e-04,\n",
      "       1.84059328e-04, 4.00352506e-04, 4.62310777e-07, 4.90407635e-04,\n",
      "       4.62310777e-07, 4.90524343e-04, 4.90660640e-04, 4.90427131e-04,\n",
      "       4.00567605e-04, 4.10190833e-07, 7.83523403e-07, 6.33012928e-04,\n",
      "       3.16297988e-07, 3.50402318e-07, 4.00471982e-04, 4.90505013e-04,\n",
      "       3.99995031e-04, 4.90524366e-04, 1.78416128e-07, 4.00591138e-04,\n",
      "       4.00328931e-04, 4.00400517e-04, 4.90621930e-04, 4.00114102e-04,\n",
      "       4.89998792e-04, 4.89979335e-04, 4.10190833e-07, 4.00590968e-04,\n",
      "       4.90096205e-04, 4.90797056e-04, 1.90734863e-07, 4.00114187e-04,\n",
      "       4.90543839e-04, 4.90252341e-04, 5.56082906e-07, 6.46813391e-07,\n",
      "       4.90660825e-04, 2.78041453e-07, 4.00567094e-04, 4.90193715e-04,\n",
      "       4.00567236e-04, 4.90310330e-04, 4.00447931e-04, 4.00400318e-04,\n",
      "       4.90757945e-04, 3.69356475e-07, 4.00471982e-04, 8.60951905e-07,\n",
      "       4.90933902e-07, 4.90349125e-04, 4.90252017e-04, 4.10190833e-07,\n",
      "       4.90485456e-04, 4.10190833e-07, 2.13248060e-07, 4.90582865e-04,\n",
      "       2.78041453e-07, 4.00114187e-04, 4.67203091e-07, 8.31393994e-07,\n",
      "       4.00233393e-04, 4.00495600e-04, 4.00638637e-04, 4.00066575e-04,\n",
      "       4.00781674e-04, 4.90563315e-04, 4.90212936e-04, 9.60800251e-07,\n",
      "       4.00615657e-04, 4.00471840e-04, 4.00567094e-04, 4.90174173e-04,\n",
      "       4.90037671e-04, 4.90563547e-04, 4.90310284e-04, 4.90057163e-04,\n",
      "       4.00495572e-04, 4.85526370e-04, 4.90466111e-04, 4.90446468e-04,\n",
      "       4.00138054e-04, 4.90563292e-04, 4.89901591e-04, 4.90855277e-04,\n",
      "       4.67203091e-07, 4.89979335e-04, 4.90135448e-04, 4.90349310e-04,\n",
      "       4.90427061e-04, 4.90972077e-04, 4.00185880e-04, 7.59953377e-07,\n",
      "       2.16252880e-05, 4.90310237e-04, 4.00614948e-04, 4.00328789e-04,\n",
      "       4.00233421e-04, 4.90193437e-04, 2.18463328e-04, 4.90680070e-04,\n",
      "       5.76164530e-07, 4.90485456e-04, 4.00424213e-04, 4.00424270e-04,\n",
      "       4.90660802e-04, 4.00710287e-04, 4.90232417e-04, 4.90271574e-04,\n",
      "       4.00471726e-04, 2.78041453e-07, 4.79652685e-04, 4.90057302e-04,\n",
      "       3.99995372e-04, 4.00424043e-04, 4.00352563e-04, 4.48269218e-04,\n",
      "       3.50402318e-07, 4.00328704e-04, 4.90368817e-04, 3.81469727e-07,\n",
      "       4.04312203e-04, 4.90582958e-04, 4.90933902e-07, 4.90368910e-04,\n",
      "       3.81469727e-07, 4.90213029e-04, 4.90271412e-04, 4.89862534e-04,\n",
      "       5.00111031e-07, 4.90115569e-04, 4.47595857e-04, 4.00686562e-04,\n",
      "       4.00018848e-04, 4.00209583e-04, 3.50402318e-07, 4.00424128e-04,\n",
      "       4.90894357e-04, 2.43140197e-07, 6.10649513e-07, 2.78041453e-07,\n",
      "       2.78041453e-07, 8.34124359e-07, 3.98950589e-07, 3.99971065e-04,\n",
      "       4.03094387e-04, 4.00185709e-04, 4.00472010e-04, 4.00209725e-04,\n",
      "       3.23406696e-07, 5.91739352e-07, 2.13248060e-07, 4.90349217e-04,\n",
      "       4.00090512e-04, 4.00233450e-04, 4.89960067e-04, 4.90329760e-04,\n",
      "       4.90427270e-04, 4.90271273e-04, 4.90037741e-04, 4.00018735e-04,\n",
      "       2.13248060e-07, 4.90174265e-04, 4.00018848e-04, 4.90407820e-04,\n",
      "       4.00328846e-04, 1.88160547e-04, 3.16297988e-07, 2.78041453e-07,\n",
      "       4.00209725e-04, 4.90660593e-04, 4.90446491e-04, 4.90271667e-04,\n",
      "       4.90232370e-04, 4.00567179e-04, 4.00280992e-04, 3.87384339e-07,\n",
      "       5.51978917e-07, 4.15696997e-07, 4.00424355e-04, 4.90310237e-04,\n",
      "       4.00376387e-04, 4.00734004e-04, 2.61174468e-07, 4.62310777e-07,\n",
      "       3.50402318e-07, 4.90407797e-04, 4.90466064e-04, 4.89959881e-04,\n",
      "       4.90115569e-04, 4.90719289e-04, 4.00471755e-04, 4.00161828e-04,\n",
      "       2.22989572e-05, 4.15696997e-07, 1.90734863e-07, 4.90018253e-04,\n",
      "       4.90485502e-04, 4.00376700e-04, 5.09122765e-07, 2.78041453e-07,\n",
      "       3.56832255e-07, 4.00018962e-04, 3.56832255e-07, 1.78416128e-07,\n",
      "       4.90388097e-04, 4.90174173e-04, 4.89862604e-04, 1.90734863e-07,\n",
      "       4.86280395e-07, 4.62310777e-07, 2.61174468e-07, 4.00257224e-04,\n",
      "       4.62310777e-07, 4.00614834e-04, 4.90271319e-04, 4.00424043e-04,\n",
      "       4.00567207e-04, 3.99923623e-04, 2.15292109e-04, 4.90913694e-04,\n",
      "       3.98950589e-07, 4.00638609e-04, 4.90057117e-04, 4.90251970e-04,\n",
      "       3.98950589e-07, 4.00066575e-04, 4.90835997e-04, 4.00328846e-04,\n",
      "       4.90018206e-04, 4.00257167e-04, 2.43140197e-07, 4.00710457e-04,\n",
      "       4.90388143e-04, 4.00328760e-04, 4.00424071e-04, 4.00877041e-04,\n",
      "       4.00662830e-04, 4.90290718e-04, 7.53945746e-07, 1.90734863e-07,\n",
      "       4.90738476e-04, 4.00376700e-04, 4.00353018e-04, 4.90349356e-04,\n",
      "       4.90446515e-04, 4.00376529e-04, 4.00543582e-04, 4.67203091e-07,\n",
      "       4.00781702e-04, 4.00424469e-04, 4.00877580e-04, 4.90368817e-04,\n",
      "       4.90037718e-04, 4.90251878e-04, 4.90349264e-04, 4.00137940e-04,\n",
      "       4.00686505e-04, 4.90349217e-04, 4.90407681e-04, 4.00519467e-04,\n",
      "       4.00400290e-04, 3.56832255e-07, 4.89999186e-04, 4.00328846e-04,\n",
      "       4.00328789e-04, 4.10190833e-07, 4.00257253e-04, 4.90388050e-04,\n",
      "       4.90563501e-04, 4.90933902e-07, 2.78041453e-07, 3.23406696e-07,\n",
      "       4.90485502e-04, 4.90485479e-04, 4.90465925e-04, 4.90252434e-04,\n",
      "       4.00424128e-04, 5.09122765e-07, 5.03110779e-04, 4.00161970e-04,\n",
      "       4.00424213e-04, 6.33012849e-04, 4.00686562e-04, 4.90232556e-04,\n",
      "       4.00138111e-04, 9.53674316e-08, 4.90251831e-04, 4.90427131e-04,\n",
      "       4.89998745e-04, 1.78416128e-07, 4.90154518e-04, 4.00400573e-04,\n",
      "       4.00066518e-04, 6.91002691e-07, 4.90543908e-04, 4.00209555e-04,\n",
      "       4.90271458e-04, 4.00209498e-04, 4.00781674e-04, 4.90544071e-04,\n",
      "       4.90563640e-04, 2.78041453e-07, 4.90446607e-04, 4.90251831e-04,\n",
      "       4.26496120e-07, 4.86280395e-07, 4.90057302e-04, 5.72204590e-07,\n",
      "       4.00638836e-04, 4.00614806e-04, 3.01578299e-07, 4.10190833e-07,\n",
      "       5.56082906e-07, 4.00138111e-04, 4.90193761e-04, 4.90504921e-04,\n",
      "       4.90368678e-04, 4.90115662e-04, 4.00448215e-04, 4.10190833e-07,\n",
      "       4.00137997e-04, 4.00424043e-04, 4.90621860e-04, 4.90524598e-04,\n",
      "       4.00305206e-04, 4.90252156e-04, 4.00114301e-04, 4.00162112e-04,\n",
      "       4.00257167e-04, 4.90504874e-04, 4.89784651e-04, 4.15696997e-07,\n",
      "       4.90115569e-04, 4.90660732e-04, 4.90018485e-04, 3.23406696e-07,\n",
      "       4.10190833e-07, 4.00471897e-04, 4.00066461e-04, 4.00519467e-04,\n",
      "       4.89998815e-04, 2.78041453e-07, 4.90349217e-04, 5.64201334e-07,\n",
      "       1.78416128e-07, 2.78041453e-07, 6.28991411e-07, 4.00066489e-04,\n",
      "       4.00066461e-04, 4.90330154e-04, 4.90388213e-04, 4.00400318e-04,\n",
      "       3.81469727e-07, 4.00233393e-04, 4.00519382e-04, 4.00400290e-04,\n",
      "       5.76164530e-07, 4.00233535e-04, 4.90699620e-04, 4.90816930e-04,\n",
      "       5.56082906e-07, 4.10190833e-07, 4.90135123e-04, 2.78041453e-07,\n",
      "       4.00352478e-04, 4.00519524e-04, 4.90349240e-04, 4.90271273e-04,\n",
      "       4.00018763e-04, 6.28991411e-07, 3.16297988e-07, 4.00424270e-04,\n",
      "       3.99994918e-04, 4.67203091e-07, 4.90135146e-04, 4.89940362e-04,\n",
      "       4.90154518e-04, 4.10190833e-07, 4.00185908e-04, 4.90660964e-04,\n",
      "       4.00662603e-04, 4.90505013e-04, 4.62310777e-07, 2.86102295e-07,\n",
      "       4.62310777e-07, 6.21719590e-07, 4.90154565e-04, 6.32595976e-07,\n",
      "       4.90174150e-04, 4.00018763e-04, 4.00328846e-04, 5.13569337e-07,\n",
      "       5.35248383e-07, 4.90563640e-04, 4.26496120e-07, 4.00161772e-04,\n",
      "       4.90563269e-04, 4.89649481e-04, 4.00376785e-04, 4.90874769e-04,\n",
      "       2.61174468e-07, 4.90349125e-04, 4.26496120e-07, 4.89959997e-04,\n",
      "       6.46813391e-07, 4.00233478e-04, 4.90505292e-04, 4.90505060e-04,\n",
      "       4.00495884e-04, 1.16800773e-07, 4.42200589e-07, 4.00304951e-04,\n",
      "       4.90563408e-04, 4.90193576e-04, 1.78416128e-07, 4.00543355e-04,\n",
      "       2.78041453e-07, 4.00066518e-04, 2.13248060e-07, 4.90096205e-04,\n",
      "       4.90310214e-04, 4.90427200e-04, 4.90524320e-04, 3.98950589e-07,\n",
      "       5.00111031e-07, 3.99828000e-04, 4.00042630e-04, 4.90232370e-04,\n",
      "       4.90329899e-04, 4.90018183e-04, 5.09122765e-07, 6.57274664e-07,\n",
      "       4.90427455e-04, 4.90485572e-04, 4.90271342e-04, 4.00686335e-04,\n",
      "       4.00448044e-04, 4.00352961e-04, 3.50402318e-07, 4.00662688e-04,\n",
      "       4.00281134e-04, 4.90544024e-04, 8.34124359e-07, 4.90660686e-04,\n",
      "       4.00424071e-04, 4.90290904e-04, 5.35248383e-07, 4.00972522e-04,\n",
      "       4.00137940e-04, 2.78041453e-07, 4.90212959e-04, 4.00352535e-04,\n",
      "       3.37174788e-07, 4.00090740e-04, 4.00424128e-04, 1.90734863e-07,\n",
      "       3.99995657e-04, 2.33601546e-07, 4.00638637e-04, 4.00543326e-04,\n",
      "       4.90037718e-04, 4.86461744e-04, 3.87384339e-07, 8.44957597e-07,\n",
      "       8.74056949e-07, 4.00281332e-04, 5.13569337e-07, 4.90329691e-04,\n",
      "       4.00280992e-04, 5.43678010e-07, 4.90602187e-04, 4.00281219e-04,\n",
      "       4.10190833e-07, 4.00352506e-04, 4.90349125e-04, 3.99876408e-04,\n",
      "       4.90427084e-04, 4.90446491e-04, 4.89882061e-04, 4.90310214e-04,\n",
      "       4.90563269e-04, 4.00567349e-04, 4.90115709e-04, 4.90427038e-04,\n",
      "       4.90135216e-04, 3.99899550e-04, 9.84180805e-07, 4.89862557e-04,\n",
      "       4.90777626e-04, 4.85804262e-04, 4.00376785e-04, 1.50789149e-07,\n",
      "       4.37028474e-07, 4.00328732e-04, 6.14361702e-07, 4.00638609e-04,\n",
      "       4.90193437e-04, 4.90251831e-04, 4.89998815e-04, 3.81469727e-07,\n",
      "       7.83523403e-07, 4.90271319e-04, 4.90135170e-04, 4.90602257e-04,\n",
      "       3.23406696e-07, 4.90271319e-04, 3.99708986e-04, 4.89901498e-04,\n",
      "       9.70220087e-07, 1.78416128e-07, 4.90290718e-04, 4.00543582e-04,\n",
      "       4.00280992e-04, 4.42200589e-07, 4.00496792e-04, 4.90582772e-04,\n",
      "       4.00519637e-04, 2.13248060e-07, 4.00352563e-04, 4.00304809e-04,\n",
      "       4.00781674e-04, 4.90410231e-04, 4.15696997e-07, 4.00305036e-04,\n",
      "       4.00352677e-04, 4.00495770e-04, 2.43140197e-07, 4.90544117e-04,\n",
      "       4.90427084e-04, 4.90290857e-04, 4.90154565e-04, 4.90115593e-04,\n",
      "       4.89940548e-04, 4.00018735e-04, 5.30983387e-07, 4.00233308e-04,\n",
      "       4.76837158e-07, 4.90466018e-04, 4.00209498e-04, 4.90037718e-04,\n",
      "       2.43140197e-07, 4.90154518e-04, 3.01578299e-07, 4.89998722e-04]), 'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_loss': masked_array(data=['squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'squared_error',\n",
      "                   'squared_error', 'squared_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'absolute_error',\n",
      "                   'absolute_error', 'absolute_error', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'huber', 'huber', 'huber', 'huber', 'huber',\n",
      "                   'huber', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile', 'quantile', 'quantile',\n",
      "                   'quantile', 'quantile'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "                   7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "                   9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900, 100, 200, 300, 400, 500, 600, 700,\n",
      "                   800, 900, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
      "                   100, 200, 300, 400, 500, 600, 700, 800, 900, 100, 200,\n",
      "                   300, 400, 500, 600, 700, 800, 900, 100, 200, 300, 400,\n",
      "                   500, 600, 700, 800, 900, 100, 200, 300, 400, 500, 600,\n",
      "                   700, 800, 900, 100, 200, 300, 400, 500, 600, 700, 800,\n",
      "                   900, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100,\n",
      "                   200, 300, 400, 500, 600, 700, 800, 900, 100, 200, 300,\n",
      "                   400, 500, 600, 700, 800, 900, 100, 200, 300, 400, 500,\n",
      "                   600, 700, 800, 900],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.1, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.01, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'squared_error', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'absolute_error', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'huber', 'max_depth': 9, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 1, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 2, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 3, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 4, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 5, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 6, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 7, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 8, 'n_estimators': 900}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 100}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 200}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 300}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 400}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 500}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 600}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 700}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 800}, {'learning_rate': 0.001, 'loss': 'quantile', 'max_depth': 9, 'n_estimators': 900}], 'split0_test_score': array([-0.0044533 , -0.00326418, -0.00298344, -0.00285064, -0.00275298,\n",
      "       -0.00270751, -0.00266776, -0.00263423, -0.00260227, -0.00299592,\n",
      "       -0.00149568, -0.0084533 , -0.00828713, -0.00751738, -0.01009029,\n",
      "       -0.00744083, -0.00668949, -0.01504938, -0.00126423, -0.00131744,\n",
      "       -0.00207659, -0.00180957, -0.0074288 , -0.00110271, -0.00128443,\n",
      "       -0.00153815, -0.0009837 , -0.00217764, -0.00384438, -0.00504986,\n",
      "       -0.00263226, -0.00532959, -0.0030888 , -0.00204093, -0.00311394,\n",
      "       -0.00271599, -0.00234809, -0.00255148, -0.00237737, -0.00226242,\n",
      "       -0.00226054, -0.00240689, -0.00251057, -0.0024551 , -0.00234088,\n",
      "       -0.00288919, -0.00267893, -0.00282977, -0.00254373, -0.0026982 ,\n",
      "       -0.00300153, -0.00269928, -0.00295231, -0.00282844, -0.00374779,\n",
      "       -0.00399667, -0.00372748, -0.00377737, -0.00400059, -0.00370126,\n",
      "       -0.00378208, -0.00411323, -0.00403826, -0.00557136, -0.00583301,\n",
      "       -0.00565206, -0.00581748, -0.00594482, -0.00576674, -0.0056707 ,\n",
      "       -0.00581217, -0.00612947, -0.00844566, -0.0082007 , -0.00765881,\n",
      "       -0.00806695, -0.00751574, -0.00769197, -0.00769084, -0.0084507 ,\n",
      "       -0.00878071, -0.00893134, -0.00288566, -0.00275764, -0.00266488,\n",
      "       -0.00264925, -0.00259288, -0.00260733, -0.00250801, -0.00251271,\n",
      "       -0.00273073, -0.00196203, -0.00225208, -0.0021129 , -0.00253855,\n",
      "       -0.00204068, -0.00249686, -0.00290153, -0.00234726, -0.00208093,\n",
      "       -0.0020965 , -0.00192598, -0.00188688, -0.00153869, -0.00167188,\n",
      "       -0.00202278, -0.00176741, -0.00177876, -0.00198499, -0.00288998,\n",
      "       -0.00277554, -0.00214153, -0.00272627, -0.00238846, -0.00322657,\n",
      "       -0.0021698 , -0.00253646, -0.00280252, -0.01331723, -0.00211728,\n",
      "       -0.00625763, -0.00297239, -0.00310737, -0.00303737, -0.00215127,\n",
      "       -0.00233379, -0.00251165, -0.00249594, -0.00210475, -0.00259394,\n",
      "       -0.00252652, -0.0014993 , -0.00773283, -0.00212525, -0.00241848,\n",
      "       -0.00221385, -0.00259547, -0.00426205, -0.00479637, -0.00252954,\n",
      "       -0.00201885, -0.00223653, -0.00213241, -0.00450309, -0.00262215,\n",
      "       -0.00173745, -0.00235749, -0.01340408, -0.00286955, -0.00277541,\n",
      "       -0.00354801, -0.0026173 , -0.00243513, -0.0015874 , -0.00203411,\n",
      "       -0.00234052, -0.0019334 , -0.00223583, -0.00267838, -0.00194692,\n",
      "       -0.0057014 , -0.00205128, -0.00354987, -0.00271833, -0.00252289,\n",
      "       -0.00236172, -0.00223304, -0.00217225, -0.00213183, -0.00209639,\n",
      "       -0.00207436, -0.00304311, -0.00273247, -0.00228124, -0.0022224 ,\n",
      "       -0.00213488, -0.0021246 , -0.00218338, -0.00217508, -0.00217698,\n",
      "       -0.00306745, -0.00285224, -0.00270306, -0.00268896, -0.00264018,\n",
      "       -0.00264003, -0.00266995, -0.00252328, -0.00275037, -0.00299056,\n",
      "       -0.00258841, -0.00265588, -0.00290742, -0.0026542 , -0.00323179,\n",
      "       -0.0028298 , -0.00258619, -0.00282457, -0.00299586, -0.00270296,\n",
      "       -0.00248354, -0.00269107, -0.00266512, -0.00272979, -0.00279388,\n",
      "       -0.00356094, -0.00288672, -0.00472976, -0.00323789, -0.00439591,\n",
      "       -0.00267229, -0.00322062, -0.00468855, -0.00341819, -0.00331059,\n",
      "       -0.00493384, -0.00445447, -0.0036705 , -0.00464532, -0.0038485 ,\n",
      "       -0.0045786 , -0.0043603 , -0.00722443, -0.00442796, -0.00440562,\n",
      "       -0.00466706, -0.00529467, -0.00539245, -0.00641981, -0.00578568,\n",
      "       -0.0056162 , -0.00625439, -0.00576759, -0.00753092, -0.00954707,\n",
      "       -0.00692531, -0.00746311, -0.00587902, -0.0060403 , -0.00886573,\n",
      "       -0.00695613, -0.00750694, -0.00779068, -0.01925834, -0.01721109,\n",
      "       -0.01721109, -0.01672562, -0.01721109, -0.01721109, -0.01672562,\n",
      "       -0.01721109, -0.01721109, -0.01386674, -0.00985539, -0.01000994,\n",
      "       -0.01312935, -0.00845206, -0.01314742, -0.00908874, -0.01537409,\n",
      "       -0.01209408, -0.01814591, -0.00897468, -0.00865788, -0.00717055,\n",
      "       -0.00738682, -0.00755659, -0.0118968 , -0.01915703, -0.01837728,\n",
      "       -0.00677951, -0.00832255, -0.01709559, -0.01234293, -0.00733676,\n",
      "       -0.01771672, -0.00784412, -0.00837362, -0.00731881, -0.00850037,\n",
      "       -0.00593738, -0.00681491, -0.00779773, -0.0056179 , -0.0130634 ,\n",
      "       -0.00763677, -0.00671398, -0.00797774, -0.00898025, -0.00603355,\n",
      "       -0.00814951, -0.00884207, -0.00759781, -0.00499758, -0.00416657,\n",
      "       -0.00908884, -0.00464502, -0.01128928, -0.00714415, -0.00884067,\n",
      "       -0.01221207, -0.00571483, -0.00698772, -0.00488029, -0.00666817,\n",
      "       -0.01046704, -0.01022269, -0.00947405, -0.00748317, -0.01453655,\n",
      "       -0.00974424, -0.00659662, -0.00932431, -0.00942456, -0.0062215 ,\n",
      "       -0.00727444, -0.01259123, -0.00843277, -0.00579151, -0.00618151,\n",
      "       -0.00674745, -0.00705221, -0.00699323, -0.00728655, -0.15372356,\n",
      "       -0.07888775, -0.04264976, -0.02534801, -0.01619825, -0.01119155,\n",
      "       -0.00823187, -0.00630435, -0.00515839, -0.06717956, -0.01911162,\n",
      "       -0.01098778, -0.00913561, -0.00723815, -0.00756735, -0.00512506,\n",
      "       -0.00685802, -0.00760642, -0.0501167 , -0.01121222, -0.0051816 ,\n",
      "       -0.00429019, -0.00332924, -0.00250695, -0.00438937, -0.00436125,\n",
      "       -0.00464147, -0.04713686, -0.0099008 , -0.00403098, -0.00358831,\n",
      "       -0.00344691, -0.00377701, -0.00348315, -0.00311163, -0.00337893,\n",
      "       -0.04456578, -0.00963139, -0.00371116, -0.00298074, -0.00238809,\n",
      "       -0.00236084, -0.00235322, -0.00240562, -0.0024015 , -0.04329005,\n",
      "       -0.0090917 , -0.00370583, -0.002851  , -0.00263144, -0.00256178,\n",
      "       -0.00244996, -0.00246467, -0.00255336, -0.04553931, -0.01147689,\n",
      "       -0.00567278, -0.00428728, -0.00410452, -0.00391472, -0.00390001,\n",
      "       -0.00389092, -0.00379955, -0.04704288, -0.01224351, -0.00703827,\n",
      "       -0.00614769, -0.00596821, -0.00596802, -0.00593086, -0.00571266,\n",
      "       -0.00571247, -0.04557207, -0.0131038 , -0.0087207 , -0.0080312 ,\n",
      "       -0.0077457 , -0.00769567, -0.00768144, -0.00775032, -0.0076847 ,\n",
      "       -0.17048031, -0.11507128, -0.08400929, -0.06112945, -0.04591111,\n",
      "       -0.03393436, -0.02419676, -0.01911089, -0.01652028, -0.13400987,\n",
      "       -0.0610605 , -0.02890016, -0.0154936 , -0.00844605, -0.00589152,\n",
      "       -0.00371389, -0.00293222, -0.00193633, -0.11525026, -0.04607671,\n",
      "       -0.0210133 , -0.00585411, -0.00292897, -0.00207465, -0.00198879,\n",
      "       -0.00200793, -0.00204551, -0.11226489, -0.04078531, -0.01125901,\n",
      "       -0.0033127 , -0.00217197, -0.00222687, -0.00168531, -0.00182874,\n",
      "       -0.00176957, -0.1107007 , -0.04077538, -0.01004692, -0.00309578,\n",
      "       -0.00217893, -0.00233558, -0.00190255, -0.00165115, -0.00207312,\n",
      "       -0.11215778, -0.04187529, -0.01014936, -0.00409171, -0.00233861,\n",
      "       -0.00273288, -0.00191973, -0.00153348, -0.00188261, -0.11176939,\n",
      "       -0.03880253, -0.00896205, -0.002815  , -0.00202533, -0.00160609,\n",
      "       -0.0023524 , -0.00168537, -0.00223095, -0.11138577, -0.04014758,\n",
      "       -0.00919126, -0.0031162 , -0.00246434, -0.00160849, -0.00178042,\n",
      "       -0.00210644, -0.00123822, -0.11179966, -0.04243061, -0.00941259,\n",
      "       -0.0031795 , -0.00234762, -0.00201516, -0.00152335, -0.0014523 ,\n",
      "       -0.00186714, -0.12672192, -0.06654991, -0.03727691, -0.02515302,\n",
      "       -0.02011631, -0.01119449, -0.00741214, -0.00620009, -0.00493564,\n",
      "       -0.0817224 , -0.02848005, -0.01430643, -0.00706223, -0.00405231,\n",
      "       -0.00310211, -0.00277522, -0.00266314, -0.00260419, -0.06277844,\n",
      "       -0.02137622, -0.00788753, -0.00449762, -0.0024352 , -0.00210848,\n",
      "       -0.00204933, -0.00207287, -0.00211835, -0.05483656, -0.01538274,\n",
      "       -0.00645154, -0.00392041, -0.0028613 , -0.00292075, -0.00294584,\n",
      "       -0.00280371, -0.00291884, -0.05248241, -0.01331141, -0.00679449,\n",
      "       -0.00380071, -0.00363821, -0.00324059, -0.00312171, -0.00296629,\n",
      "       -0.00340432, -0.05268868, -0.01319533, -0.00608584, -0.00394728,\n",
      "       -0.00359031, -0.00370159, -0.00375583, -0.00387232, -0.00391266,\n",
      "       -0.05322587, -0.01526036, -0.00735852, -0.00521686, -0.00472535,\n",
      "       -0.00548706, -0.00463634, -0.00596213, -0.00549591, -0.04933863,\n",
      "       -0.01462321, -0.00790728, -0.0074552 , -0.00612119, -0.00570104,\n",
      "       -0.00621701, -0.00575273, -0.00563368, -0.05066436, -0.01502518,\n",
      "       -0.0091861 , -0.00969657, -0.00701797, -0.01226608, -0.0065401 ,\n",
      "       -0.00661229, -0.00763362, -0.47412562, -0.26579937, -0.16158203,\n",
      "       -0.10357572, -0.0664996 , -0.0414474 , -0.02829547, -0.02007776,\n",
      "       -0.01636527, -0.40644931, -0.19612264, -0.11236846, -0.06608268,\n",
      "       -0.04260106, -0.02232344, -0.01706004, -0.01426279, -0.01164906,\n",
      "       -0.35678096, -0.17709931, -0.10517782, -0.05672386, -0.03630911,\n",
      "       -0.0176918 , -0.01558463, -0.00973498, -0.00978583, -0.35286611,\n",
      "       -0.17787769, -0.09635877, -0.05263856, -0.03826065, -0.02361651,\n",
      "       -0.01066394, -0.01008242, -0.00993604, -0.35397434, -0.18155339,\n",
      "       -0.0941837 , -0.04726122, -0.02715706, -0.01671728, -0.01174381,\n",
      "       -0.00920795, -0.0074718 , -0.35708242, -0.17069104, -0.10706796,\n",
      "       -0.05576842, -0.03237089, -0.01550857, -0.01417976, -0.00734723,\n",
      "       -0.00648481, -0.34510914, -0.17589003, -0.09067834, -0.04599316,\n",
      "       -0.0352594 , -0.01680007, -0.01461694, -0.01065313, -0.00613361,\n",
      "       -0.34976169, -0.17805088, -0.09375851, -0.04861403, -0.02662698,\n",
      "       -0.01418046, -0.01101258, -0.00749541, -0.00783472, -0.35279147,\n",
      "       -0.18017891, -0.08167339, -0.05163534, -0.03715304, -0.01834716,\n",
      "       -0.01055092, -0.00563102, -0.00699993, -0.26761807, -0.25250843,\n",
      "       -0.23831538, -0.22518757, -0.21300084, -0.20091812, -0.18727708,\n",
      "       -0.17484904, -0.16361151, -0.25106614, -0.22054454, -0.19091599,\n",
      "       -0.16573714, -0.14519593, -0.12378236, -0.10639062, -0.09209328,\n",
      "       -0.0797193 , -0.24583051, -0.21000844, -0.1787489 , -0.15182564,\n",
      "       -0.12566397, -0.10323983, -0.08599395, -0.07111489, -0.06006027,\n",
      "       -0.24011672, -0.20010063, -0.16706486, -0.13968619, -0.11726699,\n",
      "       -0.09798606, -0.08150996, -0.06840026, -0.05783004, -0.23788858,\n",
      "       -0.19606748, -0.1619806 , -0.13354069, -0.11023281, -0.09115119,\n",
      "       -0.07569391, -0.06347121, -0.05326647, -0.23881711, -0.19685762,\n",
      "       -0.16178006, -0.13327351, -0.10995905, -0.09137368, -0.07591393,\n",
      "       -0.06312615, -0.05264786, -0.23826674, -0.19735661, -0.16393065,\n",
      "       -0.13632648, -0.11277444, -0.09391058, -0.07795744, -0.06544012,\n",
      "       -0.05460901, -0.23791826, -0.19654134, -0.16267324, -0.13550442,\n",
      "       -0.11251266, -0.09391012, -0.07838723, -0.0659969 , -0.05570604,\n",
      "       -0.23790527, -0.19651625, -0.162282  , -0.13478237, -0.11170097,\n",
      "       -0.09307276, -0.07777005, -0.06532228, -0.05511386, -0.2722    ,\n",
      "       -0.25730619, -0.24437021, -0.2287479 , -0.21561574, -0.20487725,\n",
      "       -0.19481623, -0.18559724, -0.17717543, -0.26801919, -0.2475159 ,\n",
      "       -0.2290862 , -0.21042895, -0.19303359, -0.17761787, -0.16316465,\n",
      "       -0.1512471 , -0.13888728, -0.26420512, -0.2404315 , -0.21846203,\n",
      "       -0.19963148, -0.18297047, -0.16618603, -0.15160231, -0.13941941,\n",
      "       -0.12728467, -0.26304549, -0.2384572 , -0.21672768, -0.19684791,\n",
      "       -0.17914177, -0.16317563, -0.14800073, -0.13470249, -0.12291485,\n",
      "       -0.26295859, -0.23834112, -0.21634235, -0.19675028, -0.17894201,\n",
      "       -0.16295538, -0.14796346, -0.13504611, -0.12204105, -0.26291287,\n",
      "       -0.2384919 , -0.21636027, -0.19578341, -0.17948856, -0.16296934,\n",
      "       -0.14955997, -0.13460119, -0.12205792, -0.26291855, -0.23853875,\n",
      "       -0.21621356, -0.19697322, -0.17934533, -0.16323347, -0.14878902,\n",
      "       -0.13532521, -0.12227856, -0.26295507, -0.23846888, -0.21648315,\n",
      "       -0.1969808 , -0.17902131, -0.16292057, -0.14886719, -0.13534801,\n",
      "       -0.12211382, -0.26289366, -0.23830882, -0.21637212, -0.19638761,\n",
      "       -0.17957525, -0.16253196, -0.14897881, -0.13508425, -0.1231941 ,\n",
      "       -0.26172346, -0.23770686, -0.21715791, -0.19973779, -0.18464796,\n",
      "       -0.17061259, -0.15777592, -0.14636541, -0.13628892, -0.25081988,\n",
      "       -0.21877429, -0.19230787, -0.16977233, -0.14968927, -0.13142413,\n",
      "       -0.11542921, -0.10304273, -0.09211442, -0.24502531, -0.21082988,\n",
      "       -0.18273981, -0.15698564, -0.13463907, -0.11394421, -0.09801249,\n",
      "       -0.08574539, -0.07147672, -0.24545985, -0.20782586, -0.17753604,\n",
      "       -0.15069661, -0.127197  , -0.10671674, -0.08916359, -0.07552744,\n",
      "       -0.06386047, -0.24207734, -0.20495472, -0.17187016, -0.14418818,\n",
      "       -0.12130616, -0.10203463, -0.08603595, -0.07251558, -0.06175966,\n",
      "       -0.24036464, -0.20033051, -0.16823309, -0.14156744, -0.11897174,\n",
      "       -0.10061286, -0.08518755, -0.07210119, -0.06080209, -0.24092393,\n",
      "       -0.20071569, -0.1668069 , -0.13884051, -0.11592918, -0.09677696,\n",
      "       -0.0817686 , -0.06960536, -0.06019827, -0.24156487, -0.20127261,\n",
      "       -0.16673771, -0.13870428, -0.11557673, -0.0963208 , -0.08161763,\n",
      "       -0.06881635, -0.05805442, -0.24156541, -0.20104162, -0.16710503,\n",
      "       -0.1392089 , -0.11597153, -0.09702406, -0.08182721, -0.06915486,\n",
      "       -0.05833237, -0.79960081, -0.74960669, -0.7101258 , -0.66627469,\n",
      "       -0.62586519, -0.58993599, -0.55490076, -0.52329989, -0.49622347,\n",
      "       -0.77199671, -0.69892734, -0.64744457, -0.60393171, -0.55681658,\n",
      "       -0.52123942, -0.48043019, -0.44784182, -0.43377176, -0.75935236,\n",
      "       -0.67905864, -0.61761812, -0.56355042, -0.52185539, -0.48436095,\n",
      "       -0.44971472, -0.41614653, -0.38529906, -0.75864695, -0.67903994,\n",
      "       -0.61720343, -0.5620465 , -0.51923168, -0.48114551, -0.44240815,\n",
      "       -0.41141814, -0.37801679, -0.75902208, -0.67894842, -0.61984589,\n",
      "       -0.5620323 , -0.52003071, -0.47965183, -0.44398422, -0.41282856,\n",
      "       -0.37974426, -0.75890264, -0.67877055, -0.61781443, -0.56384396,\n",
      "       -0.51927145, -0.47830512, -0.4417948 , -0.41124933, -0.38108311,\n",
      "       -0.75898045, -0.67876148, -0.61909135, -0.56442533, -0.51805837,\n",
      "       -0.48103424, -0.44211894, -0.40706503, -0.37822709, -0.75863109,\n",
      "       -0.67858705, -0.61638945, -0.56397012, -0.52047166, -0.48184195,\n",
      "       -0.44797648, -0.41167412, -0.37658202, -0.75880271, -0.67902766,\n",
      "       -0.6188098 , -0.56340872, -0.5243606 , -0.47803063, -0.44597634,\n",
      "       -0.40727777, -0.37717052]), 'split1_test_score': array([-0.02920886, -0.02102999, -0.01980502, -0.01900907, -0.01829347,\n",
      "       -0.01778054, -0.0173841 , -0.01707001, -0.01682449, -0.04026515,\n",
      "       -0.05130234, -0.03856518, -0.01204991, -0.03238197, -0.04180878,\n",
      "       -0.04047958, -0.07170291, -0.06310561, -0.05053406, -0.06450598,\n",
      "       -0.03160898, -0.01768778, -0.02467712, -0.04014002, -0.06899178,\n",
      "       -0.02778584, -0.02707801, -0.02894467, -0.08853454, -0.06158715,\n",
      "       -0.03838089, -0.02092805, -0.0601337 , -0.05910653, -0.03341853,\n",
      "       -0.04298795, -0.01095063, -0.01372786, -0.00840438, -0.01749667,\n",
      "       -0.0126589 , -0.01460931, -0.01513665, -0.01697892, -0.01352539,\n",
      "       -0.05299407, -0.05490934, -0.05535684, -0.05477389, -0.05134734,\n",
      "       -0.05219033, -0.05850337, -0.04608356, -0.04913722, -0.08185143,\n",
      "       -0.08269624, -0.08200742, -0.08324817, -0.08286012, -0.08364509,\n",
      "       -0.08378241, -0.08323111, -0.08368081, -0.08466422, -0.08512336,\n",
      "       -0.08448044, -0.08436919, -0.08379772, -0.08468923, -0.08486509,\n",
      "       -0.08466239, -0.08324178, -0.08445814, -0.08414537, -0.0846703 ,\n",
      "       -0.08485844, -0.08510375, -0.08415049, -0.0847146 , -0.08504724,\n",
      "       -0.08479368, -0.11300398, -0.05559556, -0.04376952, -0.04292386,\n",
      "       -0.04214445, -0.04218961, -0.03243944, -0.04160686, -0.0245313 ,\n",
      "       -0.05625851, -0.04202302, -0.0237987 , -0.01445985, -0.01694536,\n",
      "       -0.02026789, -0.01707057, -0.00648394, -0.01926062, -0.04825818,\n",
      "       -0.03943854, -0.01991166, -0.01537316, -0.01619384, -0.01211381,\n",
      "       -0.01825616, -0.015786  , -0.02078414, -0.04893027, -0.02542965,\n",
      "       -0.00399457, -0.0068318 , -0.02450373, -0.01040471, -0.01966811,\n",
      "       -0.00225059, -0.05449818, -0.03863268, -0.0249598 , -0.01910595,\n",
      "       -0.02077923, -0.02575273, -0.01237049, -0.03413304, -0.12232958,\n",
      "       -0.01934629, -0.0514645 , -0.03313963, -0.0046272 , -0.00942183,\n",
      "       -0.00720595, -0.01317262, -0.02056518, -0.01396424, -0.18111193,\n",
      "       -0.03775128, -0.00707552, -0.00398963, -0.11390923, -0.00716645,\n",
      "       -0.13250645, -0.04467091, -0.01742435, -0.02539787, -0.05257343,\n",
      "       -0.03106773, -0.06353399, -0.01566135, -0.06603568, -0.00573992,\n",
      "       -0.05780887, -0.07869966, -0.02718203, -0.04792135, -0.01269869,\n",
      "       -0.0112708 , -0.00532581, -0.00750518, -0.14931283, -0.05503074,\n",
      "       -0.04692292, -0.02005682, -0.06485129, -0.02376717, -0.02150678,\n",
      "       -0.02088819, -0.02006958, -0.01946982, -0.01901737, -0.01852366,\n",
      "       -0.01814534, -0.0105096 , -0.00473012, -0.00299096, -0.00270773,\n",
      "       -0.00444888, -0.02059544, -0.02101044, -0.00892989, -0.0064796 ,\n",
      "       -0.01431662, -0.03235103, -0.02813562, -0.01946242, -0.07671628,\n",
      "       -0.03931079, -0.06098219, -0.07906619, -0.06328192, -0.01136571,\n",
      "       -0.00640052, -0.00921462, -0.0190529 , -0.00907398, -0.01378217,\n",
      "       -0.03742691, -0.05042688, -0.0260599 , -0.02774145, -0.05513019,\n",
      "       -0.06518024, -0.07917998, -0.02301797, -0.02725403, -0.01509278,\n",
      "       -0.0341075 , -0.01108242, -0.03090168, -0.03802478, -0.03167814,\n",
      "       -0.0172612 , -0.00625777, -0.0122263 , -0.02339214, -0.04734271,\n",
      "       -0.02312172, -0.03427279, -0.02108759, -0.02607716, -0.01926159,\n",
      "       -0.00491915, -0.04006176, -0.01726332, -0.023851  , -0.01022345,\n",
      "       -0.04276301, -0.00382671, -0.02192437, -0.0127049 , -0.12218437,\n",
      "       -0.06174939, -0.13733596, -0.07044516, -0.06156037, -0.02037209,\n",
      "       -0.04048955, -0.04649832, -0.0446311 , -0.05339984, -0.08005178,\n",
      "       -0.13127648, -0.17260177, -0.06366208, -0.01298594, -0.01019055,\n",
      "       -0.01019054, -0.01019054, -0.01019054, -0.01019054, -0.01019054,\n",
      "       -0.01019054, -0.01019054, -0.1251625 , -0.13696309, -0.07963682,\n",
      "       -0.12600112, -0.05459398, -0.13553416, -0.08820083, -0.06173251,\n",
      "       -0.1019598 , -0.02366231, -0.07959606, -0.0733247 , -0.15946642,\n",
      "       -0.17099748, -0.06582867, -0.02704138, -0.17556782, -0.03687637,\n",
      "       -0.06316433, -0.08898968, -0.1086977 , -0.14783021, -0.07223203,\n",
      "       -0.16413333, -0.10632816, -0.16141556, -0.07602514, -0.35454425,\n",
      "       -0.1130335 , -0.25488836, -0.1713537 , -0.10852959, -0.11068586,\n",
      "       -0.08625567, -0.07111285, -0.41689406, -0.14471107, -0.1381752 ,\n",
      "       -0.15177401, -0.25586172, -0.1124429 , -0.20350237, -0.09177317,\n",
      "       -0.11840139, -0.07767441, -0.09559047, -0.11963416, -0.12456796,\n",
      "       -0.05504434, -0.12949381, -0.15833429, -0.05796171, -0.10969437,\n",
      "       -0.16047203, -0.11480604, -0.15595139, -0.1488017 , -0.10525087,\n",
      "       -0.09956829, -0.11483211, -0.02587169, -0.15621339, -0.18174642,\n",
      "       -0.19870643, -0.17031717, -0.23580537, -0.10667668, -0.10411249,\n",
      "       -0.13595558, -0.10256723, -0.05532014, -0.11877443, -0.29483985,\n",
      "       -0.18841258, -0.12551112, -0.09028602, -0.07008529, -0.05530762,\n",
      "       -0.04546533, -0.03881969, -0.03396065, -0.08452821, -0.03290791,\n",
      "       -0.02487728, -0.03226463, -0.01871731, -0.03902743, -0.02930283,\n",
      "       -0.02271079, -0.03357699, -0.0669835 , -0.02748905, -0.02720598,\n",
      "       -0.03166149, -0.03614296, -0.03500593, -0.04477812, -0.03640454,\n",
      "       -0.04145493, -0.07393591, -0.01631563, -0.02300157, -0.02111351,\n",
      "       -0.02118075, -0.02180895, -0.03267347, -0.02079771, -0.03653465,\n",
      "       -0.15890676, -0.04446545, -0.01319455, -0.00910521, -0.00864085,\n",
      "       -0.00920013, -0.0084175 , -0.00632574, -0.00581306, -0.16957558,\n",
      "       -0.09990154, -0.07672318, -0.06212112, -0.05681209, -0.05683596,\n",
      "       -0.05516962, -0.05453548, -0.05424926, -0.17110889, -0.10908105,\n",
      "       -0.09300588, -0.08699894, -0.08526549, -0.08436157, -0.08339348,\n",
      "       -0.08292418, -0.08321543, -0.17102777, -0.10838014, -0.09241213,\n",
      "       -0.08749907, -0.08583122, -0.08563633, -0.08504772, -0.08505442,\n",
      "       -0.08500683, -0.17057296, -0.10862815, -0.09247831, -0.08755345,\n",
      "       -0.08608558, -0.08554939, -0.08502748, -0.08516466, -0.08508951,\n",
      "       -0.37019025, -0.30599831, -0.26268043, -0.2181806 , -0.18950205,\n",
      "       -0.15440761, -0.13605224, -0.12692806, -0.12666192, -0.31886371,\n",
      "       -0.22343351, -0.15964352, -0.1237939 , -0.10191884, -0.08014259,\n",
      "       -0.06842192, -0.05998581, -0.05286495, -0.2937644 , -0.19396015,\n",
      "       -0.12866123, -0.09369925, -0.07557238, -0.06238181, -0.06072376,\n",
      "       -0.05146625, -0.05324598, -0.28943504, -0.18357743, -0.12611629,\n",
      "       -0.08413193, -0.06597693, -0.06132424, -0.05575041, -0.05695309,\n",
      "       -0.04238648, -0.29092177, -0.18345992, -0.12034368, -0.08036357,\n",
      "       -0.06795424, -0.0611501 , -0.05738764, -0.05287288, -0.03816866,\n",
      "       -0.29084536, -0.18463355, -0.11793699, -0.08110948, -0.06734716,\n",
      "       -0.05805502, -0.05660883, -0.031436  , -0.04917246, -0.28938229,\n",
      "       -0.18127594, -0.11418147, -0.07849034, -0.06526588, -0.05845158,\n",
      "       -0.05323599, -0.04358512, -0.04157559, -0.2910159 , -0.18127037,\n",
      "       -0.11565652, -0.0737706 , -0.06540535, -0.04314629, -0.05227481,\n",
      "       -0.03911742, -0.03536002, -0.29102223, -0.17983957, -0.11759125,\n",
      "       -0.07848737, -0.06650109, -0.05415314, -0.0550783 , -0.04368346,\n",
      "       -0.03019781, -0.31096121, -0.22306374, -0.17082146, -0.14559896,\n",
      "       -0.12959186, -0.11070201, -0.09158655, -0.08443251, -0.08057418,\n",
      "       -0.24302362, -0.1499063 , -0.11922058, -0.08732234, -0.06675797,\n",
      "       -0.05716268, -0.04843562, -0.03743588, -0.02898849, -0.21546701,\n",
      "       -0.14319037, -0.09902695, -0.07232907, -0.05817588, -0.0449133 ,\n",
      "       -0.03472655, -0.02933784, -0.00576893, -0.19509266, -0.12468981,\n",
      "       -0.08836976, -0.06604893, -0.05853978, -0.04823656, -0.03210375,\n",
      "       -0.0180579 , -0.02722407, -0.18747969, -0.10637173, -0.07741981,\n",
      "       -0.05426737, -0.0498856 , -0.04530563, -0.02264733, -0.02326892,\n",
      "       -0.00255663, -0.18089022, -0.10484498, -0.07323982, -0.0630639 ,\n",
      "       -0.04985289, -0.05867383, -0.0407111 , -0.0345021 , -0.03206154,\n",
      "       -0.16803463, -0.0944404 , -0.05853326, -0.06603094, -0.05626166,\n",
      "       -0.04078517, -0.04965994, -0.03109476, -0.03512026, -0.17386287,\n",
      "       -0.09580081, -0.05654669, -0.04746726, -0.0459706 , -0.03954664,\n",
      "       -0.03872477, -0.02629698, -0.02701506, -0.15997985, -0.08055773,\n",
      "       -0.06118034, -0.05142494, -0.03884022, -0.03231867, -0.06553223,\n",
      "       -0.00799792, -0.03269097, -0.53887538, -0.29361079, -0.17430386,\n",
      "       -0.10001574, -0.06584895, -0.04630763, -0.03667766, -0.03058325,\n",
      "       -0.02449967, -0.36179199, -0.1665082 , -0.09213401, -0.07524611,\n",
      "       -0.06102629, -0.02633031, -0.03333294, -0.01842688, -0.01594733,\n",
      "       -0.31010225, -0.14206725, -0.09020019, -0.06447644, -0.01840101,\n",
      "       -0.0232048 , -0.01290391, -0.01647347, -0.01762229, -0.31549923,\n",
      "       -0.15709773, -0.11876122, -0.04569341, -0.11247612, -0.02660644,\n",
      "       -0.02121266, -0.01987298, -0.02609014, -0.30084903, -0.17338776,\n",
      "       -0.08718898, -0.06810849, -0.17591903, -0.07046549, -0.02724027,\n",
      "       -0.08451266, -0.01218888, -0.30208534, -0.19574586, -0.17113505,\n",
      "       -0.26568183, -0.09368561, -0.03213929, -0.12532038, -0.06506988,\n",
      "       -0.10345315, -0.300011  , -0.14626207, -0.19356258, -0.22596027,\n",
      "       -0.23919639, -0.16472621, -0.08893925, -0.02258546, -0.15989611,\n",
      "       -0.31393063, -0.25241476, -0.24415014, -0.0919655 , -0.05937057,\n",
      "       -0.13022246, -0.12470135, -0.15208693, -0.12510479, -0.30838517,\n",
      "       -0.21828254, -0.19768618, -0.2443436 , -0.149696  , -0.0678005 ,\n",
      "       -0.26559179, -0.03510262, -0.22915724, -0.46258223, -0.43785375,\n",
      "       -0.41579719, -0.39569181, -0.37697348, -0.35956829, -0.34249044,\n",
      "       -0.32648787, -0.31134691, -0.42142367, -0.34367754, -0.28711406,\n",
      "       -0.23646252, -0.19508827, -0.16012552, -0.13621038, -0.11547394,\n",
      "       -0.10533379, -0.43144211, -0.3611347 , -0.29570676, -0.24193217,\n",
      "       -0.19168848, -0.15349764, -0.12355278, -0.09768223, -0.080839  ,\n",
      "       -0.42909495, -0.38232236, -0.31469313, -0.2584332 , -0.20766609,\n",
      "       -0.17172273, -0.13659951, -0.11114943, -0.09185167, -0.42600751,\n",
      "       -0.37772811, -0.33474379, -0.29764441, -0.26483129, -0.23805135,\n",
      "       -0.21475414, -0.19532993, -0.17100102, -0.42386353, -0.37422095,\n",
      "       -0.33254879, -0.29702904, -0.26713638, -0.24193369, -0.2205844 ,\n",
      "       -0.20226835, -0.18589917, -0.42375556, -0.37323816, -0.33096547,\n",
      "       -0.29539842, -0.26534694, -0.24004279, -0.21840673, -0.20040235,\n",
      "       -0.18494668, -0.42364681, -0.37324834, -0.33088287, -0.29523118,\n",
      "       -0.2651627 , -0.23972082, -0.21839824, -0.20022547, -0.1848006 ,\n",
      "       -0.42359454, -0.37307988, -0.33073472, -0.29495504, -0.26481246,\n",
      "       -0.23944628, -0.21804275, -0.19971497, -0.18436416, -0.49136276,\n",
      "       -0.4728506 , -0.45498402, -0.4377092 , -0.42383575, -0.41031481,\n",
      "       -0.39811272, -0.38818352, -0.37747905, -0.48203805, -0.45369033,\n",
      "       -0.42904591, -0.40931259, -0.39084796, -0.37325805, -0.35633119,\n",
      "       -0.34123174, -0.32740049, -0.47806628, -0.44942733, -0.42375989,\n",
      "       -0.40050565, -0.37975797, -0.36011597, -0.34251138, -0.32688962,\n",
      "       -0.30987666, -0.47716851, -0.44809716, -0.42190837, -0.39783036,\n",
      "       -0.37517021, -0.35613667, -0.33835413, -0.32321816, -0.30562308,\n",
      "       -0.47728926, -0.44823143, -0.4214343 , -0.39776854, -0.3749226 ,\n",
      "       -0.35612384, -0.338788  , -0.32305261, -0.3065832 , -0.47715507,\n",
      "       -0.44811301, -0.42131352, -0.39718255, -0.3754418 , -0.35614039,\n",
      "       -0.33889981, -0.32312717, -0.30587762, -0.47717646, -0.44813634,\n",
      "       -0.42143507, -0.39740091, -0.37550327, -0.35680309, -0.3387525 ,\n",
      "       -0.32313223, -0.3057723 , -0.47717568, -0.44815891, -0.42136128,\n",
      "       -0.39725791, -0.3753902 , -0.35622198, -0.3383399 , -0.32261885,\n",
      "       -0.30613812, -0.47718203, -0.44814401, -0.42168236, -0.3974639 ,\n",
      "       -0.37557487, -0.35636661, -0.33900855, -0.32158658, -0.30594146,\n",
      "       -0.48084058, -0.45263119, -0.42742905, -0.40575903, -0.38623555,\n",
      "       -0.36802484, -0.352546  , -0.33739088, -0.32429653, -0.46365889,\n",
      "       -0.42458787, -0.39188396, -0.36259588, -0.33576737, -0.31311712,\n",
      "       -0.29226423, -0.27354988, -0.25653606, -0.45792821, -0.41182621,\n",
      "       -0.37415689, -0.3386759 , -0.31079279, -0.28578965, -0.26332549,\n",
      "       -0.24665627, -0.22971183, -0.45025255, -0.40034101, -0.35933835,\n",
      "       -0.32584646, -0.29775984, -0.27197772, -0.25096026, -0.23162655,\n",
      "       -0.21097624, -0.44995703, -0.39884823, -0.35485272, -0.3191356 ,\n",
      "       -0.28654603, -0.26014737, -0.23673036, -0.21865572, -0.20357975,\n",
      "       -0.44488527, -0.39529073, -0.3536573 , -0.31442301, -0.28113752,\n",
      "       -0.25222578, -0.22770935, -0.20932471, -0.19367552, -0.44791254,\n",
      "       -0.39379276, -0.35063822, -0.31150872, -0.27586047, -0.24787079,\n",
      "       -0.22268694, -0.19938682, -0.18766436, -0.44208022, -0.39094996,\n",
      "       -0.34610965, -0.3068507 , -0.27344942, -0.24237528, -0.22306855,\n",
      "       -0.19901812, -0.18319199, -0.44650707, -0.39019228, -0.34481318,\n",
      "       -0.30060958, -0.27242805, -0.24318158, -0.21694041, -0.19722392,\n",
      "       -0.17935077, -0.87783964, -0.83795776, -0.80532931, -0.77151157,\n",
      "       -0.73343866, -0.69726923, -0.65719469, -0.6208357 , -0.57736381,\n",
      "       -0.84776661, -0.76983333, -0.7030614 , -0.62591686, -0.56696687,\n",
      "       -0.52644888, -0.47590508, -0.43860259, -0.3993943 , -0.84000021,\n",
      "       -0.75098471, -0.67815313, -0.60271041, -0.52317336, -0.47312012,\n",
      "       -0.42904932, -0.3719082 , -0.3484261 , -0.83460245, -0.74615392,\n",
      "       -0.67194953, -0.60501241, -0.53869286, -0.47837791, -0.41767935,\n",
      "       -0.37555611, -0.33338333, -0.83462983, -0.74577711, -0.66986384,\n",
      "       -0.60179478, -0.52204131, -0.45600986, -0.41932181, -0.37586216,\n",
      "       -0.33048578, -0.83459761, -0.74599846, -0.67057812, -0.60277855,\n",
      "       -0.52489016, -0.45752078, -0.41413616, -0.3656836 , -0.33155497,\n",
      "       -0.83417993, -0.74637655, -0.67164322, -0.60066451, -0.52653656,\n",
      "       -0.45563577, -0.40172901, -0.36046124, -0.32542153, -0.8345962 ,\n",
      "       -0.74594041, -0.67173437, -0.60312904, -0.52441243, -0.45454681,\n",
      "       -0.41159054, -0.35725397, -0.33226196, -0.83454287, -0.74596741,\n",
      "       -0.6705377 , -0.60349866, -0.51899175, -0.46067898, -0.41063607,\n",
      "       -0.36419285, -0.33587343]), 'split2_test_score': array([-0.31668748, -0.2972428 , -0.2929226 , -0.29004136, -0.28823654,\n",
      "       -0.28706746, -0.28632667, -0.2860528 , -0.28567906, -0.28765763,\n",
      "       -0.27903019, -0.2786842 , -0.28593399, -0.28651084, -0.27890919,\n",
      "       -0.28685249, -0.27914282, -0.27921834, -0.30095134, -0.29836105,\n",
      "       -0.30074922, -0.29190714, -0.29966101, -0.28471475, -0.28496169,\n",
      "       -0.28520846, -0.28395702, -0.28976334, -0.28622331, -0.30107335,\n",
      "       -0.30054741, -0.2917652 , -0.29346916, -0.29622832, -0.29077366,\n",
      "       -0.28879163, -0.29217521, -0.29383296, -0.29426204, -0.29059634,\n",
      "       -0.28883206, -0.28825163, -0.28914707, -0.29104837, -0.28962463,\n",
      "       -0.2890592 , -0.28882553, -0.28873114, -0.28890521, -0.28900952,\n",
      "       -0.28859842, -0.28867515, -0.28867325, -0.28820898, -0.28784429,\n",
      "       -0.28897979, -0.28885919, -0.28918856, -0.28836097, -0.28805856,\n",
      "       -0.28879186, -0.28888841, -0.28849778, -0.28933645, -0.28988098,\n",
      "       -0.29015884, -0.28982118, -0.28990579, -0.29005919, -0.28930379,\n",
      "       -0.28939696, -0.29001264, -0.29049474, -0.2903374 , -0.29001794,\n",
      "       -0.29029721, -0.2899296 , -0.29060864, -0.29004348, -0.29042943,\n",
      "       -0.29026432, -0.74429434, -0.5999444 , -0.53723433, -0.53583536,\n",
      "       -0.53051261, -0.52508121, -0.52723818, -0.52805125, -0.5283223 ,\n",
      "       -0.56166964, -0.50412453, -0.49105146, -0.48195367, -0.45584296,\n",
      "       -0.48600868, -0.36677144, -0.4827138 , -0.3228522 , -0.54795091,\n",
      "       -0.51551141, -0.48979304, -0.52487432, -0.45461324, -0.49682617,\n",
      "       -0.32133989, -0.44435629, -0.30697669, -0.56621499, -0.4981536 ,\n",
      "       -0.51772138, -0.52197666, -0.44931068, -0.37875068, -0.35236839,\n",
      "       -0.42478072, -0.2961077 , -0.55504908, -0.58230241, -0.52781696,\n",
      "       -0.36110971, -0.51153905, -0.4064618 , -0.35448131, -0.2966087 ,\n",
      "       -0.41760316, -0.55013163, -0.55532558, -0.52437557, -0.36409096,\n",
      "       -0.38230006, -0.35735295, -0.36732428, -0.33132634, -0.34956658,\n",
      "       -0.57806889, -0.47289795, -0.37128536, -0.33265345, -0.37479195,\n",
      "       -0.38825095, -0.40528091, -0.3805576 , -0.3345295 , -0.50876818,\n",
      "       -0.45548408, -0.50257436, -0.3708844 , -0.36505524, -0.44426413,\n",
      "       -0.33788147, -0.41477529, -0.36926935, -0.50955019, -0.51834172,\n",
      "       -0.45263403, -0.39599042, -0.33316875, -0.34910892, -0.37749531,\n",
      "       -0.38949655, -0.38901916, -0.62223416, -0.52512553, -0.50646627,\n",
      "       -0.30423203, -0.28763502, -0.28639722, -0.28565394, -0.28492096,\n",
      "       -0.28498774, -0.48042449, -0.31507709, -0.34037914, -0.3435039 ,\n",
      "       -0.31823373, -0.30355643, -0.29468781, -0.29663815, -0.29887322,\n",
      "       -0.34155687, -0.30402479, -0.32060143, -0.31141021, -0.29415297,\n",
      "       -0.34443732, -0.28946631, -0.330992  , -0.28797046, -0.33895441,\n",
      "       -0.29976213, -0.29992465, -0.31860489, -0.30012847, -0.30264865,\n",
      "       -0.33744184, -0.3060727 , -0.30018258, -0.5097626 , -0.30632275,\n",
      "       -0.28882403, -0.32992735, -0.28822641, -0.30818617, -0.30718728,\n",
      "       -0.28759609, -0.29167153, -0.46301649, -0.28500214, -0.28126658,\n",
      "       -0.30768965, -0.33025492, -0.28597928, -0.30434811, -0.29612785,\n",
      "       -0.28683516, -0.56536891, -0.32436405, -0.28764699, -0.2904292 ,\n",
      "       -0.31399297, -0.28704099, -0.34855026, -0.31373966, -0.28794665,\n",
      "       -0.57447692, -0.41877429, -0.3081825 , -0.28788605, -0.30380568,\n",
      "       -0.32695887, -0.28783632, -0.28821413, -0.29908088, -0.45536428,\n",
      "       -0.48235401, -0.37385739, -0.30131258, -0.41032405, -0.29988183,\n",
      "       -0.39591141, -0.42097788, -0.52698493, -0.51681003, -0.29817871,\n",
      "       -0.29816595, -0.29816595, -0.29816595, -0.29816595, -0.29816595,\n",
      "       -0.29816595, -0.29816595, -0.305283  , -0.28848666, -0.30668036,\n",
      "       -0.29825466, -0.29211599, -0.30733468, -0.31102269, -0.32368741,\n",
      "       -0.28618489, -0.29162634, -0.32315092, -0.31224088, -0.28812186,\n",
      "       -0.28979141, -0.33114085, -0.28941971, -0.28851294, -0.29062966,\n",
      "       -0.30803333, -0.28677207, -0.35954463, -0.30551352, -0.2950578 ,\n",
      "       -0.28458533, -0.28762335, -0.30186546, -0.29584255, -0.29311016,\n",
      "       -0.30547398, -0.32333157, -0.30808523, -0.30709175, -0.30853481,\n",
      "       -0.29974884, -0.3041386 , -0.30763672, -0.3470867 , -0.31959066,\n",
      "       -0.36216546, -0.29493267, -0.29769417, -0.30085031, -0.31334226,\n",
      "       -0.3164455 , -0.33525794, -0.32220451, -0.31466541, -0.32069361,\n",
      "       -0.30876817, -0.32474075, -0.33752763, -0.32542317, -0.28567466,\n",
      "       -0.33293276, -0.30073426, -0.33344749, -0.28924107, -0.32463405,\n",
      "       -0.35287706, -0.28402372, -0.3540374 , -0.28537583, -0.30684778,\n",
      "       -0.31297812, -0.34332328, -0.32941074, -0.28724178, -0.32281296,\n",
      "       -0.38614658, -0.28811045, -0.31508153, -0.34084337, -0.93634199,\n",
      "       -0.73839535, -0.57781502, -0.4860981 , -0.42782411, -0.39045551,\n",
      "       -0.36385534, -0.34562257, -0.33191109, -0.67340986, -0.45880337,\n",
      "       -0.37359846, -0.33085087, -0.31257632, -0.30168946, -0.29779868,\n",
      "       -0.29440724, -0.29247356, -0.56889908, -0.39627989, -0.3439042 ,\n",
      "       -0.3181597 , -0.30159064, -0.31052264, -0.30972987, -0.29806513,\n",
      "       -0.29704434, -0.5538685 , -0.37832526, -0.32086332, -0.30175622,\n",
      "       -0.29909965, -0.296191  , -0.29153009, -0.2956181 , -0.29695045,\n",
      "       -0.54479979, -0.37062335, -0.31912116, -0.30238756, -0.29273787,\n",
      "       -0.2921422 , -0.29232011, -0.29119194, -0.29119124, -0.54367903,\n",
      "       -0.36690458, -0.31508514, -0.29780357, -0.29196267, -0.28964491,\n",
      "       -0.28873285, -0.28861143, -0.28881146, -0.54389023, -0.36705367,\n",
      "       -0.31519874, -0.29803092, -0.29219673, -0.28991362, -0.28909211,\n",
      "       -0.28870967, -0.28853243, -0.54453511, -0.36777436, -0.31608791,\n",
      "       -0.29891343, -0.29315533, -0.29094463, -0.28990105, -0.28955003,\n",
      "       -0.28966738, -0.54416956, -0.36865039, -0.31726437, -0.29983411,\n",
      "       -0.29375326, -0.29174647, -0.2909131 , -0.2905654 , -0.29039733,\n",
      "       -1.16524555, -1.06794087, -0.97510161, -0.91836778, -0.86319326,\n",
      "       -0.84129143, -0.80099841, -0.7755886 , -0.757279  , -1.08839747,\n",
      "       -0.93296219, -0.81668786, -0.76485574, -0.70150981, -0.66585247,\n",
      "       -0.63038868, -0.60443524, -0.57090956, -1.04752723, -0.88038946,\n",
      "       -0.77111047, -0.70387435, -0.64206141, -0.59832666, -0.5659406 ,\n",
      "       -0.55930211, -0.52690103, -1.04048605, -0.85306408, -0.75243763,\n",
      "       -0.66061969, -0.62036086, -0.58471693, -0.58239196, -0.58466261,\n",
      "       -0.57182511, -1.03641676, -0.85243848, -0.75109089, -0.66167013,\n",
      "       -0.62125931, -0.59507977, -0.57998799, -0.59800769, -0.56552753,\n",
      "       -1.03738178, -0.86023498, -0.74915244, -0.66333046, -0.62698471,\n",
      "       -0.59747967, -0.58604998, -0.57904848, -0.58797286, -1.03671959,\n",
      "       -0.85593423, -0.74461681, -0.66252643, -0.64571573, -0.59974974,\n",
      "       -0.58933086, -0.56302162, -0.59697065, -1.03584078, -0.85277443,\n",
      "       -0.75164881, -0.66671749, -0.6237794 , -0.60127813, -0.61319085,\n",
      "       -0.59532026, -0.58244091, -1.03877849, -0.85179968, -0.73357164,\n",
      "       -0.65402534, -0.62921462, -0.60926908, -0.60288071, -0.5907854 ,\n",
      "       -0.59836914, -1.05190374, -0.92851875, -0.84714188, -0.79949656,\n",
      "       -0.76130741, -0.73043982, -0.69192992, -0.65122821, -0.63833511,\n",
      "       -0.94635356, -0.81244286, -0.74534517, -0.68886422, -0.62225953,\n",
      "       -0.59088492, -0.55728159, -0.53318868, -0.51730864, -0.91181544,\n",
      "       -0.78664688, -0.69545202, -0.63364158, -0.60286568, -0.58660431,\n",
      "       -0.56344106, -0.51285278, -0.40449372, -0.8904214 , -0.7469455 ,\n",
      "       -0.65895233, -0.61234144, -0.58924459, -0.57551226, -0.56623744,\n",
      "       -0.48458245, -0.36446199, -0.87339125, -0.73119774, -0.65410162,\n",
      "       -0.62487643, -0.59781054, -0.58076557, -0.572335  , -0.5755883 ,\n",
      "       -0.5628089 , -0.86148146, -0.73942155, -0.65766464, -0.62809818,\n",
      "       -0.59946327, -0.58970519, -0.58361655, -0.56122753, -0.45599485,\n",
      "       -0.85233755, -0.70661149, -0.65875502, -0.63074488, -0.59877278,\n",
      "       -0.59504787, -0.57536231, -0.56457522, -0.56528425, -0.84798056,\n",
      "       -0.69787788, -0.64028928, -0.60651823, -0.57148967, -0.57796621,\n",
      "       -0.5603647 , -0.57072221, -0.56703167, -0.8455231 , -0.69879786,\n",
      "       -0.62819988, -0.60267777, -0.57245867, -0.49812545, -0.56342438,\n",
      "       -0.55995396, -0.436231  , -1.0705458 , -0.83531849, -0.69028195,\n",
      "       -0.61469566, -0.57613046, -0.55466774, -0.54365692, -0.53646575,\n",
      "       -0.53226641, -0.98304119, -0.60247451, -0.45882922, -0.39942677,\n",
      "       -0.35883012, -0.33914444, -0.32312156, -0.32791917, -0.31414683,\n",
      "       -0.93554542, -0.57096938, -0.43366358, -0.42204855, -0.35120227,\n",
      "       -0.31839132, -0.32149218, -0.308217  , -0.31609326, -0.8905254 ,\n",
      "       -0.59061915, -0.41815397, -0.363269  , -0.3417548 , -0.32436712,\n",
      "       -0.31104626, -0.32647237, -0.3103272 , -0.87305344, -0.55841468,\n",
      "       -0.43372316, -0.37400258, -0.32813688, -0.31046152, -0.30109879,\n",
      "       -0.31530763, -0.29384131, -0.90820898, -0.57384221, -0.40680002,\n",
      "       -0.351402  , -0.31847772, -0.32516475, -0.30320705, -0.32534351,\n",
      "       -0.30293575, -0.86844407, -0.55000757, -0.42692348, -0.36214552,\n",
      "       -0.33974602, -0.31619834, -0.31903291, -0.35351213, -0.29531143,\n",
      "       -0.90923433, -0.56175208, -0.42874722, -0.34119286, -0.32530711,\n",
      "       -0.3071205 , -0.30279605, -0.32950931, -0.38464113, -0.87520823,\n",
      "       -0.52744097, -0.49612243, -0.35182084, -0.33816362, -0.31737166,\n",
      "       -0.29512104, -0.30036694, -0.29807539, -1.22635598, -1.17702455,\n",
      "       -1.1352731 , -1.09873904, -1.06535338, -1.03500765, -1.00774998,\n",
      "       -0.98321473, -0.95948254, -1.18384114, -1.0892474 , -1.01073483,\n",
      "       -0.94298361, -0.88283566, -0.83170564, -0.78943969, -0.74998304,\n",
      "       -0.7096566 , -1.1548137 , -1.04509692, -0.95052422, -0.87046484,\n",
      "       -0.8017672 , -0.74131705, -0.6916585 , -0.6455679 , -0.60706123,\n",
      "       -1.14940462, -1.03496667, -0.93816317, -0.85541057, -0.78444027,\n",
      "       -0.72345241, -0.67101018, -0.62608817, -0.5871072 , -1.14945663,\n",
      "       -1.03473799, -0.93704031, -0.85310994, -0.78112933, -0.71950067,\n",
      "       -0.66611298, -0.62038169, -0.580864  , -1.14907459, -1.03407238,\n",
      "       -0.93614676, -0.85253989, -0.78056092, -0.71874565, -0.66584109,\n",
      "       -0.61985378, -0.58013127, -1.14902889, -1.03406938, -0.93607998,\n",
      "       -0.85199283, -0.78031402, -0.71870749, -0.66539713, -0.61973982,\n",
      "       -0.57986575, -1.14891581, -1.03391716, -0.93583539, -0.85219522,\n",
      "       -0.78024572, -0.71865149, -0.66574445, -0.61982899, -0.58018055,\n",
      "       -1.14881991, -1.03380161, -0.93564008, -0.85171276, -0.7801966 ,\n",
      "       -0.71866348, -0.66557333, -0.6199563 , -0.58037999, -1.31294073,\n",
      "       -1.29250951, -1.27196334, -1.25327573, -1.23809225, -1.22240402,\n",
      "       -1.20515785, -1.18889008, -1.1760813 , -1.304316  , -1.27346054,\n",
      "       -1.24703025, -1.22000876, -1.19481039, -1.17271704, -1.15314189,\n",
      "       -1.13174466, -1.11112697, -1.29305425, -1.25589556, -1.22254969,\n",
      "       -1.19421355, -1.16747342, -1.14004409, -1.11564655, -1.09224802,\n",
      "       -1.0699027 , -1.29186332, -1.25388506, -1.22130452, -1.19231751,\n",
      "       -1.16233708, -1.13609291, -1.11076148, -1.08517525, -1.06060826,\n",
      "       -1.29197061, -1.25450743, -1.22179152, -1.19220155, -1.16193084,\n",
      "       -1.13615278, -1.11048243, -1.08408735, -1.06034929, -1.29249874,\n",
      "       -1.25520627, -1.22242335, -1.19165301, -1.16256743, -1.13569402,\n",
      "       -1.10913513, -1.08241488, -1.06225923, -1.29249641, -1.25504906,\n",
      "       -1.22195977, -1.19210254, -1.16291336, -1.13503605, -1.10971633,\n",
      "       -1.08327706, -1.05941449, -1.29249961, -1.25547832, -1.22272795,\n",
      "       -1.19170037, -1.16205206, -1.13558337, -1.10948968, -1.08367981,\n",
      "       -1.05694833, -1.29249351, -1.25543079, -1.22219808, -1.19244461,\n",
      "       -1.1624546 , -1.13592136, -1.11050991, -1.08517113, -1.05931426,\n",
      "       -1.29052693, -1.249921  , -1.2149742 , -1.18613665, -1.16003214,\n",
      "       -1.13517131, -1.11191528, -1.09020254, -1.07058712, -1.26403583,\n",
      "       -1.2083931 , -1.16072522, -1.11710503, -1.07892962, -1.04982143,\n",
      "       -1.02077872, -0.99329968, -0.97018964, -1.25787033, -1.19458881,\n",
      "       -1.14070603, -1.09570307, -1.05430247, -1.01990424, -0.98693478,\n",
      "       -0.9557005 , -0.93262098, -1.25436633, -1.18786127, -1.13043834,\n",
      "       -1.07825945, -1.03258148, -0.99565573, -0.96466698, -0.93785514,\n",
      "       -0.91363981, -1.25307646, -1.18359207, -1.12318516, -1.06965445,\n",
      "       -1.02257793, -0.9802487 , -0.94559784, -0.91785576, -0.89061082,\n",
      "       -1.25099787, -1.17903894, -1.11744772, -1.06217671, -1.01677432,\n",
      "       -0.97785806, -0.94205337, -0.9122146 , -0.88512695, -1.24872928,\n",
      "       -1.17736355, -1.11668781, -1.05992195, -1.01207549, -0.97124184,\n",
      "       -0.93678403, -0.90657475, -0.87980549, -1.24683832, -1.17292662,\n",
      "       -1.11089553, -1.05706309, -1.01041308, -0.96884569, -0.93307326,\n",
      "       -0.89930522, -0.86862623, -1.24546352, -1.17092713, -1.10838027,\n",
      "       -1.05464383, -1.00704502, -0.96457347, -0.92861219, -0.89692109,\n",
      "       -0.86479595, -1.51489765, -1.44627779, -1.3864287 , -1.33442659,\n",
      "       -1.28822916, -1.24777239, -1.20487737, -1.14672018, -1.10735134,\n",
      "       -1.50419886, -1.41504215, -1.34285871, -1.28101048, -1.22877105,\n",
      "       -1.16893457, -1.13264134, -1.08383414, -1.01859238, -1.50328806,\n",
      "       -1.41242316, -1.33350071, -1.25876009, -1.19551614, -1.14128745,\n",
      "       -1.08682687, -1.03048491, -0.98460849, -1.50011004, -1.40801824,\n",
      "       -1.32870854, -1.25386293, -1.18920578, -1.10652847, -1.08360552,\n",
      "       -0.99923528, -0.92503197, -1.47763192, -1.3863668 , -1.31107192,\n",
      "       -1.23767337, -1.17019468, -1.11274537, -1.06385734, -0.96201037,\n",
      "       -0.9415083 , -1.47978545, -1.37402561, -1.29319198, -1.22140738,\n",
      "       -1.16114624, -1.0966245 , -1.04502198, -0.99788133, -0.96163263,\n",
      "       -1.48035531, -1.37694314, -1.29175878, -1.22902079, -1.15492766,\n",
      "       -1.0996822 , -1.03968453, -0.98698518, -0.95776071, -1.48363726,\n",
      "       -1.37041318, -1.29499537, -1.22396879, -1.1684855 , -1.10128509,\n",
      "       -1.04406136, -1.00966497, -0.92199062, -1.48146236, -1.37483769,\n",
      "       -1.2972202 , -1.22439389, -1.16297503, -1.10106673, -1.043504  ,\n",
      "       -0.99970848, -0.95893596]), 'split3_test_score': array([-0.00492986, -0.00336068, -0.00300323, -0.00283574, -0.00269536,\n",
      "       -0.00259753, -0.00252091, -0.00245134, -0.00239023, -0.00251051,\n",
      "       -0.00188899, -0.00165573, -0.00151124, -0.00143918, -0.0013863 ,\n",
      "       -0.0014425 , -0.00137435, -0.00135948, -0.00287959, -0.00260613,\n",
      "       -0.002522  , -0.00246462, -0.0024222 , -0.00259532, -0.00245851,\n",
      "       -0.00238704, -0.00242307, -0.00311596, -0.00299738, -0.00304597,\n",
      "       -0.00299872, -0.00293032, -0.00297948, -0.00296098, -0.00304643,\n",
      "       -0.00301668, -0.0033385 , -0.00358652, -0.00351489, -0.00358048,\n",
      "       -0.00359596, -0.00359744, -0.00356432, -0.00330962, -0.00328002,\n",
      "       -0.00464847, -0.00465733, -0.00480158, -0.00502954, -0.00478284,\n",
      "       -0.00486273, -0.00471584, -0.00467543, -0.00479136, -0.00604897,\n",
      "       -0.00604011, -0.0055963 , -0.00552934, -0.00610552, -0.00609967,\n",
      "       -0.0058299 , -0.0060728 , -0.0056733 , -0.00726762, -0.00752548,\n",
      "       -0.0075171 , -0.00758982, -0.00725682, -0.0074938 , -0.00738376,\n",
      "       -0.00749632, -0.00735048, -0.00780728, -0.00771449, -0.00766417,\n",
      "       -0.00777239, -0.00772679, -0.0075975 , -0.00771047, -0.00809194,\n",
      "       -0.00774798, -0.01715791, -0.00251484, -0.00246242, -0.00242779,\n",
      "       -0.00238632, -0.00232703, -0.00236467, -0.00235766, -0.00236137,\n",
      "       -0.00208971, -0.0018099 , -0.0018426 , -0.00169128, -0.00175859,\n",
      "       -0.00179781, -0.00199522, -0.00164106, -0.00165409, -0.00286257,\n",
      "       -0.00208467, -0.00181263, -0.002296  , -0.00234494, -0.00233297,\n",
      "       -0.00156252, -0.0023912 , -0.00245209, -0.00244305, -0.00267868,\n",
      "       -0.00206429, -0.00170388, -0.00244142, -0.0020608 , -0.00248382,\n",
      "       -0.00265462, -0.00256432, -0.00433358, -0.00203115, -0.0025444 ,\n",
      "       -0.00262333, -0.00275026, -0.00240625, -0.00200441, -0.00197698,\n",
      "       -0.00275789, -0.00337806, -0.00216145, -0.00288231, -0.00221414,\n",
      "       -0.00237962, -0.00158422, -0.00256293, -0.00142381, -0.00214766,\n",
      "       -0.00215944, -0.00180899, -0.00213817, -0.00184607, -0.00236839,\n",
      "       -0.00185638, -0.00199769, -0.0022731 , -0.00201097, -0.00163714,\n",
      "       -0.00406692, -0.00211968, -0.00189723, -0.00293071, -0.0023136 ,\n",
      "       -0.00186219, -0.00245839, -0.00222838, -0.00443412, -0.00800339,\n",
      "       -0.00144004, -0.00434798, -0.00380689, -0.00231377, -0.00226817,\n",
      "       -0.01957641, -0.00301709, -0.00342074, -0.00265362, -0.00238877,\n",
      "       -0.00221247, -0.00207954, -0.00202333, -0.00197702, -0.00193599,\n",
      "       -0.00190608, -0.00363966, -0.00301339, -0.00216122, -0.00207108,\n",
      "       -0.00184357, -0.00188413, -0.00222006, -0.00176799, -0.00190664,\n",
      "       -0.00248321, -0.00239429, -0.00213409, -0.001996  , -0.00214906,\n",
      "       -0.00220534, -0.00224426, -0.00196998, -0.0019816 , -0.00212251,\n",
      "       -0.00213116, -0.00241827, -0.00204273, -0.00241196, -0.00211404,\n",
      "       -0.00197794, -0.00234421, -0.00217506, -0.00235444, -0.00349271,\n",
      "       -0.00229254, -0.00272585, -0.00364741, -0.00235524, -0.00188465,\n",
      "       -0.00295166, -0.00295473, -0.00218478, -0.00252309, -0.00239683,\n",
      "       -0.0029872 , -0.00272598, -0.00209507, -0.00236288, -0.00246949,\n",
      "       -0.00259436, -0.00268597, -0.00263518, -0.00183288, -0.00250766,\n",
      "       -0.00289149, -0.00296006, -0.00198684, -0.00360195, -0.00189189,\n",
      "       -0.00280415, -0.00229728, -0.00381448, -0.00337211, -0.00291045,\n",
      "       -0.00322629, -0.00285145, -0.00226288, -0.0035908 , -0.00518261,\n",
      "       -0.00314992, -0.00814269, -0.00347311, -0.00263391, -0.00495769,\n",
      "       -0.0036766 , -0.00367872, -0.00401163, -0.0312697 , -0.0286514 ,\n",
      "       -0.02865139, -0.02865139, -0.02865139, -0.02865139, -0.02865139,\n",
      "       -0.02865139, -0.02865139, -0.01371358, -0.00577953, -0.00770517,\n",
      "       -0.01690469, -0.01174709, -0.01262554, -0.01046142, -0.0124732 ,\n",
      "       -0.00880965, -0.02147375, -0.00864319, -0.01497312, -0.00403489,\n",
      "       -0.00489747, -0.0049381 , -0.01659489, -0.00680394, -0.00884555,\n",
      "       -0.00502241, -0.00990056, -0.01010317, -0.00416886, -0.0042069 ,\n",
      "       -0.0107981 , -0.00958157, -0.00799474, -0.00926234, -0.00663349,\n",
      "       -0.00862397, -0.00949089, -0.00980073, -0.00335165, -0.00377611,\n",
      "       -0.00285944, -0.00223036, -0.00950756, -0.00559014, -0.00654248,\n",
      "       -0.0022027 , -0.00875877, -0.00362462, -0.00571266, -0.003097  ,\n",
      "       -0.0032089 , -0.01016254, -0.00363368, -0.00662605, -0.00607977,\n",
      "       -0.03507283, -0.00391345, -0.00376336, -0.00377755, -0.00387172,\n",
      "       -0.00328885, -0.01014876, -0.0089056 , -0.00978876, -0.00280131,\n",
      "       -0.00843645, -0.01525418, -0.00321373, -0.00848162, -0.00332826,\n",
      "       -0.01125684, -0.00281697, -0.00366742, -0.00325645, -0.00332411,\n",
      "       -0.00297777, -0.00353578, -0.00309071, -0.0097572 , -0.12206087,\n",
      "       -0.0605838 , -0.03202089, -0.01858079, -0.01225065, -0.00905371,\n",
      "       -0.00699499, -0.00585035, -0.00520007, -0.05727042, -0.01655984,\n",
      "       -0.00819345, -0.00539357, -0.00440114, -0.00386195, -0.00340892,\n",
      "       -0.0031646 , -0.00294229, -0.05065281, -0.01371325, -0.00615397,\n",
      "       -0.0039604 , -0.00313334, -0.0027851 , -0.00259764, -0.00249099,\n",
      "       -0.00250637, -0.04357904, -0.01153124, -0.00531188, -0.00369562,\n",
      "       -0.00323464, -0.0029466 , -0.00285649, -0.00296322, -0.00288904,\n",
      "       -0.03745189, -0.00991743, -0.00501463, -0.0037994 , -0.00359956,\n",
      "       -0.00357663, -0.00332265, -0.00339453, -0.00331869, -0.03953562,\n",
      "       -0.01060883, -0.00605816, -0.00509312, -0.00482802, -0.00485444,\n",
      "       -0.00471559, -0.00463696, -0.00469704, -0.04028151, -0.01108388,\n",
      "       -0.00699338, -0.00605251, -0.00600845, -0.00599314, -0.00582092,\n",
      "       -0.00587738, -0.00596075, -0.04177771, -0.01240938, -0.00845355,\n",
      "       -0.00756499, -0.00740093, -0.00732662, -0.00734734, -0.00732   ,\n",
      "       -0.00734935, -0.04164281, -0.0123482 , -0.00850824, -0.00788983,\n",
      "       -0.00783144, -0.00791479, -0.00789956, -0.00793324, -0.00784298,\n",
      "       -0.16395412, -0.11980227, -0.08221758, -0.05338224, -0.04489942,\n",
      "       -0.0339583 , -0.02880282, -0.02182731, -0.01939954, -0.11821611,\n",
      "       -0.056497  , -0.02543533, -0.01850361, -0.01150606, -0.00457182,\n",
      "       -0.00298796, -0.0017103 , -0.00173872, -0.10359329, -0.0467508 ,\n",
      "       -0.01631499, -0.00705313, -0.00298052, -0.00249647, -0.00255062,\n",
      "       -0.00169934, -0.00178641, -0.10173728, -0.04281437, -0.01431953,\n",
      "       -0.00317492, -0.00258988, -0.00288705, -0.00313748, -0.00197687,\n",
      "       -0.00200861, -0.09877997, -0.04094109, -0.01198621, -0.00362483,\n",
      "       -0.00216222, -0.00272861, -0.00201292, -0.00323755, -0.00168393,\n",
      "       -0.10208123, -0.0394888 , -0.00746423, -0.00278954, -0.00235459,\n",
      "       -0.00209313, -0.00177233, -0.00196107, -0.00151567, -0.09742487,\n",
      "       -0.03827631, -0.00811518, -0.00325265, -0.00230624, -0.0017788 ,\n",
      "       -0.00255957, -0.00200064, -0.00144765, -0.09807602, -0.04044726,\n",
      "       -0.00832797, -0.00313956, -0.00190131, -0.00225997, -0.00178219,\n",
      "       -0.00189673, -0.00175065, -0.09747984, -0.03942398, -0.00792833,\n",
      "       -0.00291278, -0.00245679, -0.00279728, -0.0031766 , -0.00176784,\n",
      "       -0.00157687, -0.11529598, -0.06354061, -0.03929654, -0.02783457,\n",
      "       -0.02282998, -0.01705669, -0.00758988, -0.00550755, -0.00487135,\n",
      "       -0.078873  , -0.03365674, -0.02138823, -0.00916058, -0.00367461,\n",
      "       -0.00337668, -0.00258759, -0.00253974, -0.00260414, -0.06690258,\n",
      "       -0.02672841, -0.00699125, -0.00258562, -0.00219714, -0.002013  ,\n",
      "       -0.00184604, -0.00185443, -0.00196288, -0.06100543, -0.01888496,\n",
      "       -0.00452722, -0.00239725, -0.00232061, -0.00214375, -0.00199498,\n",
      "       -0.00204537, -0.00207289, -0.05648761, -0.01237014, -0.00368533,\n",
      "       -0.00210803, -0.00145225, -0.00149559, -0.00165189, -0.00171951,\n",
      "       -0.00162134, -0.0528514 , -0.01192392, -0.00428821, -0.00286557,\n",
      "       -0.0026574 , -0.00263244, -0.00205905, -0.00221651, -0.00217418,\n",
      "       -0.05107084, -0.01147079, -0.00531333, -0.00495206, -0.00420068,\n",
      "       -0.00370857, -0.00348746, -0.00404374, -0.00371079, -0.05439842,\n",
      "       -0.01291147, -0.00732635, -0.00645751, -0.00461402, -0.00548864,\n",
      "       -0.00421752, -0.00596196, -0.00601782, -0.05277731, -0.01492195,\n",
      "       -0.00834311, -0.00524099, -0.00545102, -0.0057092 , -0.00560278,\n",
      "       -0.00432119, -0.00535683, -0.41528661, -0.23739268, -0.13974864,\n",
      "       -0.07420143, -0.04341052, -0.028467  , -0.01995333, -0.01485234,\n",
      "       -0.01264122, -0.31722422, -0.14016778, -0.07272078, -0.04318811,\n",
      "       -0.02881631, -0.01421502, -0.01442028, -0.00876281, -0.00952223,\n",
      "       -0.2940938 , -0.13167692, -0.07209199, -0.04013101, -0.02576449,\n",
      "       -0.01198331, -0.01492149, -0.00829813, -0.00672539, -0.28625406,\n",
      "       -0.1350394 , -0.07428739, -0.03676563, -0.02081525, -0.01364222,\n",
      "       -0.01028   , -0.00822829, -0.00711364, -0.28705787, -0.12551665,\n",
      "       -0.07368873, -0.028142  , -0.02503035, -0.01396083, -0.00830879,\n",
      "       -0.00789783, -0.00549532, -0.28967932, -0.13288215, -0.07030589,\n",
      "       -0.04009359, -0.02102095, -0.0099862 , -0.00718412, -0.00718252,\n",
      "       -0.00528516, -0.28489934, -0.13511757, -0.06907868, -0.04080704,\n",
      "       -0.01657477, -0.01376088, -0.00813368, -0.00748987, -0.00510377,\n",
      "       -0.29000671, -0.1294721 , -0.07359271, -0.04025861, -0.02332947,\n",
      "       -0.01590292, -0.00778545, -0.00693795, -0.00531429, -0.29209212,\n",
      "       -0.13373068, -0.06105706, -0.04037622, -0.01618271, -0.01335377,\n",
      "       -0.00996793, -0.00648575, -0.00397505, -0.23148154, -0.21637606,\n",
      "       -0.20114615, -0.1860118 , -0.17304422, -0.16085489, -0.14980223,\n",
      "       -0.13999004, -0.13100987, -0.22015807, -0.19055245, -0.16154892,\n",
      "       -0.13769853, -0.11854228, -0.1022125 , -0.08815624, -0.07637427,\n",
      "       -0.06631864, -0.20511824, -0.17244675, -0.14789401, -0.1274139 ,\n",
      "       -0.10916655, -0.09331882, -0.08003196, -0.06911087, -0.05958703,\n",
      "       -0.20655779, -0.16672181, -0.13838489, -0.11717282, -0.09918758,\n",
      "       -0.084058  , -0.07136002, -0.06047653, -0.0513608 , -0.20708822,\n",
      "       -0.16851432, -0.13757992, -0.11226701, -0.09280123, -0.0769477 ,\n",
      "       -0.06375714, -0.05291027, -0.04467439, -0.21034572, -0.17310069,\n",
      "       -0.14240549, -0.11754479, -0.09714101, -0.08053473, -0.06724563,\n",
      "       -0.05604101, -0.0469597 , -0.21087365, -0.17382053, -0.14349495,\n",
      "       -0.11849949, -0.09811597, -0.08132128, -0.0680623 , -0.05690124,\n",
      "       -0.04784296, -0.21101191, -0.17418527, -0.14446758, -0.11988387,\n",
      "       -0.0996468 , -0.0830814 , -0.06963001, -0.05877947, -0.04948036,\n",
      "       -0.21118125, -0.17429486, -0.14436743, -0.11966676, -0.09946685,\n",
      "       -0.08291671, -0.06929394, -0.05821699, -0.04903764, -0.26377966,\n",
      "       -0.24811983, -0.23344815, -0.22027289, -0.20650868, -0.19534252,\n",
      "       -0.18465513, -0.17760506, -0.17093004, -0.25560672, -0.23220769,\n",
      "       -0.21079591, -0.1906764 , -0.17290406, -0.15974577, -0.15055721,\n",
      "       -0.14007993, -0.12796541, -0.25425192, -0.22823966, -0.20427619,\n",
      "       -0.18381211, -0.16566936, -0.15090695, -0.13698966, -0.12386027,\n",
      "       -0.11102455, -0.25280459, -0.2264459 , -0.20211448, -0.18106929,\n",
      "       -0.16332816, -0.14843731, -0.13299546, -0.12032941, -0.10962551,\n",
      "       -0.2528193 , -0.22637919, -0.20214868, -0.18049575, -0.16289648,\n",
      "       -0.1479047 , -0.13329283, -0.12044014, -0.10861244, -0.25278996,\n",
      "       -0.22641009, -0.20185478, -0.18039059, -0.16269955, -0.14729404,\n",
      "       -0.13340359, -0.12017485, -0.10841074, -0.25281877, -0.22647151,\n",
      "       -0.20189961, -0.18046779, -0.1626855 , -0.14787651, -0.1332553 ,\n",
      "       -0.12061238, -0.1080601 , -0.25281926, -0.22637985, -0.20198932,\n",
      "       -0.18058784, -0.16319246, -0.14748514, -0.13322149, -0.1199634 ,\n",
      "       -0.10917179, -0.25276621, -0.22632508, -0.20169105, -0.18087554,\n",
      "       -0.16315316, -0.14819229, -0.13371955, -0.12059489, -0.10910585,\n",
      "       -0.25225378, -0.22769946, -0.20673426, -0.18815203, -0.17148126,\n",
      "       -0.1566199 , -0.1443595 , -0.13418874, -0.12441706, -0.23819751,\n",
      "       -0.20421436, -0.1777647 , -0.15584826, -0.13725227, -0.12209054,\n",
      "       -0.10888487, -0.09743232, -0.08745087, -0.23542081, -0.19921564,\n",
      "       -0.16966182, -0.14634474, -0.12724635, -0.11086767, -0.09652261,\n",
      "       -0.08481621, -0.07527569, -0.23402115, -0.19620998, -0.1655815 ,\n",
      "       -0.14123512, -0.1215762 , -0.10587065, -0.09192594, -0.07976139,\n",
      "       -0.0699473 , -0.2334608 , -0.1957465 , -0.16496932, -0.1402207 ,\n",
      "       -0.11929137, -0.10180743, -0.08653762, -0.07525271, -0.06593852,\n",
      "       -0.23253866, -0.19483087, -0.16305619, -0.13683775, -0.11561564,\n",
      "       -0.09810396, -0.08332301, -0.07118935, -0.0611751 , -0.23244398,\n",
      "       -0.19505575, -0.16500887, -0.1395669 , -0.11699908, -0.09709999,\n",
      "       -0.08197699, -0.07061218, -0.05989788, -0.23255526, -0.19465585,\n",
      "       -0.1632704 , -0.13781535, -0.11767066, -0.0993919 , -0.08463332,\n",
      "       -0.07247202, -0.06263677, -0.23269483, -0.19513822, -0.16393835,\n",
      "       -0.13802854, -0.11695554, -0.09914968, -0.08503757, -0.07263291,\n",
      "       -0.06215034, -0.72559531, -0.66612022, -0.61779952, -0.57675741,\n",
      "       -0.54163392, -0.50656553, -0.47899565, -0.45441227, -0.43175798,\n",
      "       -0.7012978 , -0.63269751, -0.57217615, -0.5236854 , -0.49624568,\n",
      "       -0.43849821, -0.416298  , -0.37651952, -0.33350372, -0.68983992,\n",
      "       -0.61259837, -0.54908198, -0.49282391, -0.44442381, -0.4064268 ,\n",
      "       -0.36964241, -0.34036016, -0.31813438, -0.6908605 , -0.61272456,\n",
      "       -0.55034403, -0.49544752, -0.44691587, -0.40678912, -0.3722505 ,\n",
      "       -0.3394578 , -0.3105339 , -0.69124153, -0.61480255, -0.54927141,\n",
      "       -0.49303702, -0.44604402, -0.40636965, -0.37097311, -0.33893096,\n",
      "       -0.30866549, -0.69153137, -0.61353575, -0.54932124, -0.49339894,\n",
      "       -0.4475102 , -0.40973324, -0.37080817, -0.34102154, -0.3106391 ,\n",
      "       -0.69130848, -0.61379732, -0.54896089, -0.49075273, -0.4461866 ,\n",
      "       -0.40603445, -0.37176851, -0.33895943, -0.30697121, -0.69149387,\n",
      "       -0.61338562, -0.54608397, -0.49183769, -0.44817306, -0.40634552,\n",
      "       -0.37158768, -0.33623189, -0.30840586, -0.69054107, -0.6133618 ,\n",
      "       -0.55016226, -0.49311499, -0.4465972 , -0.4074656 , -0.37242853,\n",
      "       -0.33816303, -0.31126249]), 'split4_test_score': array([-0.00508655, -0.00384609, -0.0032898 , -0.00320208, -0.00305041,\n",
      "       -0.00317023, -0.00288929, -0.00313858, -0.00287577, -0.00272591,\n",
      "       -0.00211224, -0.00194524, -0.00186315, -0.00180524, -0.0018025 ,\n",
      "       -0.0017558 , -0.00173783, -0.00177634, -0.00121322, -0.00119318,\n",
      "       -0.00115616, -0.00112733, -0.00116218, -0.00114608, -0.00116848,\n",
      "       -0.00122684, -0.0012729 , -0.00128703, -0.0012151 , -0.00121706,\n",
      "       -0.00120922, -0.00118658, -0.00121399, -0.00116337, -0.00125155,\n",
      "       -0.00118324, -0.00217975, -0.00212367, -0.00224728, -0.00224057,\n",
      "       -0.00204366, -0.0021014 , -0.00213408, -0.00215554, -0.00227163,\n",
      "       -0.0038144 , -0.00384791, -0.00374432, -0.00389225, -0.00404497,\n",
      "       -0.00379006, -0.00373707, -0.00416527, -0.00404057, -0.00612719,\n",
      "       -0.00616292, -0.0065742 , -0.00665381, -0.00657483, -0.00640296,\n",
      "       -0.00652981, -0.00652641, -0.00653808, -0.00763742, -0.00762263,\n",
      "       -0.00753982, -0.00768735, -0.00722277, -0.00744922, -0.00737827,\n",
      "       -0.00744014, -0.00738293, -0.00770153, -0.00821493, -0.00801309,\n",
      "       -0.00795323, -0.00847182, -0.00785596, -0.00785954, -0.00807481,\n",
      "       -0.0082521 , -0.01705453, -0.00477907, -0.00425518, -0.00438044,\n",
      "       -0.00410502, -0.00394943, -0.00436368, -0.00374224, -0.00381437,\n",
      "       -0.0037974 , -0.00338608, -0.00228572, -0.00286877, -0.00283825,\n",
      "       -0.00295734, -0.00239996, -0.00322143, -0.00203028, -0.00308235,\n",
      "       -0.00230566, -0.00200369, -0.0017092 , -0.00176616, -0.00217761,\n",
      "       -0.00207594, -0.00208825, -0.00226842, -0.00173266, -0.00149228,\n",
      "       -0.00223319, -0.00209123, -0.00106871, -0.00106759, -0.00172092,\n",
      "       -0.00124627, -0.00154633, -0.00176064, -0.00259823, -0.00148033,\n",
      "       -0.00117916, -0.00201396, -0.00135339, -0.00231586, -0.00118912,\n",
      "       -0.00177065, -0.0018117 , -0.00172741, -0.00154011, -0.00182226,\n",
      "       -0.00145605, -0.00174982, -0.00125091, -0.00166255, -0.00233728,\n",
      "       -0.00186267, -0.00390786, -0.00381555, -0.00136211, -0.00105826,\n",
      "       -0.00241469, -0.00106837, -0.00138327, -0.00261033, -0.00132753,\n",
      "       -0.00170468, -0.00194466, -0.00116846, -0.00351822, -0.00222137,\n",
      "       -0.00183089, -0.00188493, -0.00196235, -0.00173089, -0.00173796,\n",
      "       -0.00160218, -0.00193567, -0.00141689, -0.00140774, -0.00180545,\n",
      "       -0.00322971, -0.00180938, -0.00503784, -0.00350977, -0.00341778,\n",
      "       -0.00300092, -0.00300877, -0.00317876, -0.00286655, -0.00282581,\n",
      "       -0.0026452 , -0.00389342, -0.00396018, -0.00325125, -0.0031545 ,\n",
      "       -0.00302328, -0.0032817 , -0.00276737, -0.00298927, -0.0031033 ,\n",
      "       -0.00268684, -0.00283362, -0.0026957 , -0.00320693, -0.00265692,\n",
      "       -0.00257269, -0.00306211, -0.00323692, -0.00276512, -0.00564747,\n",
      "       -0.00232615, -0.00150731, -0.00210319, -0.00203912, -0.00214948,\n",
      "       -0.00172241, -0.00189629, -0.00255011, -0.00222826, -0.00227499,\n",
      "       -0.00214914, -0.00325127, -0.00263189, -0.00197922, -0.00580516,\n",
      "       -0.00636246, -0.00357435, -0.00162764, -0.00201269, -0.00300991,\n",
      "       -0.00300993, -0.00296892, -0.00214514, -0.00206413, -0.00222293,\n",
      "       -0.00239899, -0.00557231, -0.00311693, -0.00357269, -0.00323688,\n",
      "       -0.00354758, -0.00525239, -0.00404038, -0.00375458, -0.00344842,\n",
      "       -0.0035837 , -0.00492435, -0.00354416, -0.00659171, -0.00382003,\n",
      "       -0.0038276 , -0.00377973, -0.02612505, -0.00246304, -0.00446006,\n",
      "       -0.00432645, -0.0046737 , -0.00540107, -0.00298697, -0.00395998,\n",
      "       -0.00624338, -0.00460062, -0.00417889, -0.02985122, -0.02817144,\n",
      "       -0.0237546 , -0.02808764, -0.0237546 , -0.0237546 , -0.02808764,\n",
      "       -0.02808764, -0.0237546 , -0.01782391, -0.01144474, -0.0143175 ,\n",
      "       -0.01401956, -0.01576447, -0.01377119, -0.02324588, -0.06000313,\n",
      "       -0.03045023, -0.01836602, -0.04267316, -0.01790278, -0.02275169,\n",
      "       -0.01124949, -0.01822817, -0.02105468, -0.00745746, -0.02009466,\n",
      "       -0.00621126, -0.01311505, -0.0067392 , -0.01146953, -0.00574005,\n",
      "       -0.0540207 , -0.00952132, -0.00420085, -0.00519372, -0.0217698 ,\n",
      "       -0.00715105, -0.01179485, -0.00632845, -0.01247867, -0.01316246,\n",
      "       -0.00509712, -0.01592695, -0.01706291, -0.00518471, -0.01067303,\n",
      "       -0.022376  , -0.01210694, -0.01287937, -0.00796103, -0.01343514,\n",
      "       -0.01493937, -0.0158512 , -0.00681927, -0.01305029, -0.00559523,\n",
      "       -0.01018376, -0.01191877, -0.00264576, -0.00525094, -0.00384745,\n",
      "       -0.0046004 , -0.01454467, -0.01278632, -0.00472938, -0.01140321,\n",
      "       -0.01321267, -0.00542514, -0.00992802, -0.00991334, -0.00484106,\n",
      "       -0.00521486, -0.00692107, -0.00506718, -0.00816528, -0.00838225,\n",
      "       -0.00693773, -0.00420485, -0.01213869, -0.00491181, -0.14417653,\n",
      "       -0.07415753, -0.04048522, -0.02425405, -0.01562514, -0.01052136,\n",
      "       -0.00797597, -0.00625965, -0.00526658, -0.07367435, -0.02363253,\n",
      "       -0.01032654, -0.00569227, -0.00407461, -0.00328792, -0.00311339,\n",
      "       -0.00289148, -0.00289725, -0.05546511, -0.01192629, -0.00359605,\n",
      "       -0.00165739, -0.00124401, -0.00105992, -0.00099966, -0.00097356,\n",
      "       -0.00096512, -0.04720736, -0.00922697, -0.0029098 , -0.00183253,\n",
      "       -0.00158343, -0.00149702, -0.00152688, -0.00150275, -0.00154194,\n",
      "       -0.04810858, -0.01016218, -0.00364798, -0.00242767, -0.00214936,\n",
      "       -0.00205563, -0.00201204, -0.00200538, -0.00198131, -0.05318417,\n",
      "       -0.0123508 , -0.00558454, -0.00400273, -0.00362681, -0.00346178,\n",
      "       -0.00345887, -0.00346305, -0.00347409, -0.0525814 , -0.01551982,\n",
      "       -0.00853059, -0.0069096 , -0.00660985, -0.00631583, -0.00645547,\n",
      "       -0.00634886, -0.00651117, -0.05268999, -0.01587334, -0.00938053,\n",
      "       -0.00787077, -0.0076121 , -0.00749006, -0.00741865, -0.00739511,\n",
      "       -0.00739176, -0.05252519, -0.01611498, -0.01006684, -0.00856524,\n",
      "       -0.00816782, -0.00811751, -0.00811909, -0.00828794, -0.00801746,\n",
      "       -0.22122177, -0.15399307, -0.1188949 , -0.08318953, -0.05865078,\n",
      "       -0.04729138, -0.03126802, -0.02195237, -0.01950575, -0.17062836,\n",
      "       -0.08934983, -0.04159346, -0.01765176, -0.00834262, -0.0051715 ,\n",
      "       -0.00409603, -0.00351875, -0.00463777, -0.14249419, -0.05916431,\n",
      "       -0.0227694 , -0.00922081, -0.00441608, -0.00373292, -0.00346087,\n",
      "       -0.0046967 , -0.00296672, -0.13634818, -0.04928452, -0.01311974,\n",
      "       -0.00645834, -0.00508301, -0.00404361, -0.00247107, -0.00231325,\n",
      "       -0.00096391, -0.13766061, -0.04589774, -0.01176969, -0.00597451,\n",
      "       -0.00470152, -0.00452729, -0.00202904, -0.00277977, -0.00165049,\n",
      "       -0.1370997 , -0.04652363, -0.0120886 , -0.00599676, -0.00313897,\n",
      "       -0.00355109, -0.00224053, -0.00216901, -0.001561  , -0.13891352,\n",
      "       -0.04749208, -0.01231018, -0.00537646, -0.00279809, -0.00246486,\n",
      "       -0.00233829, -0.00186499, -0.00137001, -0.1362852 , -0.04628967,\n",
      "       -0.01064576, -0.00546844, -0.00355838, -0.00207193, -0.00156577,\n",
      "       -0.00146972, -0.0010461 , -0.13692406, -0.04505832, -0.01251921,\n",
      "       -0.0041512 , -0.00179177, -0.00164572, -0.00187038, -0.00155662,\n",
      "       -0.00182147, -0.15398631, -0.08502561, -0.05060462, -0.02896602,\n",
      "       -0.022053  , -0.01503477, -0.00897466, -0.00719339, -0.00575643,\n",
      "       -0.09980136, -0.03533448, -0.01779619, -0.00925508, -0.00541774,\n",
      "       -0.00498036, -0.00429191, -0.00341566, -0.00327247, -0.07512565,\n",
      "       -0.02512876, -0.0079244 , -0.0040126 , -0.00296645, -0.00261798,\n",
      "       -0.00269018, -0.00268377, -0.00261246, -0.0624019 , -0.01671818,\n",
      "       -0.00621061, -0.00258783, -0.00193051, -0.00179877, -0.00175703,\n",
      "       -0.00150631, -0.00160671, -0.05669072, -0.01213583, -0.00487658,\n",
      "       -0.00299581, -0.00269792, -0.00369732, -0.00515795, -0.00269431,\n",
      "       -0.0049861 , -0.05570051, -0.01120006, -0.00507477, -0.00264886,\n",
      "       -0.00263197, -0.00269716, -0.00515453, -0.00191535, -0.00429378,\n",
      "       -0.05442519, -0.00999476, -0.00463454, -0.00352951, -0.00345175,\n",
      "       -0.00309437, -0.00314046, -0.00230377, -0.00329547, -0.05461606,\n",
      "       -0.01164847, -0.00510236, -0.00438372, -0.00466644, -0.0043681 ,\n",
      "       -0.00416358, -0.00359488, -0.01036222, -0.05180338, -0.01047219,\n",
      "       -0.00482968, -0.0048284 , -0.00359844, -0.00449091, -0.00353702,\n",
      "       -0.00434973, -0.00381423, -0.31985797, -0.17746647, -0.09404259,\n",
      "       -0.05091739, -0.03459977, -0.02781071, -0.02073732, -0.0185367 ,\n",
      "       -0.01643368, -0.26692868, -0.11392432, -0.06286676, -0.03267351,\n",
      "       -0.01954437, -0.01192786, -0.00836442, -0.00929339, -0.00706319,\n",
      "       -0.22815409, -0.10961212, -0.0507014 , -0.02927468, -0.01677644,\n",
      "       -0.01043246, -0.00793795, -0.00524695, -0.00589789, -0.21731189,\n",
      "       -0.09929409, -0.04817459, -0.02735104, -0.01634195, -0.01021509,\n",
      "       -0.00620808, -0.00483925, -0.00439774, -0.21964733, -0.10515302,\n",
      "       -0.0505019 , -0.02754137, -0.01565651, -0.00846497, -0.00711241,\n",
      "       -0.00540739, -0.00449853, -0.21752407, -0.10053574, -0.05082245,\n",
      "       -0.026985  , -0.01536968, -0.00813662, -0.00596645, -0.00437887,\n",
      "       -0.00381046, -0.21991263, -0.10402989, -0.05084937, -0.0281132 ,\n",
      "       -0.01465659, -0.00893277, -0.00691889, -0.00534552, -0.00419547,\n",
      "       -0.22396811, -0.10036092, -0.04848177, -0.02701543, -0.01378577,\n",
      "       -0.01003625, -0.00678443, -0.0056647 , -0.0042492 , -0.2205139 ,\n",
      "       -0.10312951, -0.05093215, -0.02660986, -0.01628977, -0.00902837,\n",
      "       -0.00658737, -0.00447825, -0.00403966, -0.27468925, -0.25287568,\n",
      "       -0.23443788, -0.2175926 , -0.20257121, -0.18882106, -0.17625162,\n",
      "       -0.1649775 , -0.15452859, -0.25721848, -0.22097197, -0.18992885,\n",
      "       -0.16446704, -0.14280717, -0.12481645, -0.10918738, -0.09567957,\n",
      "       -0.08400743, -0.25279872, -0.21405831, -0.18050937, -0.15249736,\n",
      "       -0.12948012, -0.10907389, -0.09188307, -0.07744683, -0.06551426,\n",
      "       -0.25021519, -0.20870726, -0.17294815, -0.14275022, -0.11806511,\n",
      "       -0.0979579 , -0.08142444, -0.06787305, -0.05667816, -0.24990336,\n",
      "       -0.20824326, -0.17423452, -0.14542416, -0.11997266, -0.09919249,\n",
      "       -0.08218969, -0.06870205, -0.05758453, -0.25009716, -0.20827775,\n",
      "       -0.17381369, -0.14542665, -0.12210408, -0.10296879, -0.08700862,\n",
      "       -0.07380578, -0.06287552, -0.24970497, -0.20772644, -0.17321999,\n",
      "       -0.14474466, -0.12124674, -0.10205721, -0.08598094, -0.07296814,\n",
      "       -0.06209899, -0.24960862, -0.20781351, -0.17336606, -0.14494341,\n",
      "       -0.12149407, -0.10214415, -0.08621295, -0.07303537, -0.06204774,\n",
      "       -0.24945833, -0.20776846, -0.17316588, -0.14462874, -0.12141996,\n",
      "       -0.10195312, -0.08587714, -0.07281703, -0.06207097, -0.33642171,\n",
      "       -0.32056036, -0.30366062, -0.28852226, -0.27667121, -0.26541911,\n",
      "       -0.25455314, -0.24200614, -0.23119679, -0.32719057, -0.30400706,\n",
      "       -0.28065746, -0.2596079 , -0.24162035, -0.22321658, -0.20803712,\n",
      "       -0.19220426, -0.17982595, -0.32286185, -0.29358017, -0.2689474 ,\n",
      "       -0.24585983, -0.22432225, -0.20447775, -0.18788429, -0.17155069,\n",
      "       -0.15634684, -0.32256114, -0.29213078, -0.26534482, -0.24240062,\n",
      "       -0.21941727, -0.20101077, -0.18475198, -0.16900682, -0.15350322,\n",
      "       -0.32245803, -0.29147281, -0.2652062 , -0.24151385, -0.22043287,\n",
      "       -0.20157854, -0.18387046, -0.16744015, -0.15211545, -0.32244512,\n",
      "       -0.29178852, -0.26532809, -0.24097228, -0.21995847, -0.20125693,\n",
      "       -0.18504597, -0.16771361, -0.1515904 , -0.32242426, -0.29155848,\n",
      "       -0.26536505, -0.2418368 , -0.22058968, -0.20229803, -0.18533636,\n",
      "       -0.16761376, -0.15185466, -0.32244436, -0.2917943 , -0.26561913,\n",
      "       -0.24176314, -0.21991524, -0.20119662, -0.18380394, -0.16812344,\n",
      "       -0.15219006, -0.32246131, -0.29184924, -0.2654638 , -0.24090284,\n",
      "       -0.22031016, -0.20214133, -0.18497587, -0.16809004, -0.15165916,\n",
      "       -0.32240312, -0.29330637, -0.26884304, -0.24768015, -0.22837966,\n",
      "       -0.2099579 , -0.19210656, -0.17703796, -0.16508001, -0.30493629,\n",
      "       -0.26489814, -0.23121376, -0.20434208, -0.18020954, -0.15988337,\n",
      "       -0.14122193, -0.12492361, -0.11194879, -0.29868967, -0.25386759,\n",
      "       -0.21505494, -0.18249672, -0.15472336, -0.13128669, -0.1122981 ,\n",
      "       -0.09726387, -0.08568996, -0.29462895, -0.24681937, -0.20425135,\n",
      "       -0.16915695, -0.14269599, -0.1195917 , -0.10106479, -0.08619476,\n",
      "       -0.07342663, -0.29112896, -0.24214149, -0.19737458, -0.16228946,\n",
      "       -0.13547667, -0.11360657, -0.09520522, -0.08088882, -0.06792572,\n",
      "       -0.28994194, -0.23854152, -0.19729052, -0.16209067, -0.13532724,\n",
      "       -0.11278785, -0.09405737, -0.07913086, -0.06599596, -0.29160515,\n",
      "       -0.2411402 , -0.19920946, -0.16399504, -0.13615794, -0.11394981,\n",
      "       -0.095097  , -0.07898821, -0.06644811, -0.2915141 , -0.24136821,\n",
      "       -0.19926976, -0.16324178, -0.13546411, -0.11199729, -0.09281942,\n",
      "       -0.07769666, -0.06489762, -0.2914808 , -0.24127526, -0.19924622,\n",
      "       -0.16336017, -0.13442255, -0.11109081, -0.0920047 , -0.07644451,\n",
      "       -0.06303079, -0.57776427, -0.53836848, -0.49803491, -0.46907072,\n",
      "       -0.43185759, -0.39991786, -0.37984337, -0.36083003, -0.34003352,\n",
      "       -0.55211923, -0.48756305, -0.44342328, -0.41389401, -0.38566518,\n",
      "       -0.3584944 , -0.33589753, -0.32688013, -0.27276138, -0.55181567,\n",
      "       -0.48409328, -0.42988846, -0.38903627, -0.35154447, -0.32055312,\n",
      "       -0.29442351, -0.26864304, -0.24485779, -0.54829078, -0.48136976,\n",
      "       -0.42625578, -0.38240015, -0.34665246, -0.31033704, -0.28832102,\n",
      "       -0.26210426, -0.24171098, -0.54983821, -0.47993745, -0.42559859,\n",
      "       -0.38387444, -0.34325802, -0.31344018, -0.28357545, -0.25760138,\n",
      "       -0.23944001, -0.54967464, -0.48098056, -0.42445402, -0.38050544,\n",
      "       -0.34381713, -0.31443717, -0.28331209, -0.26131159, -0.23921475,\n",
      "       -0.54935262, -0.48136589, -0.42451658, -0.38226997, -0.34141363,\n",
      "       -0.31029481, -0.28510143, -0.25972078, -0.24027964, -0.54926306,\n",
      "       -0.48023115, -0.42431834, -0.37944461, -0.34472711, -0.31170901,\n",
      "       -0.28538345, -0.25939588, -0.23816655, -0.55135873, -0.48098841,\n",
      "       -0.42400938, -0.3836201 , -0.3455837 , -0.31327798, -0.28593003,\n",
      "       -0.2581021 , -0.23676067]), 'mean_test_score': array([-0.07207321, -0.06574875, -0.06440082, -0.06358778, -0.06300575,\n",
      "       -0.06266466, -0.06235775, -0.06226939, -0.06207436, -0.06723102,\n",
      "       -0.06716589, -0.06586073, -0.06192909, -0.06593092, -0.06679941,\n",
      "       -0.06759424, -0.07212948, -0.07210183, -0.07136849, -0.07359676,\n",
      "       -0.06762259, -0.06299929, -0.06707026, -0.06593978, -0.07177298,\n",
      "       -0.06362927, -0.06314294, -0.06505773, -0.07656294, -0.07439468,\n",
      "       -0.0691537 , -0.06442795, -0.07217703, -0.07230003, -0.06632082,\n",
      "       -0.0677391 , -0.06219844, -0.0631645 , -0.06216119, -0.06323529,\n",
      "       -0.06187822, -0.06219333, -0.06249854, -0.06318951, -0.06220851,\n",
      "       -0.07068106, -0.07098381, -0.07109273, -0.07102892, -0.07037657,\n",
      "       -0.07048861, -0.07166614, -0.06930996, -0.06980131, -0.07712394,\n",
      "       -0.07757515, -0.07735292, -0.07767945, -0.07758041, -0.07758151,\n",
      "       -0.07774321, -0.07776639, -0.07768565, -0.07889541, -0.07919709,\n",
      "       -0.07906965, -0.07905701, -0.07882558, -0.07909163, -0.07892032,\n",
      "       -0.0789616 , -0.07882346, -0.07978147, -0.07972258, -0.07960486,\n",
      "       -0.07978964, -0.07974954, -0.07958091, -0.07960379, -0.08001883,\n",
      "       -0.07996776, -0.18008842, -0.13314391, -0.11809581, -0.11764646,\n",
      "       -0.11635953, -0.11522803, -0.11380266, -0.1156532 , -0.11230841,\n",
      "       -0.1253092 , -0.11066111, -0.10424611, -0.10061729, -0.09598474,\n",
      "       -0.10261448, -0.07814681, -0.09939235, -0.06962889, -0.12084699,\n",
      "       -0.11228736, -0.1030894 , -0.10922791, -0.09529137, -0.10302449,\n",
      "       -0.06905146, -0.09327783, -0.06685202, -0.12426119, -0.10612884,\n",
      "       -0.10575779, -0.10694902, -0.09601016, -0.07893445, -0.07589356,\n",
      "       -0.0866204 , -0.0714506 , -0.1205157 , -0.12504176, -0.11061299,\n",
      "       -0.07838981, -0.10900568, -0.08513986, -0.0791944 , -0.08485113,\n",
      "       -0.08876236, -0.12185951, -0.11897001, -0.10710599, -0.07602863,\n",
      "       -0.07917364, -0.07507178, -0.07988723, -0.07010044, -0.10751639,\n",
      "       -0.12441123, -0.09765716, -0.07709815, -0.09091344, -0.07758292,\n",
      "       -0.10540946, -0.09105088, -0.08075415, -0.07381035, -0.11338569,\n",
      "       -0.09881217, -0.11450604, -0.08060311, -0.08808188, -0.09146289,\n",
      "       -0.08058629, -0.10008711, -0.08061545, -0.11304479, -0.10856317,\n",
      "       -0.09385752, -0.08190666, -0.06962671, -0.10096433, -0.08770932,\n",
      "       -0.0929854 , -0.08319074, -0.13981878, -0.11155488, -0.1072605 ,\n",
      "       -0.06653907, -0.06300519, -0.06264828, -0.06232934, -0.06206056,\n",
      "       -0.06195174, -0.10030206, -0.06590265, -0.07021276, -0.07073192,\n",
      "       -0.06593687, -0.06628846, -0.06457381, -0.06250008, -0.06250795,\n",
      "       -0.0728222 , -0.0688912 , -0.07125398, -0.06775291, -0.07566308,\n",
      "       -0.07823323, -0.07168496, -0.08355768, -0.0717499 , -0.07221613,\n",
      "       -0.06264168, -0.06314415, -0.06894223, -0.06326155, -0.06478523,\n",
      "       -0.07627978, -0.07266525, -0.06675845, -0.10901652, -0.07398472,\n",
      "       -0.0721859 , -0.0835551 , -0.06403776, -0.06850089, -0.06655275,\n",
      "       -0.06691573, -0.06243395, -0.10049207, -0.06616012, -0.06454948,\n",
      "       -0.06672405, -0.06908564, -0.06142687, -0.06711709, -0.07029471,\n",
      "       -0.06397681, -0.12247089, -0.07097485, -0.06475501, -0.06385677,\n",
      "       -0.06598595, -0.0679351 , -0.07581305, -0.06987503, -0.06158321,\n",
      "       -0.12565897, -0.08702346, -0.06857159, -0.06339492, -0.08770124,\n",
      "       -0.08027567, -0.08761157, -0.07856296, -0.0748452 , -0.09898522,\n",
      "       -0.10744905, -0.08812704, -0.07213938, -0.09507701, -0.0795434 ,\n",
      "       -0.1088128 , -0.12187319, -0.12132564, -0.12203505, -0.07648064,\n",
      "       -0.07559471, -0.07636423, -0.07559471, -0.07559471, -0.07636423,\n",
      "       -0.07646132, -0.07559471, -0.09516995, -0.09050588, -0.08366996,\n",
      "       -0.09366188, -0.07653472, -0.0964826 , -0.08840391, -0.09465407,\n",
      "       -0.08789973, -0.07465487, -0.0926076 , -0.08541987, -0.09630908,\n",
      "       -0.09686454, -0.08553848, -0.07320149, -0.09949984, -0.0749647 ,\n",
      "       -0.07784217, -0.08141998, -0.10043606, -0.09626501, -0.07691471,\n",
      "       -0.10625084, -0.0841797 , -0.09677004, -0.07872851, -0.13691161,\n",
      "       -0.08804398, -0.12126412, -0.10067317, -0.08741391, -0.08984453,\n",
      "       -0.08031957, -0.08002455, -0.1518158 , -0.10231058, -0.09620298,\n",
      "       -0.10933354, -0.11610044, -0.08684777, -0.10460479, -0.08516283,\n",
      "       -0.0924168 , -0.08871822, -0.08790744, -0.09222401, -0.09315545,\n",
      "       -0.08425624, -0.09515632, -0.10185175, -0.07945873, -0.08195128,\n",
      "       -0.10235221, -0.09009128, -0.10411297, -0.09200882, -0.0917252 ,\n",
      "       -0.09676774, -0.08522635, -0.08047503, -0.09388175, -0.10059701,\n",
      "       -0.10708613, -0.10719394, -0.11647669, -0.08222634, -0.08896266,\n",
      "       -0.10775302, -0.08109411, -0.07852486, -0.09631467, -0.33022856,\n",
      "       -0.2280874 , -0.1636964 , -0.12891339, -0.10839669, -0.09530595,\n",
      "       -0.0865047 , -0.08057132, -0.07629936, -0.19121248, -0.11020306,\n",
      "       -0.0855967 , -0.07666739, -0.06940151, -0.07108682, -0.06774978,\n",
      "       -0.06600643, -0.0678993 , -0.15842344, -0.09212414, -0.07720836,\n",
      "       -0.07194583, -0.06908804, -0.07037611, -0.07249893, -0.06845909,\n",
      "       -0.06932244, -0.15314554, -0.08505998, -0.07122351, -0.06639724,\n",
      "       -0.06570907, -0.06524412, -0.06641402, -0.06479868, -0.068259  ,\n",
      "       -0.16676656, -0.08895996, -0.0689379 , -0.06414012, -0.06190315,\n",
      "       -0.06186709, -0.0616851 , -0.06106464, -0.06094116, -0.16985289,\n",
      "       -0.09977149, -0.08143137, -0.07437431, -0.07197221, -0.07147177,\n",
      "       -0.07090538, -0.07074232, -0.07075704, -0.17068027, -0.10284306,\n",
      "       -0.08588027, -0.08045585, -0.07883701, -0.07809977, -0.0777324 ,\n",
      "       -0.0775502 , -0.07760387, -0.17141469, -0.10333615, -0.08667448,\n",
      "       -0.08159919, -0.07999356, -0.07947313, -0.07912912, -0.07900644,\n",
      "       -0.07902556, -0.17089652, -0.10376911, -0.08740769, -0.08237477,\n",
      "       -0.08071676, -0.08020476, -0.07992813, -0.07994031, -0.0798064 ,\n",
      "       -0.4182184 , -0.35256116, -0.30458076, -0.26684992, -0.24043132,\n",
      "       -0.22217661, -0.20426365, -0.19308145, -0.1878733 , -0.36602311,\n",
      "       -0.27266061, -0.21445207, -0.18805972, -0.16634468, -0.15232598,\n",
      "       -0.1419217 , -0.13451646, -0.12641747, -0.34052587, -0.24526829,\n",
      "       -0.19197388, -0.16394033, -0.14559187, -0.1338025 , -0.12693293,\n",
      "       -0.12383447, -0.11738913, -0.33605429, -0.23390514, -0.18345044,\n",
      "       -0.15153952, -0.13923653, -0.13103974, -0.12908724, -0.12954691,\n",
      "       -0.12379074, -0.33489596, -0.23270252, -0.18104748, -0.15094577,\n",
      "       -0.13965124, -0.13316427, -0.12866403, -0.13170981, -0.12182075,\n",
      "       -0.33591317, -0.23455125, -0.17935832, -0.15146359, -0.14043281,\n",
      "       -0.13278236, -0.12971828, -0.12322961, -0.12842092, -0.33484193,\n",
      "       -0.23235622, -0.17763714, -0.15049218, -0.14362225, -0.13281021,\n",
      "       -0.12996342, -0.12243155, -0.12871897, -0.33452074, -0.23218586,\n",
      "       -0.17909406, -0.15044246, -0.13942176, -0.13007296, -0.13411881,\n",
      "       -0.12798211, -0.12436718, -0.33520085, -0.23171043, -0.17620461,\n",
      "       -0.14855124, -0.14046238, -0.13397608, -0.13290587, -0.12784912,\n",
      "       -0.12676649, -0.35177383, -0.27333973, -0.22902828, -0.20540982,\n",
      "       -0.19117971, -0.17688556, -0.16149863, -0.15091235, -0.14689454,\n",
      "       -0.28995479, -0.21196409, -0.18361132, -0.16033289, -0.14043243,\n",
      "       -0.13190135, -0.12307439, -0.11584862, -0.11095558, -0.26641782,\n",
      "       -0.20061413, -0.16345643, -0.1434133 , -0.13372807, -0.12765141,\n",
      "       -0.12095063, -0.10976034, -0.08339127, -0.25275159, -0.18452424,\n",
      "       -0.15290229, -0.13745917, -0.13097936, -0.12612242, -0.1210078 ,\n",
      "       -0.10179915, -0.0796569 , -0.24530634, -0.17507737, -0.14937557,\n",
      "       -0.13760967, -0.1310969 , -0.12690094, -0.12098278, -0.12124747,\n",
      "       -0.11507546, -0.24072246, -0.17611717, -0.14927066, -0.14012476,\n",
      "       -0.13163917, -0.13148204, -0.12705941, -0.12074676, -0.0996874 ,\n",
      "       -0.23581881, -0.16755556, -0.14691893, -0.14209485, -0.13348244,\n",
      "       -0.12962461, -0.1272573 , -0.12159592, -0.12258134, -0.23603931,\n",
      "       -0.16657237, -0.14343439, -0.13445639, -0.12657238, -0.12661413,\n",
      "       -0.12273751, -0.12246575, -0.12321209, -0.2321496 , -0.16395498,\n",
      "       -0.14234782, -0.13477373, -0.12547327, -0.11058206, -0.1289273 ,\n",
      "       -0.11664702, -0.09714533, -0.56373827, -0.36191756, -0.25199182,\n",
      "       -0.18868119, -0.15729786, -0.13974009, -0.12986414, -0.12410316,\n",
      "       -0.12044125, -0.46708708, -0.24383949, -0.15978385, -0.12332344,\n",
      "       -0.10216363, -0.08278822, -0.07925985, -0.07573301, -0.07166573,\n",
      "       -0.4249353 , -0.226285  , -0.15036699, -0.12253091, -0.08969067,\n",
      "       -0.07634074, -0.07456803, -0.0695941 , -0.07122493, -0.41249134,\n",
      "       -0.23198561, -0.15114719, -0.10514353, -0.10592975, -0.07968948,\n",
      "       -0.07188219, -0.07389906, -0.07157295, -0.4069164 , -0.2288051 ,\n",
      "       -0.14785729, -0.10901113, -0.11437996, -0.08401402, -0.07110081,\n",
      "       -0.08446669, -0.06469917, -0.41491603, -0.2347394 , -0.16122627,\n",
      "       -0.14798617, -0.09618497, -0.07818709, -0.09117155, -0.0818644 ,\n",
      "       -0.08439387, -0.40367524, -0.22226143, -0.16621849, -0.14060384,\n",
      "       -0.12908663, -0.10408365, -0.08752833, -0.07991722, -0.09412808,\n",
      "       -0.41738029, -0.24441015, -0.17774607, -0.10980929, -0.08968398,\n",
      "       -0.09549252, -0.09061597, -0.10033886, -0.10542883, -0.40979818,\n",
      "       -0.23255252, -0.17749424, -0.14295717, -0.11149703, -0.08518029,\n",
      "       -0.11756381, -0.07041292, -0.10844945, -0.49254541, -0.46732769,\n",
      "       -0.44499394, -0.42464456, -0.40618862, -0.389034  , -0.37271427,\n",
      "       -0.35790383, -0.34399588, -0.4667415 , -0.41299878, -0.36804853,\n",
      "       -0.32946977, -0.29689386, -0.26852849, -0.24587686, -0.22592082,\n",
      "       -0.20900715, -0.45800066, -0.40054903, -0.35067665, -0.30882678,\n",
      "       -0.27155326, -0.24008945, -0.21462405, -0.19218454, -0.17461236,\n",
      "       -0.45507785, -0.39856375, -0.34625084, -0.3026906 , -0.26532521,\n",
      "       -0.23503542, -0.20838082, -0.18679749, -0.16896557, -0.45406886,\n",
      "       -0.39705823, -0.34911583, -0.30839724, -0.27379346, -0.24496868,\n",
      "       -0.22050157, -0.20015903, -0.18147808, -0.45443962, -0.39730588,\n",
      "       -0.34933896, -0.30916277, -0.27538029, -0.24711131, -0.22331874,\n",
      "       -0.20301901, -0.1857027 , -0.45432596, -0.39724222, -0.34953821,\n",
      "       -0.30939237, -0.27555962, -0.24720787, -0.22316091, -0.20309033,\n",
      "       -0.18587268, -0.45422028, -0.39714112, -0.34944503, -0.30955162,\n",
      "       -0.27581239, -0.2475016 , -0.22367458, -0.20357324, -0.18644306,\n",
      "       -0.45419186, -0.39709221, -0.34923802, -0.30914913, -0.27551937,\n",
      "       -0.24721047, -0.22331144, -0.20320552, -0.18619332, -0.53534097,\n",
      "       -0.5182693 , -0.50168527, -0.4857056 , -0.47214473, -0.45967154,\n",
      "       -0.44745902, -0.43645641, -0.42657252, -0.52743411, -0.5021763 ,\n",
      "       -0.47932315, -0.45800692, -0.43864327, -0.42131106, -0.40624641,\n",
      "       -0.39130154, -0.37704122, -0.52248789, -0.49351484, -0.46759904,\n",
      "       -0.44480452, -0.42403869, -0.40434616, -0.38692684, -0.3707936 ,\n",
      "       -0.35488709, -0.52148861, -0.49180322, -0.46547997, -0.44209314,\n",
      "       -0.4198789 , -0.40097066, -0.38297276, -0.36648643, -0.35045498,\n",
      "       -0.52149916, -0.4917864 , -0.46538461, -0.44174599, -0.41982496,\n",
      "       -0.40094305, -0.38287943, -0.36601327, -0.34994029, -0.52156035,\n",
      "       -0.49200196, -0.465456  , -0.44119637, -0.42003116, -0.40067094,\n",
      "       -0.38320889, -0.36560634, -0.35003918, -0.52156689, -0.49195083,\n",
      "       -0.46537461, -0.44175625, -0.42020743, -0.40104943, -0.3831699 ,\n",
      "       -0.36599213, -0.34947602, -0.5215788 , -0.49205605, -0.46563617,\n",
      "       -0.44165801, -0.41991425, -0.40068153, -0.38274444, -0.3659467 ,\n",
      "       -0.34931242, -0.52155934, -0.49201159, -0.46548148, -0.4416149 ,\n",
      "       -0.42021361, -0.40103071, -0.38343854, -0.36610538, -0.34984297,\n",
      "       -0.52154957, -0.49225298, -0.46702769, -0.44549313, -0.42615532,\n",
      "       -0.40807731, -0.39174065, -0.37703711, -0.36413393, -0.50432968,\n",
      "       -0.46417355, -0.4307791 , -0.40193272, -0.37636962, -0.35526732,\n",
      "       -0.33571579, -0.31844964, -0.30364795, -0.49898687, -0.45406563,\n",
      "       -0.4164639 , -0.38404121, -0.35634081, -0.33235849, -0.31141869,\n",
      "       -0.29403645, -0.27895504, -0.49574577, -0.4478115 , -0.40742912,\n",
      "       -0.37303892, -0.3443621 , -0.31996251, -0.29955631, -0.28219306,\n",
      "       -0.26637009, -0.49394012, -0.4450566 , -0.40245039, -0.36709768,\n",
      "       -0.33703963, -0.31156894, -0.2900214 , -0.27303372, -0.25796289,\n",
      "       -0.49174568, -0.44160651, -0.39993696, -0.36341912, -0.33356529,\n",
      "       -0.3083177 , -0.28646613, -0.26879214, -0.25335512, -0.49232298,\n",
      "       -0.44161359, -0.39967025, -0.36276662, -0.33140443, -0.30538788,\n",
      "       -0.28366271, -0.26503346, -0.25080282, -0.49091055, -0.44023465,\n",
      "       -0.39725661, -0.36073504, -0.3305148 , -0.30378619, -0.28304243,\n",
      "       -0.26346168, -0.24748141, -0.49154233, -0.4397149 , -0.39669661,\n",
      "       -0.3591702 , -0.32936454, -0.30300392, -0.28088441, -0.26247546,\n",
      "       -0.24553204, -0.89913953, -0.84766619, -0.80354365, -0.76360819,\n",
      "       -0.7242049 , -0.6882922 , -0.65516237, -0.62121961, -0.59054602,\n",
      "       -0.87547584, -0.80081268, -0.74179282, -0.68968769, -0.64689307,\n",
      "       -0.6027231 , -0.56823443, -0.53473564, -0.49160471, -0.86885924,\n",
      "       -0.78783163, -0.72164848, -0.66137622, -0.60730263, -0.56514969,\n",
      "       -0.52593137, -0.48550857, -0.45626516, -0.86650215, -0.78546128,\n",
      "       -0.71889227, -0.6597539 , -0.60813973, -0.55663561, -0.52085291,\n",
      "       -0.47755432, -0.43773539, -0.86247271, -0.78116647, -0.71513033,\n",
      "       -0.65568238, -0.60031375, -0.55364338, -0.51634239, -0.46944669,\n",
      "       -0.43996877, -0.86289834, -0.77866219, -0.71107196, -0.65238685,\n",
      "       -0.59932704, -0.55132416, -0.51101464, -0.47542948, -0.44482491,\n",
      "       -0.86283536, -0.77944888, -0.71119416, -0.65342667, -0.59742456,\n",
      "       -0.55053629, -0.50808049, -0.47063833, -0.44173203, -0.8635243 ,\n",
      "       -0.77771148, -0.7107043 , -0.65247005, -0.60125395, -0.55114568,\n",
      "       -0.5121199 , -0.47484416, -0.4354814 , -0.86334155, -0.77883659,\n",
      "       -0.71214787, -0.65360727, -0.59970165, -0.55210399, -0.51169499,\n",
      "       -0.47348885, -0.44400062]), 'std_test_score': array([0.12267142, 0.11594636, 0.11444414, 0.11339729, 0.11277453,\n",
      "       0.11235098, 0.11212898, 0.11202946, 0.11193767, 0.11116731,\n",
      "       0.10765107, 0.10727717, 0.11207303, 0.11087332, 0.1070836 ,\n",
      "       0.11057899, 0.10686287, 0.10600313, 0.11633526, 0.11498511,\n",
      "       0.11712997, 0.11461998, 0.11659844, 0.11040172, 0.10974086,\n",
      "       0.11124933, 0.11084955, 0.11283098, 0.10997997, 0.11558681,\n",
      "       0.11654016, 0.1138846 , 0.11288267, 0.11412503, 0.11286665,\n",
      "       0.11164544, 0.1150343 , 0.1154135 , 0.11607219, 0.11382602,\n",
      "       0.11354457, 0.11312429, 0.11342696, 0.11406533, 0.11378688,\n",
      "       0.11084136, 0.11071169, 0.11063838, 0.11071384, 0.110856  ,\n",
      "       0.11064961, 0.11056156, 0.1108914 , 0.11060294, 0.10945471,\n",
      "       0.10986256, 0.10985073, 0.10998083, 0.10956346, 0.10951866,\n",
      "       0.10980995, 0.10976545, 0.1096808 , 0.10945626, 0.10960368,\n",
      "       0.10974001, 0.10955818, 0.10967245, 0.1097033 , 0.10945117,\n",
      "       0.10944312, 0.10965121, 0.1094409 , 0.10935451, 0.1093402 ,\n",
      "       0.10938942, 0.109261  , 0.10958803, 0.10936027, 0.10933373,\n",
      "       0.10924684, 0.28469274, 0.23427554, 0.21015954, 0.20966197,\n",
      "       0.20763027, 0.20548989, 0.20703073, 0.20674467, 0.20817626,\n",
      "       0.21915842, 0.19733051, 0.19358479, 0.19072744, 0.18001788,\n",
      "       0.19182425, 0.14442579, 0.19166739, 0.12678799, 0.21428071,\n",
      "       0.20212828, 0.19347743, 0.20788817, 0.17974659, 0.19693945,\n",
      "       0.12630355, 0.17561956, 0.12027887, 0.22172157, 0.1962166 ,\n",
      "       0.2059829 , 0.20752239, 0.17686452, 0.14994545, 0.13839848,\n",
      "       0.16908079, 0.11413964, 0.21770693, 0.22878378, 0.20870686,\n",
      "       0.14153064, 0.20146695, 0.16070938, 0.13818966, 0.11571744,\n",
      "       0.16455339, 0.21497242, 0.21850827, 0.20863739, 0.14405845,\n",
      "       0.15157645, 0.14121162, 0.1438806 , 0.13069896, 0.13943843,\n",
      "       0.22724923, 0.187629  , 0.14709548, 0.12832429, 0.14861894,\n",
      "       0.15016946, 0.15799172, 0.1500221 , 0.1306494 , 0.19866493,\n",
      "       0.17868083, 0.19548566, 0.14525897, 0.14061519, 0.17640536,\n",
      "       0.13042578, 0.16010089, 0.14465076, 0.19903136, 0.20492965,\n",
      "       0.17942606, 0.15704755, 0.13178759, 0.13654076, 0.14634115,\n",
      "       0.14906648, 0.15306944, 0.24235687, 0.2069425 , 0.19973498,\n",
      "       0.11905938, 0.1125227 , 0.11206902, 0.11184969, 0.11160792,\n",
      "       0.11168895, 0.19008067, 0.12458923, 0.13508382, 0.13638652,\n",
      "       0.12615169, 0.11884335, 0.11528297, 0.11709776, 0.11819389,\n",
      "       0.13444217, 0.11812669, 0.12506828, 0.12200354, 0.11296503,\n",
      "       0.1338646 , 0.11120921, 0.12721514, 0.11064401, 0.13340822,\n",
      "       0.1185707 , 0.1184221 , 0.12499919, 0.1184621 , 0.11901266,\n",
      "       0.13129328, 0.11818456, 0.1170679 , 0.20061105, 0.11792282,\n",
      "       0.11102235, 0.1266803 , 0.11236321, 0.12023024, 0.12040808,\n",
      "       0.11094876, 0.11466032, 0.18159058, 0.11027892, 0.10891772,\n",
      "       0.12061136, 0.13059093, 0.11233726, 0.118889  , 0.11423511,\n",
      "       0.11169663, 0.22175623, 0.12688555, 0.11179665, 0.11345772,\n",
      "       0.12400561, 0.11043274, 0.13646954, 0.12217653, 0.1132168 ,\n",
      "       0.22491955, 0.16587869, 0.1200025 , 0.11228647, 0.11732511,\n",
      "       0.12534016, 0.11259974, 0.10760122, 0.11428535, 0.17828022,\n",
      "       0.18796537, 0.14369649, 0.11561709, 0.15879013, 0.11386   ,\n",
      "       0.15157778, 0.16299658, 0.20408854, 0.19750355, 0.11106638,\n",
      "       0.11145885, 0.11112054, 0.11145885, 0.11145885, 0.11112054,\n",
      "       0.11106858, 0.11145885, 0.11337972, 0.11071439, 0.11467878,\n",
      "       0.11101719, 0.10907098, 0.11558682, 0.1150397 , 0.11643006,\n",
      "       0.10470614, 0.1085051 , 0.11820107, 0.11576508, 0.11193917,\n",
      "       0.11533483, 0.12475358, 0.10822471, 0.11404524, 0.1082097 ,\n",
      "       0.11720667, 0.10709865, 0.13497427, 0.1176085 , 0.11207291,\n",
      "       0.1047197 , 0.10848571, 0.11874949, 0.11178379, 0.15393598,\n",
      "       0.11618346, 0.13875308, 0.1214908 , 0.11668467, 0.11614048,\n",
      "       0.11412775, 0.11475313, 0.17529746, 0.13357543, 0.12259578,\n",
      "       0.13784195, 0.13065636, 0.11295069, 0.12436583, 0.11878519,\n",
      "       0.11980685, 0.12605768, 0.12206707, 0.11921876, 0.12257105,\n",
      "       0.11345047, 0.12421079, 0.13205737, 0.12470526, 0.10966956,\n",
      "       0.12989007, 0.11265733, 0.12778347, 0.1128259 , 0.12226745,\n",
      "       0.13263241, 0.10755823, 0.1369865 , 0.11138412, 0.12382387,\n",
      "       0.12673529, 0.13389584, 0.13884649, 0.1097203 , 0.12295964,\n",
      "       0.14808245, 0.11020555, 0.11975953, 0.1296699 , 0.30910484,\n",
      "       0.25922989, 0.20982091, 0.18051351, 0.16115385, 0.14860433,\n",
      "       0.13944375, 0.13312881, 0.12829008, 0.24126156, 0.17438915,\n",
      "       0.14412163, 0.1274824 , 0.12170441, 0.11606548, 0.11544707,\n",
      "       0.11443126, 0.1128641 , 0.20532744, 0.15219403, 0.13362804,\n",
      "       0.12359925, 0.11697854, 0.12074842, 0.11973655, 0.11555176,\n",
      "       0.11485173, 0.20065822, 0.14665356, 0.12503706, 0.11788937,\n",
      "       0.11691507, 0.11571167, 0.11315994, 0.11562783, 0.11509999,\n",
      "       0.19427091, 0.14146651, 0.12514189, 0.11914746, 0.11544124,\n",
      "       0.1151665 , 0.1153406 , 0.11507358, 0.11513271, 0.19305874,\n",
      "       0.13796759, 0.12007612, 0.1139635 , 0.11190461, 0.1110185 ,\n",
      "       0.11073634, 0.11071393, 0.11078168, 0.19281976, 0.13728731,\n",
      "       0.11939606, 0.11325042, 0.111058  , 0.11023615, 0.1099162 ,\n",
      "       0.10977205, 0.10968713, 0.19265962, 0.13723578, 0.11924616,\n",
      "       0.11302226, 0.11086978, 0.1100435 , 0.10964747, 0.10954842,\n",
      "       0.10958964, 0.19274718, 0.13743866, 0.11938021, 0.11299398,\n",
      "       0.11073732, 0.10996221, 0.10964023, 0.1094721 , 0.10946267,\n",
      "       0.38083813, 0.36440188, 0.34173974, 0.33119925, 0.31608266,\n",
      "       0.31283923, 0.30129164, 0.29413254, 0.28777164, 0.36809409,\n",
      "       0.33571584, 0.30519793, 0.29133862, 0.26997186, 0.25839841,\n",
      "       0.24552071, 0.23600456, 0.22309363, 0.36003896, 0.32240738,\n",
      "       0.29261627, 0.27203144, 0.24980234, 0.23340746, 0.220653  ,\n",
      "       0.21855056, 0.20570608, 0.35868263, 0.31425671, 0.28785459,\n",
      "       0.25641302, 0.24178658, 0.22795926, 0.22759161, 0.22854961,\n",
      "       0.22457424, 0.35748601, 0.31464329, 0.28813619, 0.25706068,\n",
      "       0.24211571, 0.232047  , 0.22667997, 0.23396252, 0.22230008,\n",
      "       0.35731218, 0.3176475 , 0.28795706, 0.25765886, 0.2445647 ,\n",
      "       0.23333282, 0.22914485, 0.22819667, 0.23051188, 0.35755139,\n",
      "       0.31646912, 0.2863615 , 0.25764702, 0.25222566, 0.23449324,\n",
      "       0.2305255 , 0.22088726, 0.23463528, 0.35741715, 0.31493566,\n",
      "       0.28922175, 0.25955312, 0.24339631, 0.23614152, 0.24033526,\n",
      "       0.23411513, 0.22941555, 0.35852651, 0.31459218, 0.28178819,\n",
      "       0.25440436, 0.24564193, 0.23849865, 0.23587913, 0.23204151,\n",
      "       0.23605852, 0.35708195, 0.33287449, 0.31306683, 0.30055758,\n",
      "       0.28811346, 0.27928375, 0.26718502, 0.25198209, 0.24744903,\n",
      "       0.33380727, 0.30367214, 0.28360755, 0.26602458, 0.24212248,\n",
      "       0.23042073, 0.21780959, 0.20909917, 0.20342916, 0.32772003,\n",
      "       0.29661068, 0.26834445, 0.24655194, 0.2355568 , 0.23007075,\n",
      "       0.22160385, 0.2018202 , 0.16055722, 0.32314619, 0.28428926,\n",
      "       0.25504216, 0.23869528, 0.23016317, 0.22539883, 0.22291558,\n",
      "       0.19149163, 0.1427326 , 0.31819617, 0.28042188, 0.25391376,\n",
      "       0.24444274, 0.23407548, 0.22752952, 0.22580309, 0.22731371,\n",
      "       0.22386946, 0.31426326, 0.28393385, 0.25556188, 0.24508792,\n",
      "       0.2346163 , 0.23012392, 0.22873133, 0.22058622, 0.1784992 ,\n",
      "       0.31146932, 0.27140701, 0.25673423, 0.24548265, 0.23352015,\n",
      "       0.23314637, 0.22475734, 0.22173923, 0.22167708, 0.30954901,\n",
      "       0.26758019, 0.24917584, 0.23657616, 0.22302082, 0.22606853,\n",
      "       0.21920743, 0.22428002, 0.22204683, 0.30953888, 0.26868565,\n",
      "       0.24381999, 0.2346018 , 0.22387126, 0.1940282 , 0.2185026 ,\n",
      "       0.22165788, 0.16987149, 0.26344561, 0.23980893, 0.22084115,\n",
      "       0.21385851, 0.20978709, 0.20758898, 0.20698475, 0.20624751,\n",
      "       0.20594901, 0.2621049 , 0.18138461, 0.15048306, 0.13889569,\n",
      "       0.12909178, 0.12828521, 0.12221044, 0.12614251, 0.12127566,\n",
      "       0.25861039, 0.17371381, 0.14281405, 0.15026522, 0.13093752,\n",
      "       0.12110936, 0.12349115, 0.11936797, 0.12250414, 0.24310906,\n",
      "       0.18119574, 0.13553894, 0.12934223, 0.12288683, 0.12248924,\n",
      "       0.11968496, 0.12638557, 0.11961513, 0.23696947, 0.16727499,\n",
      "       0.14370793, 0.13332943, 0.12232464, 0.1154175 , 0.1152245 ,\n",
      "       0.11921794, 0.1146016 , 0.25062372, 0.17262614, 0.12945523,\n",
      "       0.13417636, 0.11460654, 0.12377834, 0.11521001, 0.12385341,\n",
      "       0.11571128, 0.23582313, 0.165479  , 0.13940393, 0.13261309,\n",
      "       0.13495054, 0.12124395, 0.11976128, 0.13692719, 0.11709518,\n",
      "       0.24932983, 0.16681395, 0.14284409, 0.11772318, 0.11880809,\n",
      "       0.11510126, 0.11524541, 0.12767442, 0.14705883, 0.23656886,\n",
      "       0.1525922 , 0.16774317, 0.1313792 , 0.12370382, 0.11801671,\n",
      "       0.13325408, 0.11554776, 0.12855869, 0.37565508, 0.36322226,\n",
      "       0.3532278 , 0.34491762, 0.33719122, 0.33036002, 0.32460996,\n",
      "       0.31944224, 0.31422578, 0.36537782, 0.34220255, 0.32414216,\n",
      "       0.30849962, 0.29402599, 0.28220039, 0.27221444, 0.2623267 ,\n",
      "       0.25063852, 0.35702305, 0.3286672 , 0.30413012, 0.28351757,\n",
      "       0.26658699, 0.25146044, 0.23899034, 0.22691712, 0.21636121,\n",
      "       0.35572574, 0.32694227, 0.302227  , 0.28072274, 0.26230269,\n",
      "       0.24614086, 0.23245099, 0.22037098, 0.20956117, 0.35602486,\n",
      "       0.32719714, 0.30206366, 0.28015341, 0.26101384, 0.24428263,\n",
      "       0.22946495, 0.21645189, 0.20499852, 0.35532615, 0.32624641,\n",
      "       0.30114256, 0.27923822, 0.25996248, 0.24299991, 0.22825466,\n",
      "       0.21523029, 0.20377127, 0.35534971, 0.32616338, 0.3007884 ,\n",
      "       0.27860792, 0.25949144, 0.24267277, 0.22783917, 0.21487421,\n",
      "       0.20338814, 0.35534192, 0.32614387, 0.30069968, 0.27857828,\n",
      "       0.25926113, 0.24240293, 0.22767848, 0.21457524, 0.20315366,\n",
      "       0.35530105, 0.32609456, 0.30071105, 0.2785502 , 0.25938054,\n",
      "       0.24256083, 0.22777849, 0.21481528, 0.20336486, 0.39727901,\n",
      "       0.395394  , 0.39316289, 0.39161987, 0.39079122, 0.38902979,\n",
      "       0.38643228, 0.38372698, 0.38207257, 0.39670895, 0.39350636,\n",
      "       0.3914321 , 0.38862336, 0.38570263, 0.38313555, 0.38055145,\n",
      "       0.37713158, 0.37389731, 0.39351159, 0.38924646, 0.38542003,\n",
      "       0.38246101, 0.37931813, 0.37526173, 0.37160982, 0.36786733,\n",
      "       0.36440727, 0.39344569, 0.38913924, 0.38586588, 0.38287115,\n",
      "       0.37873488, 0.37489154, 0.37112241, 0.3665245 , 0.36190909,\n",
      "       0.39350482, 0.38947181, 0.38612683, 0.38301046, 0.37855816,\n",
      "       0.37495463, 0.37106165, 0.36621285, 0.36218024, 0.39372598,\n",
      "       0.3896919 , 0.38640227, 0.38300372, 0.37880278, 0.37488925,\n",
      "       0.37018786, 0.36561742, 0.36302874, 0.39372202, 0.38963898,\n",
      "       0.38622686, 0.3829217 , 0.37889046, 0.37439262, 0.37050572,\n",
      "       0.36581609, 0.36190529, 0.39371639, 0.38980395, 0.38645619,\n",
      "       0.38275774, 0.378599  , 0.3748307 , 0.37058548, 0.36601522,\n",
      "       0.3607649 , 0.39372746, 0.38980832, 0.38631239, 0.38317133,\n",
      "       0.37864564, 0.3748133 , 0.37076277, 0.36657706, 0.36162902,\n",
      "       0.39310877, 0.38729646, 0.38221899, 0.3783865 , 0.37482494,\n",
      "       0.37125234, 0.36768966, 0.36396736, 0.36046168, 0.38824189,\n",
      "       0.3802473 , 0.37283919, 0.36510735, 0.3584073 , 0.35407178,\n",
      "       0.34900016, 0.34355194, 0.33903791, 0.38772992, 0.37798152,\n",
      "       0.3694375 , 0.36254507, 0.35539011, 0.34988017, 0.34351317,\n",
      "       0.33642887, 0.33214093, 0.38708283, 0.37715286, 0.36815143,\n",
      "       0.35897077, 0.35022311, 0.34360484, 0.33808523, 0.33303283,\n",
      "       0.32828214, 0.38746334, 0.37644358, 0.36697268, 0.35748975,\n",
      "       0.34845236, 0.33966761, 0.33274298, 0.32710761, 0.32083769,\n",
      "       0.38723772, 0.37584557, 0.36546635, 0.35545836, 0.3470948 ,\n",
      "       0.33970388, 0.3322795 , 0.32595534, 0.3199408 , 0.38604378,\n",
      "       0.37486717, 0.36496415, 0.35443591, 0.34551951, 0.33770419,\n",
      "       0.33084162, 0.32449632, 0.31824276, 0.38535461, 0.37315578,\n",
      "       0.36303824, 0.35377131, 0.34498229, 0.33695024, 0.32932047,\n",
      "       0.32165898, 0.31411494, 0.3846922 , 0.3723667 , 0.36195604,\n",
      "       0.3529139 , 0.34384564, 0.33528134, 0.32780952, 0.32087368,\n",
      "       0.31300065, 0.3233943 , 0.3151729 , 0.30864917, 0.30233606,\n",
      "       0.29889076, 0.29629612, 0.28950937, 0.27617628, 0.26986234,\n",
      "       0.32914005, 0.32093807, 0.31288212, 0.3048614 , 0.29799953,\n",
      "       0.28971374, 0.28700333, 0.27804227, 0.26924031, 0.3310254 ,\n",
      "       0.32442796, 0.31685341, 0.30739486, 0.30077096, 0.29392224,\n",
      "       0.28559447, 0.27669986, 0.26817357, 0.33052012, 0.3233442 ,\n",
      "       0.3157419 , 0.30640842, 0.2982395 , 0.28189436, 0.28623159,\n",
      "       0.26548749, 0.24759621, 0.32154582, 0.31508229, 0.3090671 ,\n",
      "       0.30024017, 0.29230567, 0.28530307, 0.27918954, 0.2515931 ,\n",
      "       0.25479708, 0.32237912, 0.31028502, 0.30249416, 0.29437454,\n",
      "       0.28841783, 0.27844093, 0.27234059, 0.26571833, 0.26239843,\n",
      "       0.32268584, 0.31129569, 0.30186293, 0.2973222 , 0.28654784,\n",
      "       0.28071146, 0.27076375, 0.26253387, 0.26175949, 0.32395497,\n",
      "       0.30907212, 0.30362041, 0.29571041, 0.29100577, 0.28109953,\n",
      "       0.27141885, 0.27183912, 0.24734428, 0.32280779, 0.3105978 ,\n",
      "       0.303979  , 0.29498978, 0.28895819, 0.28041527, 0.2711891 ,\n",
      "       0.26755977, 0.26148957]), 'rank_test_score': array([137,  54,  43,  37,  29,  26,  19,  17,  12,  77,  76,  55,   9,\n",
      "        57,  71,  78, 139, 138, 125, 149,  79,  27,  74,  59, 133,  38,\n",
      "        30,  51, 177, 154,  95,  44, 141, 144,  64,  80,  15,  32,  13,\n",
      "        34,   7,  14,  21,  33,  16, 111, 117, 120, 118, 108, 110, 130,\n",
      "        96, 102, 181, 185, 183, 190, 186, 187, 193, 194, 191, 207, 219,\n",
      "       214, 213, 205, 215, 208, 210, 204, 231, 229, 226, 232, 230, 224,\n",
      "       225, 240, 238, 580, 500, 428, 427, 422, 418, 414, 419, 411, 462,\n",
      "       406, 375, 359, 334, 367, 197, 349, 101, 433, 410, 370, 399, 331,\n",
      "       369,  92, 322,  72, 458, 382, 380, 384, 335, 209, 167, 284, 126,\n",
      "       431, 461, 405, 200, 396, 275, 218, 273, 301, 442, 429, 386, 168,\n",
      "       217, 159, 234, 104, 390, 460, 346, 180, 310, 188, 378, 311, 252,\n",
      "       150, 413, 347, 416, 249, 297, 313, 248, 353, 250, 412, 394, 324,\n",
      "       258, 100, 361, 293, 320, 263, 517, 409, 388,  67,  28,  25,  18,\n",
      "        11,  10, 354,  56, 105, 112,  58,  63,  46,  22,  23, 147,  89,\n",
      "       124,  82, 164, 199, 131, 266, 132, 143,  24,  31,  91,  35,  49,\n",
      "       169, 146,  70, 398, 152, 142, 265,  41,  87,  68,  73,  20, 357,\n",
      "        62,  45,  69,  93,   3,  75, 106,  40, 447, 116,  48,  39,  60,\n",
      "        84, 166, 103,   4, 464, 287,  88,  36, 292, 243, 291, 202, 157,\n",
      "       348, 389, 298, 140, 328, 223, 395, 443, 439, 444, 175, 163, 173,\n",
      "       160, 160, 172, 174, 160, 330, 308, 267, 323, 176, 341, 299, 327,\n",
      "       294, 156, 319, 279, 339, 344, 280, 148, 350, 158, 195, 254, 356,\n",
      "       338, 179, 383, 269, 343, 203, 510, 296, 438, 360, 289, 306, 244,\n",
      "       241, 546, 365, 337, 400, 421, 286, 376, 276, 318, 300, 295, 317,\n",
      "       321, 270, 329, 363, 221, 259, 366, 307, 374, 315, 314, 342, 278,\n",
      "       246, 325, 358, 385, 387, 423, 260, 303, 391, 253, 201, 340, 705,\n",
      "       621, 557, 480, 392, 332, 283, 247, 170, 595, 403, 281, 178,  98,\n",
      "       119,  81,  61,  83, 551, 316, 182, 135,  94, 107, 145,  86,  97,\n",
      "       549, 274, 122,  65,  53,  52,  66,  50,  85, 563, 302,  90,  42,\n",
      "         8,   6,   5,   2,   1, 566, 352, 255, 153, 136, 127, 115, 113,\n",
      "       114, 567, 368, 282, 245, 206, 196, 192, 184, 189, 569, 371, 285,\n",
      "       256, 239, 222, 216, 211, 212, 568, 372, 288, 261, 251, 242, 236,\n",
      "       237, 233, 804, 735, 690, 663, 638, 613, 605, 598, 591, 750, 667,\n",
      "       610, 592, 561, 547, 523, 508, 466, 718, 643, 596, 558, 530, 504,\n",
      "       471, 456, 425, 716, 631, 583, 545, 513, 491, 483, 484, 455, 712,\n",
      "       630, 581, 542, 515, 501, 478, 495, 441, 715, 632, 579, 544, 520,\n",
      "       497, 486, 453, 477, 711, 628, 576, 540, 529, 498, 488, 445, 479,\n",
      "       710, 627, 578, 539, 514, 489, 506, 476, 459, 713, 624, 573, 535,\n",
      "       521, 505, 499, 475, 469, 734, 669, 623, 606, 594, 574, 555, 541,\n",
      "       531, 681, 609, 584, 553, 519, 496, 451, 420, 407, 662, 600, 556,\n",
      "       527, 503, 474, 434, 401, 264, 654, 585, 548, 511, 490, 465, 436,\n",
      "       362, 227, 644, 571, 537, 512, 492, 470, 435, 437, 417, 639, 572,\n",
      "       536, 518, 494, 493, 472, 432, 351, 635, 564, 532, 524, 502, 485,\n",
      "       473, 440, 449, 636, 562, 528, 507, 467, 468, 450, 446, 452, 626,\n",
      "       559, 525, 509, 463, 404, 481, 424, 345, 920, 742, 653, 593, 550,\n",
      "       516, 487, 457, 430, 862, 640, 552, 454, 364, 262, 220, 165, 129,\n",
      "       814, 620, 538, 448, 305, 171, 155,  99, 123, 799, 625, 543, 377,\n",
      "       381, 228, 134, 151, 128, 795, 622, 533, 397, 415, 268, 121, 272,\n",
      "        47, 801, 633, 554, 534, 336, 198, 312, 257, 271, 791, 614, 560,\n",
      "       522, 482, 373, 290, 235, 326, 803, 641, 577, 402, 304, 333, 309,\n",
      "       355, 379, 798, 629, 575, 526, 408, 277, 426, 109, 393, 887, 863,\n",
      "       837, 813, 793, 769, 756, 739, 719, 860, 800, 754, 704, 684, 664,\n",
      "       646, 619, 608, 850, 782, 733, 694, 666, 637, 611, 597, 570, 848,\n",
      "       779, 721, 686, 660, 634, 607, 590, 565, 843, 773, 722, 693, 670,\n",
      "       642, 612, 599, 582, 847, 778, 725, 696, 671, 647, 617, 601, 586,\n",
      "       846, 776, 728, 697, 673, 648, 615, 602, 587, 845, 775, 726, 698,\n",
      "       674, 651, 618, 604, 589, 844, 774, 723, 695, 672, 649, 616, 603,\n",
      "       588, 913, 900, 892, 874, 867, 852, 840, 819, 816, 911, 893, 872,\n",
      "       851, 821, 811, 794, 770, 760, 909, 888, 864, 835, 812, 792, 768,\n",
      "       755, 736, 902, 880, 857, 833, 806, 786, 763, 752, 732, 903, 879,\n",
      "       855, 831, 805, 785, 762, 749, 730, 906, 882, 856, 825, 808, 783,\n",
      "       765, 746, 731, 907, 881, 854, 832, 809, 788, 764, 748, 727, 908,\n",
      "       884, 859, 829, 807, 784, 761, 747, 724, 905, 883, 858, 828, 810,\n",
      "       787, 766, 751, 729, 904, 885, 861, 839, 815, 797, 771, 759, 745,\n",
      "       894, 853, 817, 789, 758, 737, 714, 701, 688, 891, 842, 802, 767,\n",
      "       738, 708, 699, 683, 675, 890, 841, 796, 757, 720, 702, 685, 677,\n",
      "       661, 889, 838, 790, 753, 717, 700, 682, 668, 656, 878, 826, 781,\n",
      "       744, 709, 692, 680, 665, 655, 886, 827, 780, 743, 707, 691, 679,\n",
      "       659, 652, 875, 824, 777, 741, 706, 689, 678, 658, 650, 876, 822,\n",
      "       772, 740, 703, 687, 676, 657, 645, 972, 963, 962, 953, 951, 942,\n",
      "       938, 932, 923, 971, 961, 952, 943, 933, 929, 922, 912, 877, 970,\n",
      "       960, 950, 941, 930, 921, 910, 873, 849, 969, 959, 949, 940, 931,\n",
      "       919, 901, 871, 820, 964, 958, 948, 939, 927, 918, 899, 865, 823,\n",
      "       966, 955, 945, 934, 925, 916, 896, 870, 836, 965, 957, 946, 936,\n",
      "       924, 914, 895, 866, 830, 968, 954, 944, 935, 928, 915, 898, 869,\n",
      "       818, 967, 956, 947, 937, 926, 917, 897, 868, 834])}\n",
      "网格搜索-最佳度量值: -0.060941160652538705\n",
      "网格搜索-最佳参数： {'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 5, 'n_estimators': 900}\n",
      "网格搜索-最佳模型： GradientBoostingRegressor(learning_rate=0.01, max_depth=5, n_estimators=900)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_gbr = GradientBoostingRegressor()\n",
    "param_grid_simple = {'n_estimators': list(range(100, 1000, 100)), 'max_depth': list(range(1, 10, 1)), 'learning_rate': [0.1, 0.01, 0.001], 'loss': ['squared_error', 'absolute_error', 'huber', 'quantile']}\n",
    "search_gbr = GridSearchCV(estimator=model_gbr, param_grid=param_grid_simple, cv=5, scoring='neg_mean_squared_error')\n",
    "search_gbr.fit(data_fit_X, data_fit_y)\n",
    "\n",
    "print('网格搜索-度量记录：',search_gbr.cv_results_)  # 包含每次训练的相关信息\n",
    "print('网格搜索-最佳度量值:',search_gbr.best_score_)  # 获取最佳度量值\n",
    "print('网格搜索-最佳参数：',search_gbr.best_params_)  # 获取最佳度量值时的代定参数的值。是一个字典\n",
    "print('网格搜索-最佳模型：',search_gbr.best_estimator_)  # 获取最佳度量时的分类器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度： -3.538102297128259e-05\n"
     ]
    }
   ],
   "source": [
    "# 输出训练集精度\n",
    "print('训练集精度：', search_gbr.score(data_fit_X, data_fit_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.9197179743478785\n",
      "mean_absolute_error 0.07367843379026702\n",
      "mean_squared_error 0.024849866400815813\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证评价性能\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import sklearn\n",
    "\n",
    "search_gbr = GradientBoostingRegressor(learning_rate=0.01, loss='squared_error', max_depth=5, n_estimators=900)\n",
    "gbr_pridict = cross_val_predict(search_gbr, data_test_X, data_test_y, cv=10)\n",
    "\n",
    "for scorer in ['r2_score', 'mean_absolute_error', 'mean_squared_error']:\n",
    "    score = getattr(sklearn.metrics, scorer)(data_test_y, gbr_pridict)\n",
    "    print(scorer, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
