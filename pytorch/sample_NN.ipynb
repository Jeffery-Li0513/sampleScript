{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "from matminer.featurizers.composition import alloy\n",
    "from matminer.featurizers.conversions import StrToComposition\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445f3c2404374217a3e8ff7a67d3cb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "StrToComposition:   0%|          | 0/799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39ef10d69bc420096413c2eb5454f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WenAlloys:   0%|          | 0/799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Convert formula to composition\n",
    "data = StrToComposition().featurize_dataframe(data, 'formula')\n",
    "# 然后基于composition计算特征\n",
    "data = alloy.WenAlloys().featurize_dataframe(data, 'composition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择前1500条数据作为训练集和验证集；后500条数据作为验证集。\n",
    "data_fit = data.iloc[:400]\n",
    "data_test = data.iloc[400:]\n",
    "\n",
    "data_fit_X = data_fit[['APE mean', 'Electronegativity local mismatch', 'VEC mean', 'Shear modulus mean', 'Shear modulus delta', 'Shear modulus strength model']]\n",
    "data_fit_y = data_fit[['SFE']]\n",
    "data_test_X = data_test[['APE mean', 'Electronegativity local mismatch', 'VEC mean', 'Shear modulus mean', 'Shear modulus delta', 'Shear modulus strength model']]\n",
    "data_test_y = data_test[['SFE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 数据归一化\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# data_fit_X = min_max_scaler.fit_transform(data_fit_X)\n",
    "# data_test_X = min_max_scaler.transform(data_test_X)\n",
    "\n",
    "# 将数据类型转换为tensor\n",
    "data_fit_X = torch.FloatTensor(data_fit_X.values)\n",
    "data_fit_y = torch.FloatTensor(data_fit_y.values)\n",
    "data_test_X = torch.FloatTensor(data_test_X.values)\n",
    "data_test_y = torch.FloatTensor(data_test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=6, out_features=20, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (predict): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # 隐层\n",
    "        self.relu = torch.nn.ReLU()                          # 选择激活层\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)                                   # 计算隐层\n",
    "        x = self.relu(x)                                     # 计算激活层\n",
    "        x = self.predict(x)                                  # 输出层\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0404])\n",
      "tensor([1.0404])\n",
      "tensor([1.1725])\n",
      "tensor([1.1725])\n",
      "tensor([1.2388])\n",
      "tensor([1.2388])\n",
      "tensor([1.2719])\n",
      "tensor([1.2719])\n",
      "tensor([1.2885])\n",
      "tensor([1.2885])\n",
      "tensor([1.2968])\n",
      "tensor([1.2968])\n",
      "tensor([1.3009])\n",
      "tensor([1.3009])\n",
      "tensor([1.3030])\n",
      "tensor([1.3030])\n",
      "tensor([1.3040])\n",
      "tensor([1.3040])\n",
      "tensor([1.3045])\n",
      "tensor([1.3045])\n",
      "tensor([1.3048])\n",
      "tensor([1.3048])\n",
      "tensor([1.3049])\n",
      "tensor([1.3049])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "tensor([1.3050])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 选择损失函数和优化方法\n",
    "import sklearn\n",
    "metric_func = lambda y_pred, y_true: sklearn.metrics.accuracy_score(y_true.data.numpy(), y_pred.data.numpy())\n",
    "metric_name = 'accuracy'\n",
    "\n",
    "loss_func = torch.nn.SmoothL1Loss()\n",
    "\n",
    "for i in range(1, 2):\n",
    "    net = Net(n_feature=6, n_hidden=i, n_output=1)              # 定义网络\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "    for t in range(50):\n",
    "        prediction = net(data_fit_X)                                      # 用网络预测一下\n",
    "        loss = loss_func(prediction, data_fit_y)                          # 计算损失\n",
    "        optimizer.zero_grad()                                    # 清除上一步的梯度\n",
    "        loss.backward()                                          # 反向传播, 计算梯度\n",
    "        optimizer.step()                                         # 优化一步\n",
    "        # print(\"train loss: {}\".format(loss.item()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted = net(data_test_X)\n",
    "            score = getattr(sklearn.metrics, 'r2_score')(data_test_y, predicted)\n",
    "            # print(\"test accur: {}\".format(score))\n",
    "            print(predicted[3])\n",
    "            print(predicted[0])\n",
    "    print(\"\\n\")\n",
    "\n",
    "predicted = net(data_test_X)\n",
    "# print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3389],\n",
      "        [1.3615],\n",
      "        [1.1708],\n",
      "        [0.9958],\n",
      "        [1.2644],\n",
      "        [1.4218],\n",
      "        [1.5325],\n",
      "        [1.8895],\n",
      "        [0.9257],\n",
      "        [1.2275],\n",
      "        [1.7786],\n",
      "        [0.8565],\n",
      "        [0.8324],\n",
      "        [1.8704],\n",
      "        [1.6943],\n",
      "        [1.9546],\n",
      "        [1.3561],\n",
      "        [1.9981],\n",
      "        [1.6506],\n",
      "        [1.2616],\n",
      "        [1.1711],\n",
      "        [1.0339],\n",
      "        [1.1983],\n",
      "        [1.3449],\n",
      "        [1.3842],\n",
      "        [1.4108],\n",
      "        [1.2423],\n",
      "        [1.1057],\n",
      "        [1.2796],\n",
      "        [1.0635],\n",
      "        [1.3798],\n",
      "        [1.0597],\n",
      "        [1.2247],\n",
      "        [2.1491],\n",
      "        [0.8386],\n",
      "        [1.0799],\n",
      "        [1.3583],\n",
      "        [1.1874],\n",
      "        [0.8555],\n",
      "        [1.4097],\n",
      "        [1.7277],\n",
      "        [1.1623],\n",
      "        [1.3405],\n",
      "        [1.3350],\n",
      "        [2.0580],\n",
      "        [1.7993],\n",
      "        [0.7360],\n",
      "        [1.3243],\n",
      "        [1.5481],\n",
      "        [1.1255],\n",
      "        [1.2696],\n",
      "        [1.2338],\n",
      "        [0.8353],\n",
      "        [1.3665],\n",
      "        [1.7180],\n",
      "        [1.5104],\n",
      "        [1.8766],\n",
      "        [1.3183],\n",
      "        [1.1367],\n",
      "        [1.7599],\n",
      "        [1.3601],\n",
      "        [1.5613],\n",
      "        [1.2576],\n",
      "        [1.3689],\n",
      "        [1.6166],\n",
      "        [1.1441],\n",
      "        [0.8260],\n",
      "        [1.2522],\n",
      "        [1.2299],\n",
      "        [1.3010],\n",
      "        [1.3760],\n",
      "        [1.4387],\n",
      "        [1.4357],\n",
      "        [1.2875],\n",
      "        [1.7343],\n",
      "        [1.4395],\n",
      "        [1.3768],\n",
      "        [1.3580],\n",
      "        [1.3762],\n",
      "        [1.2921],\n",
      "        [0.7514],\n",
      "        [1.2688],\n",
      "        [1.2128],\n",
      "        [1.1747],\n",
      "        [0.7829],\n",
      "        [1.1887],\n",
      "        [1.0672],\n",
      "        [1.7568],\n",
      "        [0.8322],\n",
      "        [1.6339],\n",
      "        [1.0562],\n",
      "        [1.2357],\n",
      "        [1.3622],\n",
      "        [0.9714],\n",
      "        [1.2549],\n",
      "        [1.5480],\n",
      "        [1.0507],\n",
      "        [1.0780],\n",
      "        [1.3455],\n",
      "        [1.9602],\n",
      "        [1.1718],\n",
      "        [1.6308],\n",
      "        [0.8089],\n",
      "        [1.1278],\n",
      "        [1.5920],\n",
      "        [1.0327],\n",
      "        [0.8896],\n",
      "        [1.5574],\n",
      "        [1.3239],\n",
      "        [1.2829],\n",
      "        [1.1095],\n",
      "        [1.3360],\n",
      "        [1.1206],\n",
      "        [0.9962],\n",
      "        [1.1353],\n",
      "        [1.3293],\n",
      "        [0.8095],\n",
      "        [1.2712],\n",
      "        [1.2540],\n",
      "        [1.8178],\n",
      "        [1.5208],\n",
      "        [0.9439],\n",
      "        [1.2256],\n",
      "        [1.7850],\n",
      "        [0.7595],\n",
      "        [1.3239],\n",
      "        [1.1950],\n",
      "        [0.7792],\n",
      "        [1.0382],\n",
      "        [1.2081],\n",
      "        [1.2447],\n",
      "        [1.6128],\n",
      "        [0.7472],\n",
      "        [1.2142],\n",
      "        [1.3704],\n",
      "        [1.3092],\n",
      "        [1.9163],\n",
      "        [1.8735],\n",
      "        [1.2610],\n",
      "        [1.2112],\n",
      "        [0.9480],\n",
      "        [0.9365],\n",
      "        [2.0666],\n",
      "        [1.3219],\n",
      "        [1.5038],\n",
      "        [0.8113],\n",
      "        [1.7203],\n",
      "        [1.1272],\n",
      "        [1.4040],\n",
      "        [1.0693],\n",
      "        [1.3169],\n",
      "        [1.1285],\n",
      "        [1.1921],\n",
      "        [0.8415],\n",
      "        [0.8480],\n",
      "        [1.1347],\n",
      "        [1.3494],\n",
      "        [0.8410],\n",
      "        [1.1147],\n",
      "        [1.2092],\n",
      "        [1.3711],\n",
      "        [1.0606],\n",
      "        [1.4329],\n",
      "        [1.9330],\n",
      "        [1.0655],\n",
      "        [1.2526],\n",
      "        [2.0580],\n",
      "        [1.8257],\n",
      "        [1.1599],\n",
      "        [1.2484],\n",
      "        [1.1733],\n",
      "        [1.5564],\n",
      "        [2.0172],\n",
      "        [1.4291],\n",
      "        [1.4312],\n",
      "        [1.7212],\n",
      "        [1.3039],\n",
      "        [0.8628],\n",
      "        [1.2579],\n",
      "        [0.8074],\n",
      "        [1.8750],\n",
      "        [1.1144],\n",
      "        [1.0646],\n",
      "        [0.7844],\n",
      "        [0.8994],\n",
      "        [0.7906],\n",
      "        [1.0859],\n",
      "        [1.9047],\n",
      "        [2.0072],\n",
      "        [1.4433],\n",
      "        [1.1688],\n",
      "        [1.3575],\n",
      "        [1.2130],\n",
      "        [1.6140],\n",
      "        [1.3545],\n",
      "        [1.2590],\n",
      "        [1.2709],\n",
      "        [1.7038],\n",
      "        [1.2176],\n",
      "        [1.8911],\n",
      "        [1.1999],\n",
      "        [0.7704],\n",
      "        [1.1969],\n",
      "        [1.5198],\n",
      "        [1.9692],\n",
      "        [0.8045],\n",
      "        [1.0991],\n",
      "        [1.2786],\n",
      "        [1.4703],\n",
      "        [1.9581],\n",
      "        [1.2071],\n",
      "        [0.9805],\n",
      "        [1.2103],\n",
      "        [1.3227],\n",
      "        [1.1739],\n",
      "        [0.8345],\n",
      "        [0.7532],\n",
      "        [1.4105],\n",
      "        [1.4581],\n",
      "        [1.0987],\n",
      "        [1.4043],\n",
      "        [1.3788],\n",
      "        [0.8230],\n",
      "        [1.5496],\n",
      "        [1.4264],\n",
      "        [1.4419],\n",
      "        [2.2254],\n",
      "        [1.2432],\n",
      "        [1.2640],\n",
      "        [1.4135],\n",
      "        [0.7907],\n",
      "        [1.3786],\n",
      "        [1.8216],\n",
      "        [0.8524],\n",
      "        [1.2925],\n",
      "        [1.1927],\n",
      "        [1.9573],\n",
      "        [0.7923],\n",
      "        [1.5804],\n",
      "        [0.8424],\n",
      "        [1.2288],\n",
      "        [1.4829],\n",
      "        [1.3702],\n",
      "        [0.8662],\n",
      "        [1.9127],\n",
      "        [1.2035],\n",
      "        [0.7985],\n",
      "        [0.9234],\n",
      "        [1.1568],\n",
      "        [1.1421],\n",
      "        [1.3176],\n",
      "        [1.1420],\n",
      "        [1.7034],\n",
      "        [1.3715],\n",
      "        [1.1618],\n",
      "        [1.1245],\n",
      "        [1.1441],\n",
      "        [1.2477],\n",
      "        [0.8204],\n",
      "        [1.4609],\n",
      "        [0.7447],\n",
      "        [1.2389],\n",
      "        [1.3135],\n",
      "        [1.5803],\n",
      "        [1.4770],\n",
      "        [1.1355],\n",
      "        [1.2448],\n",
      "        [1.1970],\n",
      "        [1.0764],\n",
      "        [1.0964],\n",
      "        [1.3980],\n",
      "        [1.6437],\n",
      "        [1.0227],\n",
      "        [1.3464],\n",
      "        [1.6079],\n",
      "        [0.8486],\n",
      "        [0.8560],\n",
      "        [1.9731],\n",
      "        [0.8780],\n",
      "        [1.6863],\n",
      "        [1.5682],\n",
      "        [2.1191],\n",
      "        [1.0040],\n",
      "        [1.3512],\n",
      "        [0.7734],\n",
      "        [1.1388],\n",
      "        [1.1777],\n",
      "        [1.9255],\n",
      "        [1.3841],\n",
      "        [1.2276],\n",
      "        [1.0701],\n",
      "        [1.0818],\n",
      "        [0.8259],\n",
      "        [1.7924],\n",
      "        [1.8917],\n",
      "        [1.1879],\n",
      "        [0.7638],\n",
      "        [1.1120],\n",
      "        [1.9003],\n",
      "        [1.0643],\n",
      "        [1.2163],\n",
      "        [1.1212],\n",
      "        [1.2154],\n",
      "        [1.1688],\n",
      "        [0.9524],\n",
      "        [1.4953],\n",
      "        [1.2406],\n",
      "        [1.1400],\n",
      "        [2.0174],\n",
      "        [1.2773],\n",
      "        [1.8985],\n",
      "        [1.3948],\n",
      "        [1.3008],\n",
      "        [1.2721],\n",
      "        [1.8755],\n",
      "        [1.1443],\n",
      "        [1.4452],\n",
      "        [1.3537],\n",
      "        [1.7969],\n",
      "        [1.4409],\n",
      "        [1.9064],\n",
      "        [1.1182],\n",
      "        [1.0991],\n",
      "        [1.0842],\n",
      "        [0.7300],\n",
      "        [1.1883],\n",
      "        [1.1765],\n",
      "        [1.7185],\n",
      "        [2.0057],\n",
      "        [1.0482],\n",
      "        [1.3385],\n",
      "        [1.1375],\n",
      "        [1.6246],\n",
      "        [1.3959],\n",
      "        [1.4759],\n",
      "        [1.8060],\n",
      "        [0.7988],\n",
      "        [1.3512],\n",
      "        [2.0563],\n",
      "        [0.7764],\n",
      "        [1.2856],\n",
      "        [0.8130],\n",
      "        [1.2576],\n",
      "        [0.8147],\n",
      "        [0.8681],\n",
      "        [1.3064],\n",
      "        [0.7929],\n",
      "        [1.2438],\n",
      "        [0.8193],\n",
      "        [1.9279],\n",
      "        [1.1918],\n",
      "        [1.0478],\n",
      "        [1.7793],\n",
      "        [1.3155],\n",
      "        [1.4337],\n",
      "        [1.2292],\n",
      "        [1.3382],\n",
      "        [1.2526],\n",
      "        [1.4128],\n",
      "        [1.4496],\n",
      "        [1.2349],\n",
      "        [0.9210],\n",
      "        [1.2248],\n",
      "        [1.3244],\n",
      "        [1.3620],\n",
      "        [1.5596],\n",
      "        [1.4704],\n",
      "        [0.9836],\n",
      "        [1.7079],\n",
      "        [1.5508],\n",
      "        [1.1195],\n",
      "        [1.6659],\n",
      "        [0.7508],\n",
      "        [1.3470],\n",
      "        [0.9378],\n",
      "        [1.3019],\n",
      "        [1.4289],\n",
      "        [1.1861],\n",
      "        [1.8017],\n",
      "        [1.3141],\n",
      "        [1.3429],\n",
      "        [1.4905],\n",
      "        [1.1576],\n",
      "        [1.3406],\n",
      "        [1.2091],\n",
      "        [1.7774],\n",
      "        [0.8783],\n",
      "        [1.7424],\n",
      "        [0.8529],\n",
      "        [1.7182],\n",
      "        [1.4294],\n",
      "        [0.7697],\n",
      "        [1.2460],\n",
      "        [1.1826],\n",
      "        [1.1778],\n",
      "        [1.2012],\n",
      "        [1.6523],\n",
      "        [1.1988],\n",
      "        [1.2960]])\n"
     ]
    }
   ],
   "source": [
    "print(data_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
